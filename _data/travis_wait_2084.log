INFO:__main__:Get urls from stories
  0%|          | 0/30 [00:00<?, ?it/s]  3%|▎         | 1/30 [00:00<00:04,  6.30it/s]  7%|▋         | 2/30 [00:03<00:27,  1.02it/s] 13%|█▎        | 4/30 [00:04<00:24,  1.06it/s] 17%|█▋        | 5/30 [00:05<00:18,  1.34it/s] 23%|██▎       | 7/30 [00:05<00:12,  1.79it/s] 27%|██▋       | 8/30 [00:10<00:44,  2.03s/it] 30%|███       | 9/30 [00:12<00:39,  1.87s/it] 33%|███▎      | 10/30 [00:13<00:32,  1.63s/it] 40%|████      | 12/30 [00:13<00:21,  1.19s/it] 43%|████▎     | 13/30 [00:13<00:15,  1.13it/s] 47%|████▋     | 14/30 [00:14<00:10,  1.47it/s] 53%|█████▎    | 16/30 [00:14<00:07,  1.79it/s] 60%|██████    | 18/30 [00:15<00:05,  2.10it/s] 70%|███████   | 21/30 [00:15<00:03,  2.86it/s] 73%|███████▎  | 22/30 [00:15<00:02,  3.40it/s] 77%|███████▋  | 23/30 [00:15<00:02,  3.16it/s] 80%|████████  | 24/30 [00:16<00:01,  3.52it/s] 83%|████████▎ | 25/30 [00:16<00:01,  3.88it/s] 90%|█████████ | 27/30 [00:16<00:00,  3.77it/s] 93%|█████████▎| 28/30 [00:16<00:00,  4.45it/s] 97%|█████████▋| 29/30 [00:17<00:00,  3.34it/s]100%|██████████| 30/30 [00:17<00:00,  1.72it/s]
  0%|          | 0/1049 [00:00<?, ?it/s]INFO:__main__:Requesting https://www.economist.com/science-and-technology/2019/02/28/the-periodic-table-is-150-years-old-this-week
INFO:__main__:Getting metadata for https://www.economist.com/science-and-technology/2019/02/28/the-periodic-table-is-150-years-old-this-week
  0%|          | 1/1049 [00:00<08:30,  2.05it/s]INFO:__main__:Requesting https://cen.acs.org/unassigned/Reactions/97/i3
INFO:__main__:Getting metadata for https://cen.acs.org/unassigned/Reactions/97/i3
ERROR:__main__:Could not get metadata for https://cen.acs.org/unassigned/Reactions/97/i3
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
  0%|          | 2/1049 [00:02<15:38,  1.12it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=2XkV6IpV2Y0
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=2XkV6IpV2Y0
  0%|          | 3/1049 [00:03<16:45,  1.04it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=0fKBhvDjuy0
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=0fKBhvDjuy0
  0%|          | 4/1049 [00:04<17:35,  1.01s/it]INFO:__main__:Requesting https://youtu.be/g_2bo4abkPI
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=g_2bo4abkPI&feature=youtu.be
  0%|          | 5/1049 [00:05<17:13,  1.01it/s]INFO:__main__:Requesting https://www.newscientist.com/article/mg24132190-300-the-true-story-of-the-birth-of-the-periodic-table-150-years-ago/
INFO:__main__:Getting metadata for https://www.newscientist.com/article/mg24132190-300-the-true-story-of-the-birth-of-the-periodic-table-150-years-ago/
  1%|          | 6/1049 [00:07<24:39,  1.42s/it]INFO:__main__:Requesting https://www.sec.gov/Archives/edgar/data/1759509/000119312519059849/d633517ds1.htm
INFO:__main__:Getting metadata for https://www.sec.gov/Archives/edgar/data/1759509/000119312519059849/d633517ds1.htm
  1%|          | 7/1049 [00:24<1:44:11,  6.00s/it]INFO:__main__:Requesting https://techcrunch.com/2017/09/15/why-dropbox-decided-to-drop-aws-and-build-its-own-infrastructure-and-network/
ERROR:__main__:Could not reach https://techcrunch.com/2017/09/15/why-dropbox-decided-to-drop-aws-and-build-its-own-infrastructure-and-network/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
  1%|          | 8/1049 [00:24<1:13:29,  4.24s/it]INFO:__main__:Requesting https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/a-new-collaboration-with-google-cloud.html
INFO:__main__:Getting metadata for https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/a-new-collaboration-with-google-cloud.html
  1%|          | 9/1049 [00:25<53:24,  3.08s/it]  INFO:__main__:Requesting https://www.contino.io/insights/whos-using-aws
INFO:__main__:Getting metadata for https://www.contino.io/insights/whos-using-aws
  1%|          | 10/1049 [00:26<46:43,  2.70s/it]INFO:__main__:Requesting http://nymag.com/intelligencer/2018/03/when-amazon-web-services-goes-down-so-does-a-lot-of-the-web.html
INFO:__main__:Getting metadata for http://nymag.com/intelligencer/2018/03/when-amazon-web-services-goes-down-so-does-a-lot-of-the-web.html
  1%|          | 11/1049 [00:27<35:26,  2.05s/it]INFO:__main__:Requesting https://twitter.com/MikeIsaac/status/1101542615042801664
INFO:__main__:Getting metadata for https://twitter.com/MikeIsaac/status/1101542615042801664
  1%|          | 12/1049 [00:28<28:21,  1.64s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Y_Combinator
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Y_Combinator
  1%|          | 13/1049 [00:29<26:17,  1.52s/it]INFO:__main__:Requesting https://news.ycombinator.com/newsguidelines.html
INFO:__main__:Getting metadata for https://news.ycombinator.com/newsguidelines.html
ERROR:__main__:Could not get metadata for https://news.ycombinator.com/newsguidelines.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  1%|▏         | 14/1049 [00:30<24:05,  1.40s/it]INFO:__main__:Requesting https://www.reuters.com/article/us-uber-results/uber-posts-50-billion-in-annual-bookings-as-profit-remains-elusive-ahead-of-ipo-idUSKCN1Q42CI
INFO:__main__:Getting metadata for https://www.reuters.com/article/us-uber-results/uber-posts-50-billion-in-annual-bookings-as-profit-remains-elusive-ahead-of-ipo-idUSKCN1Q42CI
  1%|▏         | 15/1049 [00:30<18:36,  1.08s/it]INFO:__main__:Requesting https://www.bloomberg.com/news/articles/2018-11-14/uber-revenue-slows-as-quarterly-loss-surges-to-1-1-billion
INFO:__main__:Getting metadata for https://www.bloomberg.com/tosv2.html?vid=&uuid=0611ad20-3c76-11e9-b4c9-956008982f6e&url=L25ld3MvYXJ0aWNsZXMvMjAxOC0xMS0xNC91YmVyLXJldmVudWUtc2xvd3MtYXMtcXVhcnRlcmx5LWxvc3Mtc3VyZ2VzLXRvLTEtMS1iaWxsaW9u
  2%|▏         | 16/1049 [00:31<15:44,  1.09it/s]INFO:__main__:Requesting https://imgur.com/a/NaroN6P
INFO:__main__:Getting metadata for https://imgur.com/a/NaroN6P
ERROR:__main__:Could not get metadata for https://imgur.com/a/NaroN6P
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  2%|▏         | 17/1049 [00:31<13:43,  1.25it/s]INFO:__main__:Requesting https://twitter.com/modestproposal1/status/1101542179481288704
INFO:__main__:Getting metadata for https://twitter.com/modestproposal1/status/1101542179481288704
  2%|▏         | 18/1049 [00:33<15:29,  1.11it/s]INFO:__main__:Requesting https://techcrunch.com/2019/02/26/heres-why-youre-getting-all-those-sweet-uber-and-lyft-discounts/
ERROR:__main__:Could not reach https://techcrunch.com/2019/02/26/heres-why-youre-getting-all-those-sweet-uber-and-lyft-discounts/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
  2%|▏         | 19/1049 [00:33<11:25,  1.50it/s]INFO:__main__:Requesting https://play.google.com/store/apps/details?id=com.ubercab.fleet&hl=en
INFO:__main__:Getting metadata for https://play.google.com/store/apps/details?id=com.ubercab.fleet&hl=en
  2%|▏         | 20/1049 [00:33<10:30,  1.63it/s]INFO:__main__:Requesting https://get.sentieo.com/lyft-ipo/
INFO:__main__:Getting metadata for https://get.sentieo.com/lyft-ipo/
ERROR:__main__:Could not get metadata for https://get.sentieo.com/lyft-ipo/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  2%|▏         | 21/1049 [00:34<09:34,  1.79it/s]INFO:__main__:Requesting https://www.bloomberg.com/opinion/articles/2019-02-12/lyft-doesn-t-need-investors-to-vote
INFO:__main__:Getting metadata for https://www.bloomberg.com/tosv2.html?vid=&uuid=07fbc9e0-3c76-11e9-8267-67032fcc2caf&url=L29waW5pb24vYXJ0aWNsZXMvMjAxOS0wMi0xMi9seWZ0LWRvZXNuLXQtbmVlZC1pbnZlc3RvcnMtdG8tdm90ZQ==
  2%|▏         | 22/1049 [00:34<09:15,  1.85it/s]INFO:__main__:Requesting https://github.com/aiven/pghoard/
INFO:__main__:Getting metadata for https://github.com/aiven/pghoard/
  2%|▏         | 23/1049 [00:35<10:59,  1.56it/s]INFO:__main__:Requesting https://github.com/wal-e/wal-e
INFO:__main__:Getting metadata for https://github.com/wal-e/wal-e
  2%|▏         | 24/1049 [00:36<13:11,  1.30it/s]INFO:__main__:Requesting https://github.com/wal-g/wal-g
INFO:__main__:Getting metadata for https://github.com/wal-g/wal-g
  2%|▏         | 25/1049 [00:37<13:47,  1.24it/s]INFO:__main__:Requesting https://blog.bolt.io/casper-glow-e4f8819376d7
INFO:__main__:Getting metadata for https://blog.bolt.io/casper-glow-e4f8819376d7?gi=c23a143e8643
  2%|▏         | 26/1049 [00:38<15:24,  1.11it/s]INFO:__main__:Requesting https://bedtimebulb.com/
INFO:__main__:Getting metadata for https://bedtimebulb.com
  3%|▎         | 27/1049 [00:39<14:06,  1.21it/s]INFO:__main__:Requesting https://i.imgur.com/fHJKxWA.png
INFO:__main__:Getting metadata for https://i.imgur.com/fHJKxWA.png
ERROR:__main__:Could not get metadata for https://i.imgur.com/fHJKxWA.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  3%|▎         | 28/1049 [00:42<24:21,  1.43s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Intrinsically_photosensitive_retinal_ganglion_cells
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Intrinsically_photosensitive_retinal_ganglion_cells
  3%|▎         | 29/1049 [00:43<23:42,  1.40s/it]INFO:__main__:Requesting https://www.ies.org/fires/melanopic-green-the-other-side-of-blue/
INFO:__main__:Getting metadata for https://www.ies.org/fires/melanopic-green-the-other-side-of-blue/
  3%|▎         | 30/1049 [00:48<42:12,  2.49s/it]INFO:__main__:Requesting https://fluxometer.com/rainbow/#!id=iPad%20Pro/6500K-iPad%20Pro
INFO:__main__:Getting metadata for https://fluxometer.com/rainbow/#!id=iPad%20Pro/6500K-iPad%20Pro
  3%|▎         | 31/1049 [00:49<33:51,  2.00s/it]INFO:__main__:Requesting https://i.stack.imgur.com/5snTb.png
INFO:__main__:Getting metadata for https://i.stack.imgur.com/5snTb.png
ERROR:__main__:Could not get metadata for https://i.stack.imgur.com/5snTb.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  3%|▎         | 32/1049 [00:50<27:53,  1.65s/it]INFO:__main__:Requesting https://fluxometer.com/rainbow/
INFO:__main__:Getting metadata for https://fluxometer.com/rainbow/
  3%|▎         | 33/1049 [00:50<23:30,  1.39s/it]INFO:__main__:Requesting https://medium.com/@BenEinstein/heres-why-juicero-s-press-is-so-expensive-6add74594e50
INFO:__main__:Getting metadata for https://medium.com/@BenEinstein/heres-why-juicero-s-press-is-so-expensive-6add74594e50
  3%|▎         | 34/1049 [00:51<19:33,  1.16s/it]INFO:__main__:Requesting https://www.recode.net/2017/9/23/13153814/casper-sleepopolis-lawsuits-mattress-reviews
INFO:__main__:Getting metadata for https://www.recode.net/2017/9/23/13153814/casper-sleepopolis-lawsuits-mattress-reviews
  3%|▎         | 35/1049 [00:52<17:02,  1.01s/it]INFO:__main__:Requesting https://i.imgur.com/NCr148L.png
INFO:__main__:Getting metadata for https://i.imgur.com/NCr148L.png
ERROR:__main__:Could not get metadata for https://i.imgur.com/NCr148L.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  3%|▎         | 36/1049 [01:03<1:11:02,  4.21s/it]INFO:__main__:Requesting https://twitter.com/tmincey/status/1097990987849158657
INFO:__main__:Getting metadata for https://twitter.com/tmincey/status/1097990987849158657
  4%|▎         | 37/1049 [01:04<53:17,  3.16s/it]  INFO:__main__:Requesting https://www.macrumors.com/review/casper-glow-light/
INFO:__main__:Getting metadata for https://www.macrumors.com/review/casper-glow-light/
ERROR:__main__:Could not get metadata for https://www.macrumors.com/review/casper-glow-light/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  4%|▎         | 38/1049 [01:05<40:34,  2.41s/it]INFO:__main__:Requesting https://wap.taotronics.com/#/product/product_details?urlKey=ttdl2390fa2f22
INFO:__main__:Getting metadata for https://wap.taotronics.com/#/product/product_details?urlKey=ttdl2390fa2f22
ERROR:__main__:Could not get metadata for https://wap.taotronics.com/#/product/product_details?urlKey=ttdl2390fa2f22
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  4%|▎         | 39/1049 [01:06<35:37,  2.12s/it]INFO:__main__:Requesting https://www.amazon.com/Aiprov-Fireproof-Induction-Battery-Powered-Nightlights/dp/B07HH719RL/ref=mp_s_a_1_8?keywords=motion+sensor+night+light+red&qid=1551477179&s=gateway&sr=8-8
INFO:__main__:Getting metadata for https://www.amazon.com/Aiprov-Fireproof-Induction-Battery-Powered-Nightlights/dp/B07HH719RL/ref=mp_s_a_1_8?keywords=motion+sensor+night+light+red&qid=1551477179&s=gateway&sr=8-8
  4%|▍         | 40/1049 [01:08<36:16,  2.16s/it]INFO:__main__:Requesting https://circadia.health/
INFO:__main__:Getting metadata for https://circadia.health
  4%|▍         | 41/1049 [01:09<27:48,  1.66s/it]INFO:__main__:Requesting https://thewirecutter.com/reviews/best-sunrise-alarm-clock/
INFO:__main__:Getting metadata for https://thewirecutter.com/reviews/best-sunrise-alarm-clock/
  4%|▍         | 42/1049 [01:10<22:52,  1.36s/it]INFO:__main__:Requesting https://casper.com/glow-light/buy/
INFO:__main__:Getting metadata for https://casper.com/glow-light/buy/
  4%|▍         | 43/1049 [01:10<19:25,  1.16s/it]INFO:__main__:Requesting https://slashdot.org/story/01/10/23/1816257/apple-releases-ipod
INFO:__main__:Getting metadata for https://slashdot.org/story/01/10/23/1816257/apple-releases-ipod
  4%|▍         | 44/1049 [01:11<19:36,  1.17s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=rvlA9UxGvSg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=rvlA9UxGvSg
  4%|▍         | 45/1049 [01:12<18:39,  1.12s/it]INFO:__main__:Requesting https://bolt.io/portfolio
INFO:__main__:Getting metadata for https://bolt.io/portfolio
  4%|▍         | 46/1049 [01:13<17:26,  1.04s/it]INFO:__main__:Requesting https://theconversation.com/europes-electronic-waste-has-become-africas-burden-17123
INFO:__main__:Getting metadata for https://theconversation.com/europes-electronic-waste-has-become-africas-burden-17123
  4%|▍         | 47/1049 [01:14<17:15,  1.03s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=Xn3UraChY0c&feature=youtu.be
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=Xn3UraChY0c&feature=youtu.be
  5%|▍         | 48/1049 [01:15<16:10,  1.03it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=q7rKj0DU8Xs
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=q7rKj0DU8Xs
  5%|▍         | 49/1049 [01:16<16:06,  1.03it/s]INFO:__main__:Requesting http://www.midwinter.com/lurk/
INFO:__main__:Getting metadata for http://www.midwinter.com/lurk/
ERROR:__main__:Could not get metadata for http://www.midwinter.com/lurk/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  5%|▍         | 50/1049 [01:16<12:04,  1.38it/s]INFO:__main__:Requesting https://b5books.com/babylon-5-scripts-overview/
INFO:__main__:Getting metadata for https://b5books.com/babylon-5-scripts-overview/
  5%|▍         | 51/1049 [01:18<17:18,  1.04s/it]INFO:__main__:Requesting http://jmsnews.com
INFO:__main__:Getting metadata for http://jmsnews.com
  5%|▍         | 52/1049 [01:18<13:30,  1.23it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/NewTek#Tim_Jenison
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/NewTek#Tim_Jenison
  5%|▌         | 53/1049 [01:20<15:57,  1.04it/s]INFO:__main__:Requesting https://www.nytimes.com/2018/06/14/t-magazine/agnes-denes-art.html
INFO:__main__:Getting metadata for https://www.nytimes.com/2018/06/14/t-magazine/agnes-denes-art.html
  5%|▌         | 54/1049 [01:20<12:20,  1.34it/s]INFO:__main__:Requesting https://www.kcet.org/shows/earth-focus/field-of-dreams-the-cornfield-throughout-los-angeles-history
INFO:__main__:Getting metadata for https://www.kcet.org/shows/earth-focus/field-of-dreams-the-cornfield-throughout-los-angeles-history
  5%|▌         | 55/1049 [01:21<12:27,  1.33it/s]INFO:__main__:Requesting https://www.waituntil8th.org/blog/2018/11/12/middle-school-misfortunes-then-and-now-one-teachers-take
INFO:__main__:Getting metadata for https://www.waituntil8th.org/blog/2018/11/12/middle-school-misfortunes-then-and-now-one-teachers-take
  5%|▌         | 56/1049 [01:21<11:15,  1.47it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Children%27s_Online_Privacy_Protection_Act
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Children%27s_Online_Privacy_Protection_Act
  5%|▌         | 57/1049 [01:22<13:46,  1.20it/s]INFO:__main__:Requesting https://www.jargon.com
INFO:__main__:Getting metadata for https://www.jargon.com
ERROR:__main__:Could not get metadata for https://www.jargon.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  6%|▌         | 58/1049 [01:23<10:59,  1.50it/s]INFO:__main__:Requesting https://www.npmjs.com/package/@jargon/alexa-skill-sdk
INFO:__main__:Getting metadata for https://www.npmjs.com/package/@jargon/alexa-skill-sdk
  6%|▌         | 59/1049 [01:24<12:42,  1.30it/s]INFO:__main__:Requesting https://angel.co/jargon-com/jobs
INFO:__main__:Requesting https://datadome.co
  6%|▌         | 61/1049 [01:24<10:13,  1.61it/s]INFO:__main__:Requesting https://docs.datadome.co/
INFO:__main__:Getting metadata for https://docs.datadome.co/docs
  6%|▌         | 62/1049 [01:25<11:17,  1.46it/s]INFO:__main__:Requesting http://kipsu.io/1xc6
INFO:__main__:Getting metadata for https://kipsuinc.applytojob.com/apply/1XfOk4osa8/Senior-Software-Engineer
  6%|▌         | 63/1049 [01:27<15:41,  1.05it/s]INFO:__main__:Requesting https://formant.io
INFO:__main__:Getting metadata for https://formant.io
  6%|▌         | 64/1049 [01:27<14:53,  1.10it/s]INFO:__main__:Requesting https://angel.co/formantinc
INFO:__main__:Requesting https://userland.tech
INFO:__main__:Getting metadata for https://userland.tech
  6%|▋         | 66/1049 [01:28<11:06,  1.48it/s]INFO:__main__:Requesting https://userland.tech/jobs/
INFO:__main__:Getting metadata for https://userland.tech/jobs/
  6%|▋         | 67/1049 [01:28<08:38,  1.89it/s]INFO:__main__:Requesting https://doist.com/jobs/#web-developer
INFO:__main__:Getting metadata for https://doist.com/jobs/#web-developer
  6%|▋         | 68/1049 [01:28<07:54,  2.07it/s]INFO:__main__:Requesting https://doist.com/jobs/#senior-android-developer
INFO:__main__:Getting metadata for https://doist.com/jobs/#senior-android-developer
  7%|▋         | 69/1049 [01:29<07:18,  2.24it/s]INFO:__main__:Requesting https://doist.com/jobs/#senior-ios-developer
INFO:__main__:Getting metadata for https://doist.com/jobs/#senior-ios-developer
  7%|▋         | 70/1049 [01:29<06:53,  2.37it/s]INFO:__main__:Requesting https://blog.doist.com/
INFO:__main__:Getting metadata for https://doist.com/blog/
  7%|▋         | 71/1049 [01:30<08:22,  1.95it/s]INFO:__main__:Requesting https://www.countfire.com/careers/
INFO:__main__:Getting metadata for https://www.countfire.com/careers/
  7%|▋         | 72/1049 [01:30<07:57,  2.05it/s]INFO:__main__:Requesting https://www.codot.gov/programs/roadx
INFO:__main__:Getting metadata for https://www.codot.gov/programs/roadx
  7%|▋         | 73/1049 [01:32<14:53,  1.09it/s]INFO:__main__:Requesting http://www.aaronsw.com/weblog/dweck
INFO:__main__:Getting metadata for http://www.aaronsw.com/weblog/dweck
  7%|▋         | 74/1049 [01:32<12:34,  1.29it/s]INFO:__main__:Requesting https://ae.studio/join-us
INFO:__main__:Getting metadata for https://ae.studio/join-us
  7%|▋         | 75/1049 [01:34<14:19,  1.13it/s]INFO:__main__:Requesting https://anvil.works/jobs
INFO:__main__:Getting metadata for https://anvil.works/jobs
ERROR:__main__:Could not get metadata for https://anvil.works/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  7%|▋         | 76/1049 [01:35<14:41,  1.10it/s]INFO:__main__:Requesting https://anvil.works
INFO:__main__:Getting metadata for https://anvil.works
  7%|▋         | 77/1049 [01:37<20:56,  1.29s/it]INFO:__main__:Requesting https://anvil.works/blog/img/how-many-t-shirts/crowd.jpg
INFO:__main__:Getting metadata for https://anvil.works/blog/img/how-many-t-shirts/crowd.jpg
ERROR:__main__:Could not get metadata for https://anvil.works/blog/img/how-many-t-shirts/crowd.jpg
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  7%|▋         | 78/1049 [01:47<1:05:26,  4.04s/it]INFO:__main__:Requesting https://vanta.com
INFO:__main__:Getting metadata for https://vanta.com
ERROR:__main__:Could not get metadata for https://vanta.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  8%|▊         | 79/1049 [01:48<49:29,  3.06s/it]  INFO:__main__:Requesting https://www.keyvalues.com/vanta
INFO:__main__:Getting metadata for https://www.keyvalues.com/vanta
  8%|▊         | 80/1049 [01:49<40:33,  2.51s/it]INFO:__main__:Requesting https://vanta.com/jobs?ref=keyvalues
INFO:__main__:Getting metadata for https://vanta.com/jobs?ref=keyvalues
ERROR:__main__:Could not get metadata for https://vanta.com/jobs?ref=keyvalues
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  8%|▊         | 81/1049 [01:50<32:06,  1.99s/it]INFO:__main__:Requesting https://vanta.com/jobs/support
INFO:__main__:Getting metadata for https://vanta.com/jobs/support
ERROR:__main__:Could not get metadata for https://vanta.com/jobs/support
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  8%|▊         | 82/1049 [01:51<25:54,  1.61s/it]INFO:__main__:Requesting https://vanta.com/jobs/sales
INFO:__main__:Getting metadata for https://vanta.com/jobs/sales
ERROR:__main__:Could not get metadata for https://vanta.com/jobs/sales
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  8%|▊         | 83/1049 [01:51<21:37,  1.34s/it]INFO:__main__:Requesting https://buildeazy-gmbh.breezy.hr/p/b40d43b7641901-lead-developer-full-time--remote---munich--gmt-1-----4-hrs-difference---early-stage
INFO:__main__:Getting metadata for https://buildeazy-gmbh.breezy.hr/p/b40d43b7641901-lead-developer-full-time--remote---munich--gmt-1-----4-hrs-difference---early-stage
  8%|▊         | 84/1049 [01:53<20:33,  1.28s/it]INFO:__main__:Requesting https://jobs.amd.com/
INFO:__main__:Getting metadata for https://jobs.amd.com
  8%|▊         | 85/1049 [01:53<17:18,  1.08s/it]INFO:__main__:Requesting https://transcriptic.com
INFO:__main__:Getting metadata for https://www.transcriptic.com
  8%|▊         | 86/1049 [01:54<15:30,  1.03it/s]INFO:__main__:Requesting http://autoprotocol.org/
INFO:__main__:Getting metadata for http://autoprotocol.org
  8%|▊         | 87/1049 [01:54<13:26,  1.19it/s]INFO:__main__:Requesting https://www.transcriptic.com/hiring/?gh_jid=1092746
INFO:__main__:Getting metadata for https://www.transcriptic.com/hiring/?gh_jid=1092746
  8%|▊         | 88/1049 [01:55<11:15,  1.42it/s]INFO:__main__:Requesting https://www.transcriptic.com/hiring/?gh_jid=1236117
INFO:__main__:Getting metadata for https://www.transcriptic.com/hiring/?gh_jid=1236117
  8%|▊         | 89/1049 [01:55<09:47,  1.63it/s]INFO:__main__:Requesting https://www.transcriptic.com/hiring/?gh_jid=1535939
INFO:__main__:Getting metadata for https://www.transcriptic.com/hiring/?gh_jid=1535939
  9%|▊         | 90/1049 [01:56<08:33,  1.87it/s]INFO:__main__:Requesting https://intrinsic.com
INFO:__main__:Getting metadata for https://intrinsic.com
  9%|▊         | 91/1049 [01:56<07:45,  2.06it/s]INFO:__main__:Requesting https://intrinsic.com/product
INFO:__main__:Getting metadata for https://intrinsic.com/product
  9%|▉         | 92/1049 [01:56<07:08,  2.23it/s]INFO:__main__:Requesting https://boards.greenhouse.io/datto/jobs/1212012
INFO:__main__:Getting metadata for https://boards.greenhouse.io/datto/jobs/1212012
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/datto/jobs/1212012
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
  9%|▉         | 93/1049 [01:57<07:15,  2.19it/s]INFO:__main__:Requesting https://www.paxos.com/careers/sr-software-engineer/
INFO:__main__:Getting metadata for https://www.paxos.com/careers/sr-software-engineer/
  9%|▉         | 94/1049 [01:57<06:35,  2.41it/s]INFO:__main__:Requesting https://www.paxos.com/careers/senior-site-reliability
INFO:__main__:Getting metadata for https://www.paxos.com/careers/senior-site-reliability-engineer/
  9%|▉         | 95/1049 [01:57<06:12,  2.56it/s]INFO:__main__:Requesting https://www.paxos.com/careers/senior-front-end-engineer/
INFO:__main__:Getting metadata for https://www.paxos.com/careers/senior-front-end-engineer/
  9%|▉         | 96/1049 [01:58<05:42,  2.78it/s]INFO:__main__:Requesting https://www.paxos.com/careers/senior-product-manager-2/
  9%|▉         | 97/1049 [01:58<05:48,  2.73it/s]INFO:__main__:Requesting https://nash.io/
INFO:__main__:Getting metadata for https://nash.io
ERROR:__main__:Could not get metadata for https://nash.io
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  9%|▉         | 98/1049 [01:59<09:06,  1.74it/s]INFO:__main__:Requesting https://jobs.lever.co/nash.io/665430a0-f9a4-4cc8-8c76-fa40661e67b6
INFO:__main__:Getting metadata for https://jobs.lever.co/nash.io/665430a0-f9a4-4cc8-8c76-fa40661e67b6
  9%|▉         | 99/1049 [02:00<10:06,  1.57it/s]INFO:__main__:Requesting https://nash.io/company/about
INFO:__main__:Getting metadata for https://nash.io/company/about/index.html
ERROR:__main__:Could not get metadata for https://nash.io/company/about/index.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 10%|▉         | 100/1049 [02:01<11:36,  1.36it/s]INFO:__main__:Requesting https://nash.io/company/careers
INFO:__main__:Getting metadata for https://nash.io/company/careers/index.html
ERROR:__main__:Could not get metadata for https://nash.io/company/careers/index.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 10%|▉         | 101/1049 [02:02<12:16,  1.29it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/iopipecom
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/iopipecom
ERROR:__main__:Could not get metadata for https://hire.withgoogle.com/public/jobs/iopipecom
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 10%|▉         | 102/1049 [02:02<10:44,  1.47it/s]INFO:__main__:Requesting https://serpapi.com
INFO:__main__:Getting metadata for https://serpapi.com
 10%|▉         | 103/1049 [02:03<10:11,  1.55it/s]INFO:__main__:Requesting https://balena.io
INFO:__main__:Getting metadata for https://www.balena.io
 10%|▉         | 104/1049 [02:04<11:20,  1.39it/s]INFO:__main__:Requesting https://balena.workable.com/j/39F9C34AA8
INFO:__main__:Getting metadata for https://balena.workable.com/j/39F9C34AA8
 10%|█         | 105/1049 [02:04<10:59,  1.43it/s]INFO:__main__:Requesting https://www.shortform.io/
INFO:__main__:Getting metadata for https://www.shortform.io
ERROR:__main__:Could not get metadata for https://www.shortform.io
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 10%|█         | 106/1049 [02:05<11:14,  1.40it/s]INFO:__main__:Requesting http://scorebooklive.com
INFO:__main__:Getting metadata for https://scorebooklive.com/games
 10%|█         | 107/1049 [02:06<10:49,  1.45it/s]INFO:__main__:Requesting https://www.thorn.org
INFO:__main__:Getting metadata for https://www.thorn.org
 10%|█         | 108/1049 [02:08<20:19,  1.30s/it]INFO:__main__:Requesting https://grnh.se/d96da8052
INFO:__main__:Getting metadata for https://www.thorn.org/careers/application/?gh_jid=4131539002&gh_src=d96da8052
 10%|█         | 109/1049 [02:12<29:01,  1.85s/it]INFO:__main__:Requesting https://grnh.se/c9baa7dd2
INFO:__main__:Getting metadata for https://www.thorn.org/careers/application/?gh_jid=4131953002&gh_src=c9baa7dd2
 10%|█         | 110/1049 [02:13<28:58,  1.85s/it]INFO:__main__:Requesting https://grnh.se/35ead91b2
INFO:__main__:Getting metadata for https://www.thorn.org/careers/application/?gh_jid=4131960002&gh_src=35ead91b2
 11%|█         | 111/1049 [02:15<28:07,  1.80s/it]INFO:__main__:Requesting https://www.leolabs.space/
INFO:__main__:Getting metadata for https://www.leolabs.space
ERROR:__main__:Could not get metadata for https://www.leolabs.space
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 11%|█         | 112/1049 [02:15<20:47,  1.33s/it]INFO:__main__:Requesting https://duckduckgo.com/hiring
INFO:__main__:Getting metadata for https://duckduckgo.com/hiring/
 11%|█         | 113/1049 [02:16<16:08,  1.04s/it]INFO:__main__:Requesting https://getstride.com
ERROR:__main__:Could not reach https://getstride.com
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 80, in create_connection
    raise err
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 70, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 301, in connect
    conn = self._new_conn()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 164, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97f4046438>, 'Connection to getstride.com timed out. (connect timeout=6)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='getstride.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97f4046438>, 'Connection to getstride.com timed out. (connect timeout=6)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 504, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='getstride.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97f4046438>, 'Connection to getstride.com timed out. (connect timeout=6)'))
 11%|█         | 114/1049 [02:22<39:30,  2.54s/it]INFO:__main__:Requesting https://www.getstride.com/careers
INFO:__main__:Getting metadata for https://www.getstride.com/careers
 11%|█         | 115/1049 [02:22<28:34,  1.84s/it]INFO:__main__:Requesting https://meteopollen.com/
INFO:__main__:Getting metadata for https://meteopollen.com
 11%|█         | 116/1049 [02:23<25:06,  1.62s/it]INFO:__main__:Requesting http://www.planwithvoyant.com
INFO:__main__:Getting metadata for http://www.planwithvoyant.com
 11%|█         | 117/1049 [02:23<19:34,  1.26s/it]INFO:__main__:Requesting https://www.planwithvoyant.com/content/en_US/aboutus/javaserverdev.html
INFO:__main__:Getting metadata for https://www.planwithvoyant.com/content/en_US/aboutus/javaserverdev.html
 11%|█         | 118/1049 [02:25<19:28,  1.25s/it]INFO:__main__:Requesting https://www.planwithvoyant.com/content/en_US/aboutus/javadeveloper.html
INFO:__main__:Getting metadata for https://www.planwithvoyant.com/content/en_US/aboutus/javadeveloper.html
 11%|█▏        | 119/1049 [02:26<19:33,  1.26s/it]INFO:__main__:Requesting https://intello.io
INFO:__main__:Getting metadata for https://www.intello.io
 11%|█▏        | 120/1049 [02:27<16:48,  1.09s/it]INFO:__main__:Requesting https://root.engineering/
INFO:__main__:Getting metadata for https://root.engineering
 12%|█▏        | 121/1049 [02:27<13:55,  1.11it/s]INFO:__main__:Requesting https://www.streak.com/careers
INFO:__main__:Getting metadata for https://www.streak.com/careers
 12%|█▏        | 122/1049 [02:28<15:57,  1.03s/it]INFO:__main__:Requesting https://www.broadinstitute.org/careers/software-engineering
INFO:__main__:Getting metadata for https://www.broadinstitute.org/careers/software-engineering
 12%|█▏        | 123/1049 [02:29<13:06,  1.18it/s]INFO:__main__:Requesting https://broad.io/aou-tech-lead
INFO:__main__:Getting metadata for https://broadinstitute.wd1.myworkdayjobs.com/broad_institute/job/Cambridge-MA/Senior-Angular-Front-End-Developer_5806
ERROR:__main__:Could not get metadata for https://broadinstitute.wd1.myworkdayjobs.com/broad_institute/job/Cambridge-MA/Senior-Angular-Front-End-Developer_5806
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 12%|█▏        | 124/1049 [02:35<36:09,  2.35s/it]INFO:__main__:Requesting https://broad.io/terra-senior-eng
INFO:__main__:Getting metadata for https://broadinstitute.wd1.myworkdayjobs.com/broad_institute/job/Cambridge-MA/Front-End-Senior-Software-Engineer_7915-1
ERROR:__main__:Could not get metadata for https://broadinstitute.wd1.myworkdayjobs.com/broad_institute/job/Cambridge-MA/Front-End-Senior-Software-Engineer_7915-1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 12%|█▏        | 125/1049 [02:39<45:23,  2.95s/it]INFO:__main__:Requesting https://broad.io/engineer-gnomad
INFO:__main__:Getting metadata for https://broadinstitute.wd1.myworkdayjobs.com/en-US/broad_institute/job/Cambridge-MA/Software-Engineer---Genome-Aggregation-Database--gnomAD-_7786
ERROR:__main__:Could not get metadata for https://broadinstitute.wd1.myworkdayjobs.com/en-US/broad_institute/job/Cambridge-MA/Software-Engineer---Genome-Aggregation-Database--gnomAD-_7786
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 12%|█▏        | 126/1049 [02:43<48:15,  3.14s/it]INFO:__main__:Requesting https://www.genomenon.com
INFO:__main__:Getting metadata for https://www.genomenon.com
 12%|█▏        | 127/1049 [02:43<35:19,  2.30s/it]INFO:__main__:Requesting https://convertkit.com/mission/
INFO:__main__:Getting metadata for https://convertkit.com/mission/
 12%|█▏        | 128/1049 [02:43<25:59,  1.69s/it]INFO:__main__:Requesting https://convertkit.baremetrics.com/
INFO:__main__:Getting metadata for https://convertkit.baremetrics.com
 12%|█▏        | 129/1049 [02:44<22:05,  1.44s/it]INFO:__main__:Requesting https://nathanbarry.com/product-secrets/
INFO:__main__:Getting metadata for https://nathanbarry.com/product-secrets/
 12%|█▏        | 130/1049 [02:44<16:40,  1.09s/it]INFO:__main__:Requesting https://convertkit.com/careers/
INFO:__main__:Getting metadata for https://convertkit.com/careers/
 12%|█▏        | 131/1049 [02:45<12:53,  1.19it/s]INFO:__main__:Requesting https://jobs.lever.co/astranis
INFO:__main__:Getting metadata for https://jobs.lever.co/astranis
 13%|█▎        | 132/1049 [02:45<11:57,  1.28it/s]INFO:__main__:Requesting https://watchtower.ai
INFO:__main__:Getting metadata for https://www.watchtower.ai
 13%|█▎        | 133/1049 [02:47<15:41,  1.03s/it]INFO:__main__:Requesting https://www.watchtower.ai/careers
INFO:__main__:Getting metadata for https://www.watchtower.ai/careers
 13%|█▎        | 134/1049 [02:48<16:00,  1.05s/it]INFO:__main__:Requesting https://dealersocket.com/
INFO:__main__:Getting metadata for https://dealersocket.com
 13%|█▎        | 135/1049 [02:49<17:18,  1.14s/it]INFO:__main__:Requesting http://careers.dealersocket.com/careers-at-dealersocket.php
INFO:__main__:Getting metadata for http://careers.dealersocket.com/careers-at-dealersocket.php
 13%|█▎        | 136/1049 [02:51<17:48,  1.17s/it]INFO:__main__:Requesting https://blog.kamihq.com/iste-2018-wrap-up/
INFO:__main__:Getting metadata for https://blog.kamihq.com/iste-2018-wrap-up/
 13%|█▎        | 137/1049 [02:51<15:38,  1.03s/it]INFO:__main__:Requesting https://www.kamihq.com/careers/#frontend
INFO:__main__:Getting metadata for https://www.kamiapp.com/careers/#frontend
 13%|█▎        | 138/1049 [02:53<17:23,  1.15s/it]INFO:__main__:Requesting https://grnh.se/273a4c161
INFO:__main__:Getting metadata for https://boards.greenhouse.io/wikimedia/jobs/1436353?gh_src=273a4c161
 13%|█▎        | 139/1049 [02:53<15:02,  1.01it/s]INFO:__main__:Requesting https://wikimediafoundation.org/about
INFO:__main__:Getting metadata for https://wikimediafoundation.org/about/
 13%|█▎        | 140/1049 [02:54<15:30,  1.02s/it]INFO:__main__:Requesting https://wikitech.wikimedia.org/wiki/Help:Cloud_Services_Introduction
INFO:__main__:Getting metadata for https://wikitech.wikimedia.org/wiki/Help:Cloud_Services_Introduction
 13%|█▎        | 141/1049 [02:55<13:28,  1.12it/s]INFO:__main__:Requesting https://vimeo.com/277517881
 14%|█▎        | 142/1049 [02:55<10:01,  1.51it/s]INFO:__main__:Requesting https://vsco.co/about/careers/software-engineer-android-oakland
INFO:__main__:Getting metadata for https://vsco.co/about/careers/software-engineer-android-oakland
 14%|█▎        | 143/1049 [02:57<13:46,  1.10it/s]INFO:__main__:Requesting https://vsco.co/about/careers/ios-engineer-oakland
INFO:__main__:Getting metadata for https://vsco.co/about/careers/ios-engineer-oakland
 14%|█▎        | 144/1049 [02:58<16:52,  1.12s/it]INFO:__main__:Requesting https://vsco.co/about/careers/software-engineer-server-oakland
INFO:__main__:Getting metadata for https://vsco.co/about/careers/software-engineer-server-oakland
 14%|█▍        | 145/1049 [03:00<19:59,  1.33s/it]INFO:__main__:Requesting https://vsco.co/about/careers/engineering-manager-devops-oakland
INFO:__main__:Getting metadata for https://vsco.co/about/careers/engineering-manager-devops-oakland
 14%|█▍        | 146/1049 [03:02<20:38,  1.37s/it]INFO:__main__:Requesting https://www.rigetti.com/
INFO:__main__:Getting metadata for https://www.rigetti.com
 14%|█▍        | 147/1049 [03:02<15:22,  1.02s/it]INFO:__main__:Requesting https://bit.ly/2TqxdFv
INFO:__main__:Getting metadata for https://saf-platform.breezy.hr/p/13708aebbbf9-full-stack-engineer
 14%|█▍        | 148/1049 [03:03<17:39,  1.18s/it]INFO:__main__:Requesting https://ca.la
INFO:__main__:Getting metadata for https://ca.la
 14%|█▍        | 149/1049 [03:04<14:09,  1.06it/s]INFO:__main__:Requesting https://jobs.ca.la/engineering
INFO:__main__:Getting metadata for https://jobs.ca.la/engineering
 14%|█▍        | 150/1049 [03:04<12:06,  1.24it/s]INFO:__main__:Requesting http://info.secondstreet.com/now-hiring-front-end-dev
INFO:__main__:Getting metadata for http://info.secondstreet.com/now-hiring-front-end-dev
 14%|█▍        | 151/1049 [03:04<09:40,  1.55it/s]INFO:__main__:Requesting https://drive.secondstreet.com/our-hiring-process/
INFO:__main__:Getting metadata for https://drive.secondstreet.com/our-hiring-process/
 14%|█▍        | 152/1049 [03:05<11:14,  1.33it/s]INFO:__main__:Requesting http://www.datakitchen.io/
INFO:__main__:Getting metadata for https://www.datakitchen.io
 15%|█▍        | 153/1049 [03:07<12:46,  1.17it/s]INFO:__main__:Requesting https://www.datakitchen.io/company.html#hiring
INFO:__main__:Getting metadata for https://www.datakitchen.io/company.html#hiring
 15%|█▍        | 154/1049 [03:07<13:06,  1.14it/s]INFO:__main__:Requesting https://softwareengineeringdaily.com/2018/08/29/dataops-with-christopher-bergh/
INFO:__main__:Getting metadata for https://softwareengineeringdaily.com/2018/08/29/dataops-with-christopher-bergh/
INFO:__main__:Requesting https://youtu.be/p1c-H8NdiEA
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=p1c-H8NdiEA&feature=youtu.be
 15%|█▍        | 156/1049 [03:08<11:18,  1.32it/s]INFO:__main__:Requesting https://www.skydio.com/press/
INFO:__main__:Getting metadata for https://www.skydio.com/press/
ERROR:__main__:Could not get metadata for https://www.skydio.com/press/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 15%|█▍        | 157/1049 [03:09<09:24,  1.58it/s]INFO:__main__:Requesting https://jobs.lever.co/skydio/c9178307-300d-4681-af92-4b443d0f3082
INFO:__main__:Getting metadata for https://jobs.lever.co/skydio/c9178307-300d-4681-af92-4b443d0f3082
 15%|█▌        | 158/1049 [03:09<09:23,  1.58it/s]INFO:__main__:Requesting https://jobs.lever.co/skydio/e106a274-bc37-41c3-8500-94cde0028a85
INFO:__main__:Getting metadata for https://jobs.lever.co/skydio/e106a274-bc37-41c3-8500-94cde0028a85
 15%|█▌        | 159/1049 [03:10<09:11,  1.61it/s]INFO:__main__:Requesting https://textio.com/careers/
INFO:__main__:Getting metadata for https://textio.com/careers/
 15%|█▌        | 160/1049 [03:10<07:44,  1.91it/s]INFO:__main__:Requesting https://textio.com/team/
INFO:__main__:Getting metadata for https://textio.com/team/
 15%|█▌        | 161/1049 [03:10<06:29,  2.28it/s]INFO:__main__:Requesting https://www.secfi.com/#gif-container
INFO:__main__:Getting metadata for https://www.secfi.com/#gif-container
 15%|█▌        | 162/1049 [03:11<05:53,  2.51it/s]INFO:__main__:Requesting https://www.secfi.com/careers
INFO:__main__:Getting metadata for https://www.secfi.com/careers
 16%|█▌        | 163/1049 [03:11<06:38,  2.22it/s]INFO:__main__:Requesting https://grnh.se/317245f71
INFO:__main__:Getting metadata for https://boards.greenhouse.getrake.io/warbyparker/jobs/1512069?gh_jid=1512069&gh_src=317245f71
 16%|█▌        | 164/1049 [03:12<07:46,  1.90it/s]INFO:__main__:Requesting https://grnh.se/52e83fb61
INFO:__main__:Getting metadata for https://boards.greenhouse.getrake.io/warbyparker/jobs/1569393?gh_jid=1569393&gh_src=52e83fb61
 16%|█▌        | 165/1049 [03:13<08:13,  1.79it/s]INFO:__main__:Requesting https://grnh.se/f1406e761
INFO:__main__:Getting metadata for https://boards.greenhouse.getrake.io/warbyparker/jobs/1521784?gh_jid=1521784&gh_src=f1406e761
 16%|█▌        | 166/1049 [03:13<08:17,  1.78it/s]INFO:__main__:Requesting https://akira.md
INFO:__main__:Getting metadata for https://akira.md
 16%|█▌        | 167/1049 [03:14<07:51,  1.87it/s]INFO:__main__:Requesting https://angel.co/akira-2/jobs/106786-sr-full-stack-ruby-engineer
INFO:__main__:Requesting https://about.gitlab.com/jobs/
INFO:__main__:Getting metadata for https://about.gitlab.com/jobs/
 16%|█▌        | 169/1049 [03:14<06:08,  2.39it/s]INFO:__main__:Requesting https://about.gitlab.com/2018/03/15/working-at-gitlab-affects-my-life/
INFO:__main__:Getting metadata for https://about.gitlab.com/2018/03/15/working-at-gitlab-affects-my-life/
 16%|█▌        | 170/1049 [03:14<05:40,  2.58it/s]INFO:__main__:Requesting https://about.gitlab.com/handbook/
INFO:__main__:Getting metadata for https://about.gitlab.com/handbook/
 16%|█▋        | 171/1049 [03:15<04:48,  3.04it/s]INFO:__main__:Requesting https://boards.greenhouse.io/gitlab/jobs/4224952002
INFO:__main__:Getting metadata for https://boards.greenhouse.io/gitlab/jobs/4224952002
 16%|█▋        | 172/1049 [03:15<05:37,  2.60it/s]INFO:__main__:Requesting https://www.dialpad.com/
INFO:__main__:Getting metadata for https://www.dialpad.com
 16%|█▋        | 173/1049 [03:15<05:12,  2.80it/s]INFO:__main__:Requesting https://www.dialpad.com/jobs
INFO:__main__:Getting metadata for https://www.dialpad.com/careers/
 17%|█▋        | 174/1049 [03:16<05:25,  2.68it/s]INFO:__main__:Requesting https://www.fastly.com/
INFO:__main__:Getting metadata for https://www.fastly.com
 17%|█▋        | 175/1049 [03:16<04:34,  3.19it/s]INFO:__main__:Requesting https://www.fastly.com/about/jobs/apply?gh_jid=1523951
INFO:__main__:Getting metadata for https://www.fastly.com/about/jobs/apply?gh_jid=1523951
 17%|█▋        | 176/1049 [03:16<03:47,  3.84it/s]INFO:__main__:Requesting https://www.wellframe.com
 17%|█▋        | 177/1049 [03:16<03:55,  3.70it/s]INFO:__main__:Requesting https://jobs.lever.co/wellframe/d387f9c1-09c6-446c-991e-62c7259dafe9
INFO:__main__:Getting metadata for https://jobs.lever.co/wellframe/d387f9c1-09c6-446c-991e-62c7259dafe9
 17%|█▋        | 178/1049 [03:17<05:55,  2.45it/s]INFO:__main__:Requesting https://jobs.lever.co/wellframe/159c643b-2737-4e99-b4ce-3b3e02254e22
INFO:__main__:Getting metadata for https://jobs.lever.co/wellframe/159c643b-2737-4e99-b4ce-3b3e02254e22
ERROR:__main__:Could not get metadata for https://jobs.lever.co/wellframe/159c643b-2737-4e99-b4ce-3b3e02254e22
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 17%|█▋        | 179/1049 [03:18<06:45,  2.14it/s]INFO:__main__:Requesting https://jobs.lever.co/wellframe/56618358-cee7-4845-b824-1d17eb3f1745
INFO:__main__:Getting metadata for https://jobs.lever.co/wellframe/56618358-cee7-4845-b824-1d17eb3f1745
 17%|█▋        | 180/1049 [03:18<07:20,  1.97it/s]INFO:__main__:Requesting https://medium.com/disney-streaming
INFO:__main__:Getting metadata for https://medium.com/disney-streaming
 17%|█▋        | 181/1049 [03:19<09:55,  1.46it/s]INFO:__main__:Requesting https://casper.com/jobs/corporate?department=Technology
INFO:__main__:Getting metadata for https://casper.com/jobs/corporate/?department=Technology
 17%|█▋        | 182/1049 [03:20<10:28,  1.38it/s]INFO:__main__:Requesting http://elicitinsights.com
INFO:__main__:Getting metadata for http://elicitinsights.com
 17%|█▋        | 183/1049 [03:21<08:35,  1.68it/s]INFO:__main__:Requesting http://elicitinsights.com/job/sr-customer-technology-consultant/
INFO:__main__:Getting metadata for http://elicitinsights.com/job/sr-customer-technology-consultant/
 18%|█▊        | 184/1049 [03:21<07:42,  1.87it/s]INFO:__main__:Requesting https://oliv.ai
INFO:__main__:Getting metadata for https://oliv.ai
 18%|█▊        | 185/1049 [03:23<14:49,  1.03s/it]INFO:__main__:Requesting https://angel.co/oliv-ai/jobs
INFO:__main__:Requesting https://swissdevjobs.ch/jobs/Open-Systems-AG-Systems--DevOps-Engineer
INFO:__main__:Getting metadata for https://swissdevjobs.ch/jobs/Open-Systems-AG-Systems--DevOps-Engineer
ERROR:__main__:Could not get metadata for https://swissdevjobs.ch/jobs/Open-Systems-AG-Systems--DevOps-Engineer
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 18%|█▊        | 187/1049 [03:26<15:43,  1.09s/it]INFO:__main__:Requesting https://grnh.se/82a1da411
INFO:__main__:Getting metadata for https://boards.greenhouse.io/pivotalsoftware/jobs/1502690?gh_src=82a1da411
 18%|█▊        | 188/1049 [03:26<13:20,  1.08it/s]INFO:__main__:Requesting https://grnh.se/f697583c1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/pivotalsoftware/jobs/1498315?gh_src=f697583c1
 18%|█▊        | 189/1049 [03:27<11:57,  1.20it/s]INFO:__main__:Requesting https://www.rapid7.com/careers/jobs/
INFO:__main__:Getting metadata for https://www.rapid7.com/careers/jobs/
ERROR:__main__:Could not get metadata for https://www.rapid7.com/careers/jobs/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 18%|█▊        | 190/1049 [03:28<11:41,  1.22it/s]INFO:__main__:Requesting https://www.hipcamp.com
INFO:__main__:Getting metadata for https://www.hipcamp.com
 18%|█▊        | 191/1049 [03:28<11:38,  1.23it/s]INFO:__main__:Requesting https://www.keyvalues.com/hipcamp
INFO:__main__:Getting metadata for https://www.keyvalues.com/hipcamp
 18%|█▊        | 192/1049 [03:29<12:46,  1.12it/s]INFO:__main__:Requesting https://jobs.lever.co/hipcamp/f1612b67-2712-46c3-81b6-4ca4118e4040
INFO:__main__:Getting metadata for https://jobs.lever.co/hipcamp/f1612b67-2712-46c3-81b6-4ca4118e4040
 18%|█▊        | 193/1049 [03:30<11:30,  1.24it/s]INFO:__main__:Requesting https://jobs.lever.co/hipcamp/257b07a0-f84d-4afd-a535-ec763e3ccbe7
INFO:__main__:Getting metadata for https://jobs.lever.co/hipcamp/257b07a0-f84d-4afd-a535-ec763e3ccbe7
 18%|█▊        | 194/1049 [03:31<10:36,  1.34it/s]INFO:__main__:Requesting https://github.com/jwplayer/jwplayer
INFO:__main__:Getting metadata for https://github.com/jwplayer/jwplayer
 19%|█▊        | 195/1049 [03:32<11:33,  1.23it/s]INFO:__main__:Requesting https://www.jwplayer.com/company/careers/
INFO:__main__:Getting metadata for https://www.jwplayer.com/careers/
ERROR:__main__:Could not get metadata for https://www.jwplayer.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 19%|█▊        | 196/1049 [03:32<09:49,  1.45it/s]INFO:__main__:Requesting https://zulipchat.com/
INFO:__main__:Getting metadata for https://zulipchat.com
 19%|█▉        | 197/1049 [03:32<08:28,  1.67it/s]INFO:__main__:Requesting http://simplebet.io
INFO:__main__:Getting metadata for https://simplebet.io
 19%|█▉        | 198/1049 [03:33<07:06,  1.99it/s]INFO:__main__:Requesting https://www.here.com/
INFO:__main__:Getting metadata for https://www.here.com
 19%|█▉        | 199/1049 [03:34<11:03,  1.28it/s]INFO:__main__:Requesting https://www.linkedin.com/in/seonyoung-park-9b1b6421/
 19%|█▉        | 200/1049 [03:34<08:41,  1.63it/s]INFO:__main__:Requesting https://www.here.com/en/careers/jobs/52584/lead-engineer-sensor-and-probe-analytics-spa-team
INFO:__main__:Getting metadata for https://www.here.com/en/careers/jobs/52584/lead-engineer-sensor-and-probe-analytics-spa-team
 19%|█▉        | 201/1049 [03:35<07:15,  1.95it/s]INFO:__main__:Requesting http://invitae.com
INFO:__main__:Getting metadata for https://www.invitae.com/en/
 19%|█▉        | 202/1049 [03:37<15:22,  1.09s/it]INFO:__main__:Requesting https://www.invitae.com/en/careers/
INFO:__main__:Getting metadata for https://www.invitae.com/en/careers/
 19%|█▉        | 203/1049 [03:39<18:17,  1.30s/it]INFO:__main__:Requesting https://boards.greenhouse.io/invitae/jobs/1412977?gh_jid=1412977
INFO:__main__:Getting metadata for https://boards.greenhouse.io/invitae/jobs/1412977?gh_jid=1412977
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/invitae/jobs/1412977?gh_jid=1412977
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 19%|█▉        | 204/1049 [03:39<14:30,  1.03s/it]INFO:__main__:Requesting https://boards.greenhouse.io/invitae/jobs/1524198?gh_jid=1524198
INFO:__main__:Getting metadata for https://boards.greenhouse.io/invitae/jobs/1524198?gh_jid=1524198
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/invitae/jobs/1524198?gh_jid=1524198
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 20%|█▉        | 205/1049 [03:40<11:57,  1.18it/s]INFO:__main__:Requesting https://boards.greenhouse.io/invitae/jobs/888569?gh_jid=888569
INFO:__main__:Getting metadata for https://boards.greenhouse.io/invitae/jobs/888569?gh_jid=888569
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/invitae/jobs/888569?gh_jid=888569
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 20%|█▉        | 206/1049 [03:40<10:00,  1.40it/s]INFO:__main__:Requesting https://boards.greenhouse.io/invitae/jobs/1078223?gh_jid=1078223
 20%|█▉        | 207/1049 [03:40<08:41,  1.61it/s]INFO:__main__:Requesting https://www.voom.flights
INFO:__main__:Getting metadata for https://www.voom.flights/en
 20%|█▉        | 208/1049 [03:44<19:07,  1.36s/it]INFO:__main__:Requesting https://www.keyvalues.com/voom
INFO:__main__:Getting metadata for https://www.keyvalues.com/voom
 20%|█▉        | 209/1049 [03:45<18:55,  1.35s/it]INFO:__main__:Requesting https://grnh.se/ba1fd7e92
INFO:__main__:Getting metadata for https://www.voom.flights/careers?gh_jid=4009041002&gh_src=ba1fd7e92
 20%|██        | 210/1049 [03:47<24:13,  1.73s/it]INFO:__main__:Requesting https://grnh.se/c279ceca2
INFO:__main__:Getting metadata for https://www.voom.flights/careers?gh_jid=4009043002&gh_src=c279ceca2
 20%|██        | 211/1049 [03:50<25:28,  1.82s/it]INFO:__main__:Requesting https://grnh.se/7365f3d92
INFO:__main__:Getting metadata for https://www.voom.flights/careers?gh_jid=4122366002&gh_src=7365f3d92
 20%|██        | 212/1049 [03:51<26:00,  1.86s/it]INFO:__main__:Requesting https://alphahq.com
INFO:__main__:Getting metadata for https://alphahq.com
 20%|██        | 213/1049 [03:52<19:48,  1.42s/it]INFO:__main__:Requesting https://alphahq.workable.com/jobs/779039
INFO:__main__:Getting metadata for https://alphahq.workable.com/jobs/779039
 20%|██        | 214/1049 [03:52<16:26,  1.18s/it]INFO:__main__:Requesting https://alphahq.workable.com/jobs/854089
INFO:__main__:Getting metadata for https://alphahq.workable.com/jobs/854089
 20%|██        | 215/1049 [03:53<14:06,  1.02s/it]INFO:__main__:Requesting https://alphahq.com/careers
INFO:__main__:Getting metadata for https://alphahq.com/careers/
ERROR:__main__:Could not get metadata for https://alphahq.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 21%|██        | 216/1049 [03:54<14:03,  1.01s/it]INFO:__main__:Requesting https://www.kialo.com
INFO:__main__:Getting metadata for https://www.kialo.com
 21%|██        | 217/1049 [03:55<12:24,  1.12it/s]INFO:__main__:Requesting https://stackoverflow.com/jobs/147695/full-stack-web-developer-kialo
INFO:__main__:Getting metadata for https://stackoverflow.com/jobs/147695/full-stack-web-developer-kialo
 21%|██        | 218/1049 [03:55<10:08,  1.37it/s]INFO:__main__:Requesting https://loadimpact.com/
INFO:__main__:Getting metadata for https://loadimpact.com
 21%|██        | 219/1049 [03:56<12:40,  1.09it/s]INFO:__main__:Requesting https://loadimpacte4.applytojob.com/apply/XoLcCyVr1x/DjangoPython-Senior-Software-Engineer
INFO:__main__:Getting metadata for https://loadimpacte4.applytojob.com/apply/XoLcCyVr1x/DjangoPython-Senior-Software-Engineer
 21%|██        | 220/1049 [03:57<13:00,  1.06it/s]INFO:__main__:Requesting https://www.grain.co
INFO:__main__:Getting metadata for https://www.grain.co
ERROR:__main__:Could not get metadata for https://www.grain.co
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 21%|██        | 221/1049 [03:58<10:55,  1.26it/s]INFO:__main__:Requesting https://www.grain.co/careers
INFO:__main__:Getting metadata for https://www.grain.co/careers
ERROR:__main__:Could not get metadata for https://www.grain.co/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 21%|██        | 222/1049 [03:58<08:56,  1.54it/s]INFO:__main__:Requesting https://www.ivpn.net
INFO:__main__:Getting metadata for https://www.ivpn.net
 21%|██▏       | 223/1049 [04:00<12:50,  1.07it/s]INFO:__main__:Requesting https://thewirecutter.com/reviews/best-vpn-service/
INFO:__main__:Getting metadata for https://thewirecutter.com/reviews/best-vpn-service/
 21%|██▏       | 224/1049 [04:00<11:24,  1.21it/s]INFO:__main__:Requesting https://www.ivpn.net/why-ivpn
INFO:__main__:Getting metadata for https://www.ivpn.net/why-ivpn
 21%|██▏       | 225/1049 [04:01<12:29,  1.10it/s]INFO:__main__:Requesting https://arstechnica.com/gadgets/2018/12/testing-wireguard-with-an-early-adopter-vpn-service/
INFO:__main__:Getting metadata for https://arstechnica.com/gadgets/2018/12/testing-wireguard-with-an-early-adopter-vpn-service/
 22%|██▏       | 226/1049 [04:02<09:56,  1.38it/s]INFO:__main__:Requesting https://medium.com/@vvecsei/fighting-the-surveillance-economy-a-practical-guide-for-individuals-and-companies-cb9719fe1098
INFO:__main__:Getting metadata for https://medium.com/@vvecsei/fighting-the-surveillance-economy-a-practical-guide-for-individuals-and-companies-cb9719fe1098
 22%|██▏       | 227/1049 [04:02<09:42,  1.41it/s]INFO:__main__:Requesting https://ivpn.recruitee.com/o/staff-writer
INFO:__main__:Getting metadata for https://ivpn.recruitee.com/o/staff-writer
 22%|██▏       | 228/1049 [04:03<08:23,  1.63it/s]INFO:__main__:Requesting https://ivpn.recruitee.com/o/ui-designer
INFO:__main__:Getting metadata for https://ivpn.recruitee.com/o/ui-designer
 22%|██▏       | 229/1049 [04:03<07:16,  1.88it/s]INFO:__main__:Requesting https://www.thisisalice.com/alice-careers/
INFO:__main__:Getting metadata for https://www.thisisalice.com/alice-careers/
 22%|██▏       | 230/1049 [04:04<07:23,  1.85it/s]INFO:__main__:Requesting https://www.thisisalice.com/alice-careers/?gh_jid=4126287002
INFO:__main__:Getting metadata for https://www.thisisalice.com/alice-careers/?gh_jid=4126287002
 22%|██▏       | 231/1049 [04:04<07:25,  1.84it/s]INFO:__main__:Requesting https://www.thisisalice.com/alice-careers/?gh_jid=4206835002
INFO:__main__:Getting metadata for https://www.thisisalice.com/alice-careers/?gh_jid=4206835002
 22%|██▏       | 232/1049 [04:05<07:23,  1.84it/s]INFO:__main__:Requesting https://www.thisisalice.com/alice-careers/?gh_jid=4128028002
INFO:__main__:Getting metadata for https://www.thisisalice.com/alice-careers/?gh_jid=4128028002
 22%|██▏       | 233/1049 [04:05<07:20,  1.85it/s]INFO:__main__:Requesting https://www.thisisalice.com/alice-careers/?gh_jid=4217705002
INFO:__main__:Getting metadata for https://www.thisisalice.com/alice-careers/?gh_jid=4217705002
 22%|██▏       | 234/1049 [04:06<07:18,  1.86it/s]INFO:__main__:Requesting https://www.biggerpockets.com
INFO:__main__:Getting metadata for https://www.biggerpockets.com
ERROR:__main__:Could not get metadata for https://www.biggerpockets.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 22%|██▏       | 235/1049 [04:07<11:00,  1.23it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/biggerpocketscom/view/P_AAAAAACAAGcKW6a4VbvODl
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/biggerpocketscom/view/P_AAAAAACAAGcKW6a4VbvODl
 22%|██▏       | 236/1049 [04:08<09:43,  1.39it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/biggerpocketscom/view/P_AAAAAACAAADJV1i6e-Ig6T
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/biggerpocketscom/view/P_AAAAAACAAADJV1i6e-Ig6T
 23%|██▎       | 237/1049 [04:08<07:51,  1.72it/s]INFO:__main__:Requesting https://lsst.org
ERROR:__main__:Could not reach https://lsst.org
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 344, in connect
    ssl_context=context)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/ssl_.py", line 344, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 407, in wrap_socket
    _context=self, _session=session)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 814, in __init__
    self.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1068, in do_handshake
    self._sslobj.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='lsst.org', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='lsst.org', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))
 23%|██▎       | 238/1049 [04:08<06:21,  2.12it/s]INFO:__main__:Requesting http://ls.st/6oc
INFO:__main__:Getting metadata for https://recruiting2.ultipro.com/SPA1004AURA/JobBoard/3a88e9d0-e68e-418e-9433-d36443ba8c5b/OpportunityDetail?opportunityId=82ec7171-6f4d-4023-bf1c-20a3ffc3cfd7
ERROR:__main__:Could not get metadata for https://recruiting2.ultipro.com/SPA1004AURA/JobBoard/3a88e9d0-e68e-418e-9433-d36443ba8c5b/OpportunityDetail?opportunityId=82ec7171-6f4d-4023-bf1c-20a3ffc3cfd7
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 23%|██▎       | 239/1049 [04:11<14:37,  1.08s/it]INFO:__main__:Requesting http://jobs.adgear.com/
INFO:__main__:Getting metadata for http://jobs.adgear.com
 23%|██▎       | 240/1049 [04:12<13:12,  1.02it/s]INFO:__main__:Requesting https://jobs.lever.co/nylas/a70ace09-c1af-4022-a586-ffedd18e929a
INFO:__main__:Getting metadata for https://jobs.lever.co/nylas/a70ace09-c1af-4022-a586-ffedd18e929a
 23%|██▎       | 241/1049 [04:12<12:09,  1.11it/s]INFO:__main__:Requesting https://github.com/nylas/handbook
INFO:__main__:Getting metadata for https://github.com/nylas/handbook
 23%|██▎       | 242/1049 [04:13<11:27,  1.17it/s]INFO:__main__:Requesting https://www.woopra.com/company/careers
INFO:__main__:Getting metadata for https://www.woopra.com/company/careers
 23%|██▎       | 243/1049 [04:14<13:19,  1.01it/s]INFO:__main__:Requesting https://instructure.com/
INFO:__main__:Getting metadata for https://www.instructure.com
 23%|██▎       | 244/1049 [04:15<13:06,  1.02it/s]INFO:__main__:Requesting https://code.instructure.com/
INFO:__main__:Getting metadata for https://code.instructure.com
 23%|██▎       | 245/1049 [04:16<10:40,  1.25it/s]INFO:__main__:Requesting https://jobs.lever.co/instructure?lever-via=IQ-V_FRhae&team=Engineering
INFO:__main__:Getting metadata for https://jobs.lever.co/instructure?lever-via=IQ-V_FRhae&team=Engineering
 23%|██▎       | 246/1049 [04:16<10:19,  1.30it/s]INFO:__main__:Requesting https://jobs.target.com/job/brooklyn-park/senior-engineer-cyber-security-engineering/1118/9827943
INFO:__main__:Getting metadata for https://jobs.target.com/job/brooklyn-park/senior-engineer-cyber-security-engineering/1118/9827943
 24%|██▎       | 247/1049 [04:17<08:27,  1.58it/s]INFO:__main__:Requesting https://jobs.target.com/search-jobs/Cyber%20Security/Minneapolis%2C%20MN/1118/1/4/6252001-5037779-5029877-5037649/44x97997/-93x26384/50/2
INFO:__main__:Getting metadata for https://jobs.target.com/search-jobs/Cyber%20Security/Minneapolis%2C%20MN/1118/1/4/6252001-5037779-5029877-5037649/44x97997/-93x26384/50/2
 24%|██▎       | 248/1049 [04:17<07:48,  1.71it/s]INFO:__main__:Requesting https://www.auditboard.com/
INFO:__main__:Getting metadata for https://www.auditboard.com
ERROR:__main__:Could not get metadata for https://www.auditboard.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 24%|██▎       | 249/1049 [04:17<06:17,  2.12it/s]INFO:__main__:Requesting https://www.auditboard.com/jobs/
INFO:__main__:Getting metadata for https://www.auditboard.com/careers/
ERROR:__main__:Could not get metadata for https://www.auditboard.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 24%|██▍       | 250/1049 [04:18<05:45,  2.32it/s]INFO:__main__:Requesting https://www.paperlessparts.com/
INFO:__main__:Getting metadata for https://www.paperlessparts.com
 24%|██▍       | 251/1049 [04:18<06:03,  2.19it/s]INFO:__main__:Requesting https://www.linkedin.com/company/paperlessparts/
 24%|██▍       | 252/1049 [04:18<05:06,  2.60it/s]INFO:__main__:Requesting https://paperlessparts.bamboohr.com/jobs/view.php?id=23
INFO:__main__:Getting metadata for https://paperlessparts.bamboohr.com/jobs/view.php?id=23
 24%|██▍       | 253/1049 [04:19<06:11,  2.14it/s]INFO:__main__:Requesting https://grnh.se/b048c8491
INFO:__main__:Getting metadata for https://boards.greenhouse.io/peek/jobs/1526308?gh_src=b048c8491
 24%|██▍       | 254/1049 [04:20<06:50,  1.94it/s]INFO:__main__:Requesting https://grnh.se/bc186d791
INFO:__main__:Getting metadata for https://boards.greenhouse.io/peek/jobs/1430301?gh_src=bc186d791
 24%|██▍       | 255/1049 [04:20<07:00,  1.89it/s]INFO:__main__:Requesting https://grnh.se/5cb706351
INFO:__main__:Getting metadata for https://boards.greenhouse.io/peek/jobs/1452573?gh_src=5cb706351
 24%|██▍       | 256/1049 [04:21<06:59,  1.89it/s]INFO:__main__:Requesting https://grnh.se/25c80e8b1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/peek/jobs/1526179?gh_src=25c80e8b1
 24%|██▍       | 257/1049 [04:21<07:14,  1.82it/s]INFO:__main__:Requesting https://stackshare.io/peek/peek-stack
INFO:__main__:Getting metadata for https://stackshare.io/peek/peek-stack
 25%|██▍       | 258/1049 [04:24<14:26,  1.10s/it]INFO:__main__:Requesting http://caremessage.org
INFO:__main__:Getting metadata for https://www.caremessage.org
 25%|██▍       | 259/1049 [04:24<11:57,  1.10it/s]INFO:__main__:Requesting https://jobs.lever.co/caremessage/de00ad76-7488-4f2c-93cc-f2fe5455c123
INFO:__main__:Getting metadata for https://jobs.lever.co/caremessage/de00ad76-7488-4f2c-93cc-f2fe5455c123
 25%|██▍       | 260/1049 [04:25<10:45,  1.22it/s]INFO:__main__:Requesting https://jobs.lever.co/caremessage/6f69134f-255c-409e-a9aa-b6c1a137eb64
INFO:__main__:Getting metadata for https://jobs.lever.co/caremessage/6f69134f-255c-409e-a9aa-b6c1a137eb64
 25%|██▍       | 261/1049 [04:25<09:53,  1.33it/s]INFO:__main__:Requesting https://jobs.lever.co/caremessage/8e8cc0d1-11fc-4052-a1ea-5c2536120b17
INFO:__main__:Getting metadata for https://jobs.lever.co/caremessage/8e8cc0d1-11fc-4052-a1ea-5c2536120b17
 25%|██▍       | 262/1049 [04:26<09:17,  1.41it/s]INFO:__main__:Requesting https://jobs.lever.co/caremessage/310bf63d-1f55-4fc2-bfd9-89bb028895b0
INFO:__main__:Getting metadata for https://jobs.lever.co/caremessage/310bf63d-1f55-4fc2-bfd9-89bb028895b0
 25%|██▌       | 263/1049 [04:27<08:53,  1.47it/s]INFO:__main__:Requesting https://jobs.lever.co/caremessage/ab5d48db-8a7b-4c5a-9e63-af36db7e3fce
INFO:__main__:Getting metadata for https://jobs.lever.co/caremessage/ab5d48db-8a7b-4c5a-9e63-af36db7e3fce
 25%|██▌       | 264/1049 [04:27<08:35,  1.52it/s]INFO:__main__:Requesting https://vetspire.com
INFO:__main__:Getting metadata for https://vetspire.com
 25%|██▌       | 265/1049 [04:28<07:38,  1.71it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/vetspirecom/view/P_AAAAAAHAABwItYGm-ime-H
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/vetspirecom/view/P_AAAAAAHAABwItYGm-ime-H
 25%|██▌       | 266/1049 [04:29<09:01,  1.45it/s]INFO:__main__:Requesting https://www.factual.com/company/careers/#career
INFO:__main__:Getting metadata for https://www.factual.com/company/careers/#career
 25%|██▌       | 267/1049 [04:29<07:55,  1.65it/s]INFO:__main__:Requesting https://narrativ.com/careers#positions
INFO:__main__:Getting metadata for https://narrativ.com/careers#positions
 26%|██▌       | 268/1049 [04:30<08:17,  1.57it/s]INFO:__main__:Requesting https://www.sourceress.com/jobs
INFO:__main__:Getting metadata for https://www.sourceress.com/jobs
ERROR:__main__:Could not get metadata for https://www.sourceress.com/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 26%|██▌       | 269/1049 [04:30<07:10,  1.81it/s]INFO:__main__:Requesting https://demo.hunter2.com/demo
INFO:__main__:Getting metadata for https://demo.hunter2.com/demo/d368e0195072d14e
 26%|██▌       | 270/1049 [04:31<08:45,  1.48it/s]INFO:__main__:Requesting https://alto.com
INFO:__main__:Getting metadata for https://alto.com
 26%|██▌       | 271/1049 [04:35<23:12,  1.79s/it]INFO:__main__:Requesting https://www.keyvalues.com/alto
INFO:__main__:Getting metadata for https://www.keyvalues.com/alto
 26%|██▌       | 272/1049 [04:38<24:12,  1.87s/it]INFO:__main__:Requesting https://grnh.se/e6c446df1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/alto/jobs/737797?gh_jid=737797&gh_src=e6c446df1
 26%|██▌       | 273/1049 [04:38<18:58,  1.47s/it]INFO:__main__:Requesting https://grnh.se/90216bc61
INFO:__main__:Getting metadata for https://boards.greenhouse.io/alto/jobs/1092523?gh_jid=1092523&gh_src=90216bc61
 26%|██▌       | 274/1049 [04:39<15:23,  1.19s/it]INFO:__main__:Requesting https://grnh.se/d2dfeea21
INFO:__main__:Getting metadata for https://alto.com/careers
 26%|██▌       | 275/1049 [04:40<16:52,  1.31s/it]INFO:__main__:Requesting https://grnh.se/61e375121
INFO:__main__:Getting metadata for https://boards.greenhouse.io/alto/jobs/776829?gh_jid=776829&gh_src=61e375121
 26%|██▋       | 276/1049 [04:41<14:19,  1.11s/it]INFO:__main__:Requesting https://www.crunchbase.com/organization/lyra-health
 26%|██▋       | 277/1049 [04:41<11:00,  1.17it/s]INFO:__main__:Requesting https://jobs.lever.co/lyrahealth/af9cc838-2def-4f3f-983b-466efa5e9d68
INFO:__main__:Getting metadata for https://jobs.lever.co/lyrahealth/af9cc838-2def-4f3f-983b-466efa5e9d68
 27%|██▋       | 278/1049 [04:42<10:00,  1.28it/s]INFO:__main__:Requesting https://jobs.lever.co/lyrahealth/49a687fb-50c4-4f77-a655-8e08f65c12da
INFO:__main__:Getting metadata for https://jobs.lever.co/lyrahealth/49a687fb-50c4-4f77-a655-8e08f65c12da
 27%|██▋       | 279/1049 [04:42<09:18,  1.38it/s]INFO:__main__:Requesting https://www.kettlebellkitchen.com
INFO:__main__:Getting metadata for https://www.kettlebellkitchen.com
 27%|██▋       | 280/1049 [04:43<08:35,  1.49it/s]INFO:__main__:Requesting https://gist.github.com/silviogutierrez/4ddf150fc4abdb1e9753d0e9d58d41d4
INFO:__main__:Getting metadata for https://gist.github.com/silviogutierrez/4ddf150fc4abdb1e9753d0e9d58d41d4
 27%|██▋       | 281/1049 [04:43<08:00,  1.60it/s]INFO:__main__:Requesting https://www.lendkey.com/
INFO:__main__:Getting metadata for https://www.lendkey.com
 27%|██▋       | 282/1049 [04:44<08:16,  1.55it/s]INFO:__main__:Requesting https://www.voleon.com
INFO:__main__:Getting metadata for https://voleon.com
 27%|██▋       | 283/1049 [04:54<44:48,  3.51s/it]INFO:__main__:Requesting https://jobs.lever.co/voleon/7af8f796-e956-4438-8607-ebc63b9c2d2f?lever-via=VAkzh0MtjQ
INFO:__main__:Getting metadata for https://jobs.lever.co/voleon/7af8f796-e956-4438-8607-ebc63b9c2d2f?lever-via=VAkzh0MtjQ
 27%|██▋       | 284/1049 [04:55<33:36,  2.64s/it]INFO:__main__:Requesting https://jobs.lever.co/voleon?lever-via=VAkzh0MtjQ
INFO:__main__:Getting metadata for https://jobs.lever.co/voleon?lever-via=VAkzh0MtjQ
 27%|██▋       | 285/1049 [04:56<26:38,  2.09s/it]INFO:__main__:Requesting https://citrine.io/
INFO:__main__:Getting metadata for https://citrine.io
 27%|██▋       | 286/1049 [04:56<20:25,  1.61s/it]INFO:__main__:Requesting https://citrine.io/careers/#senior-backend-software-engineer
INFO:__main__:Getting metadata for https://citrine.io/careers/#senior-backend-software-engineer
 27%|██▋       | 287/1049 [04:57<16:25,  1.29s/it]INFO:__main__:Requesting https://citrine.io/careers/
INFO:__main__:Getting metadata for https://citrine.io/careers/
 27%|██▋       | 288/1049 [04:57<13:36,  1.07s/it]INFO:__main__:Requesting https://careers-interactivebrokers.icims.com/jobs/1806/programmer---compliance-technology/job?mobile=false&width=875&height=500&bga=true&needsRedirect=false&jan1offset=-300&jun1offset=-240
INFO:__main__:Getting metadata for https://careers-interactivebrokers.icims.com/jobs/1806/programmer---compliance-technology/job?mobile=false&width=875&height=500&bga=true&needsRedirect=false&jan1offset=-300&jun1offset=-240
ERROR:__main__:Could not get metadata for https://careers-interactivebrokers.icims.com/jobs/1806/programmer---compliance-technology/job?mobile=false&width=875&height=500&bga=true&needsRedirect=false&jan1offset=-300&jun1offset=-240
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 28%|██▊       | 289/1049 [04:58<12:29,  1.01it/s]INFO:__main__:Requesting https://pro.benzinga.com
INFO:__main__:Getting metadata for https://pro.benzinga.com
 28%|██▊       | 290/1049 [04:59<11:33,  1.09it/s]INFO:__main__:Requesting https://benzinga.com
INFO:__main__:Getting metadata for https://www.benzinga.com
ERROR:__main__:Could not get metadata for https://www.benzinga.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 28%|██▊       | 291/1049 [04:59<10:49,  1.17it/s]INFO:__main__:Requesting http://jobs.benzinga.com
INFO:__main__:Getting metadata for http://jobs.benzinga.com
 28%|██▊       | 292/1049 [05:00<09:34,  1.32it/s]INFO:__main__:Requesting https://www.xtxmarkets.com/
INFO:__main__:Getting metadata for https://www.xtxmarkets.com
 28%|██▊       | 293/1049 [05:01<08:43,  1.44it/s]INFO:__main__:Requesting https://careers.kogan.com/software-devs-engineering/
INFO:__main__:Getting metadata for https://careers.kogan.com/software-devs-engineering/
ERROR:__main__:Could not get metadata for https://careers.kogan.com/software-devs-engineering/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 28%|██▊       | 294/1049 [05:01<09:04,  1.39it/s]INFO:__main__:Requesting https://github.com/kogan/eClaire
INFO:__main__:Getting metadata for https://github.com/kogan/eClaire
 28%|██▊       | 295/1049 [05:03<11:29,  1.09it/s]INFO:__main__:Requesting https://devblog.kogan.com/
INFO:__main__:Getting metadata for https://devblog.kogan.com
 28%|██▊       | 296/1049 [05:04<11:05,  1.13it/s]INFO:__main__:Requesting https://www.aclima.io
INFO:__main__:Getting metadata for https://aclima.io
 28%|██▊       | 297/1049 [05:05<13:06,  1.05s/it]INFO:__main__:Requesting https://jobs.aclima.io/
INFO:__main__:Getting metadata for https://jobs.aclima.io
 28%|██▊       | 298/1049 [05:05<11:07,  1.12it/s]INFO:__main__:Requesting https://news.ycombinator.com/user?id=igor47
INFO:__main__:Getting metadata for https://news.ycombinator.com/user?id=igor47
ERROR:__main__:Could not get metadata for https://news.ycombinator.com/user?id=igor47
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 29%|██▊       | 299/1049 [05:08<17:45,  1.42s/it]INFO:__main__:Requesting https://www.comscore.com/About/Careers/Job-Opportunities?sfid=21440
INFO:__main__:Getting metadata for https://www.comscore.com/About/Careers/Job-Opportunities?sfid=21440
 29%|██▊       | 300/1049 [05:11<22:40,  1.82s/it]INFO:__main__:Requesting https://up.codes
INFO:__main__:Getting metadata for https://up.codes
 29%|██▊       | 301/1049 [05:11<17:43,  1.42s/it]INFO:__main__:Requesting https://up.codes/careers
INFO:__main__:Getting metadata for https://up.codes/careers
 29%|██▉       | 302/1049 [05:12<13:51,  1.11s/it]INFO:__main__:Requesting https://www.cointracker.io
INFO:__main__:Getting metadata for https://www.cointracker.io
 29%|██▉       | 303/1049 [05:12<11:50,  1.05it/s]INFO:__main__:Requesting https://angel.co/cointracker/jobs/444855-full-stack-software-engineer
INFO:__main__:Requesting https://jobs.lever.co/pachyderm/
INFO:__main__:Getting metadata for https://jobs.lever.co/pachyderm/
 29%|██▉       | 305/1049 [05:13<09:32,  1.30it/s]INFO:__main__:Requesting http://www.Gastrograph.com/
INFO:__main__:Getting metadata for https://www.gastrograph.com
 29%|██▉       | 306/1049 [05:14<09:10,  1.35it/s]INFO:__main__:Requesting https://www.justwatch.com/us/talent
INFO:__main__:Getting metadata for https://www.justwatch.com/us/talent
ERROR:__main__:Could not get metadata for https://www.justwatch.com/us/talent
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 29%|██▉       | 307/1049 [05:15<10:10,  1.22it/s]INFO:__main__:Requesting https://dialbot.co/
INFO:__main__:Getting metadata for https://dialbot.co
 29%|██▉       | 308/1049 [05:15<07:50,  1.57it/s]INFO:__main__:Requesting https://www.instana.com/
INFO:__main__:Getting metadata for https://www.instana.com
 29%|██▉       | 309/1049 [05:17<12:14,  1.01it/s]INFO:__main__:Requesting https://happyfuncorp.com
INFO:__main__:Getting metadata for https://happyfuncorp.com
 30%|██▉       | 310/1049 [05:17<10:47,  1.14it/s]INFO:__main__:Requesting https://signal.org
INFO:__main__:Getting metadata for https://signal.org
ERROR:__main__:Could not get metadata for https://signal.org
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 30%|██▉       | 311/1049 [05:18<11:25,  1.08it/s]INFO:__main__:Requesting https://www.keyvalues.com/signal
ERROR:__main__:Could not reach https://www.keyvalues.com/signal
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.keyvalues.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.keyvalues.com', port=443): Read timed out. (read timeout=6)
 30%|██▉       | 312/1049 [05:24<30:19,  2.47s/it]INFO:__main__:Requesting https://jobs.lever.co/signal/2a5fee8b-5875-46d4-a41d-773a28a6b553
INFO:__main__:Getting metadata for https://jobs.lever.co/signal/2a5fee8b-5875-46d4-a41d-773a28a6b553
 30%|██▉       | 313/1049 [05:25<23:20,  1.90s/it]INFO:__main__:Requesting https://jobs.lever.co/signal/cc2a16be-b9aa-496e-ba2c-cf8ba3672267
INFO:__main__:Getting metadata for https://jobs.lever.co/signal/cc2a16be-b9aa-496e-ba2c-cf8ba3672267
 30%|██▉       | 314/1049 [05:26<18:31,  1.51s/it]INFO:__main__:Requesting https://jobs.lever.co/signal/6cbff26c-290a-4e74-a56f-78e9783f3f90
INFO:__main__:Getting metadata for https://jobs.lever.co/signal/6cbff26c-290a-4e74-a56f-78e9783f3f90
 30%|███       | 315/1049 [05:26<15:24,  1.26s/it]INFO:__main__:Requesting https://jobs.lever.co/signal/5d866dff-b979-4a90-9a53-f581eee730d0
INFO:__main__:Getting metadata for https://jobs.lever.co/signal/5d866dff-b979-4a90-9a53-f581eee730d0
 30%|███       | 316/1049 [05:27<12:56,  1.06s/it]INFO:__main__:Requesting https://www.tesorio.com/careers/
INFO:__main__:Getting metadata for https://www.tesorio.com/careers/
 30%|███       | 317/1049 [05:27<10:42,  1.14it/s]INFO:__main__:Requesting http://jobs.cj.com/jobs/category/engineering/
ERROR:__main__:Could not reach http://jobs.cj.com/jobs/category/engineering/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 344, in connect
    ssl_context=context)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/ssl_.py", line 344, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 407, in wrap_socket
    _context=self, _session=session)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 814, in __init__
    self.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1068, in do_handshake
    self._sslobj.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='jobs.cj.com', port=443): Max retries exceeded with url: /jobs/category/engineering/ (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 247, in resolve_redirects
    **adapter_kwargs
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='jobs.cj.com', port=443): Max retries exceeded with url: /jobs/category/engineering/ (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))
 30%|███       | 318/1049 [05:28<08:31,  1.43it/s]INFO:__main__:Requesting https://engineering.cj.com
INFO:__main__:Getting metadata for https://engineering.cj.com
ERROR:__main__:Could not get metadata for https://engineering.cj.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 30%|███       | 319/1049 [05:28<07:52,  1.54it/s]INFO:__main__:Requesting https://github.com/cjdev
INFO:__main__:Getting metadata for https://github.com/cjdev
 31%|███       | 320/1049 [05:29<09:32,  1.27it/s]INFO:__main__:Requesting https://faithlife.com/jobs/SeniorFaithlifeFullStackSoftwareDeveloper
INFO:__main__:Getting metadata for https://faithlife.com/jobs/SeniorFaithlifeFullStackSoftwareDeveloper
ERROR:__main__:Could not get metadata for https://faithlife.com/jobs/SeniorFaithlifeFullStackSoftwareDeveloper
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 31%|███       | 321/1049 [05:31<12:54,  1.06s/it]INFO:__main__:Requesting https://faithlife.com/careers
INFO:__main__:Getting metadata for https://faithlife.com/careers
ERROR:__main__:Could not get metadata for https://faithlife.com/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 31%|███       | 322/1049 [05:33<14:33,  1.20s/it]INFO:__main__:Requesting https://promptworks.com/
INFO:__main__:Getting metadata for https://www.promptworks.com
 31%|███       | 323/1049 [05:33<12:05,  1.00it/s]INFO:__main__:Requesting https://www.promptworks.com/jobs
INFO:__main__:Getting metadata for https://www.promptworks.com/jobs
 31%|███       | 324/1049 [05:33<09:51,  1.23it/s]INFO:__main__:Requesting http://www.metabase.com/
INFO:__main__:Getting metadata for https://www.metabase.com
 31%|███       | 325/1049 [05:34<09:06,  1.32it/s]INFO:__main__:Requesting http://www.metabase.com/jobs
INFO:__main__:Getting metadata for https://www.metabase.com/jobs/
 31%|███       | 326/1049 [05:34<07:36,  1.58it/s]INFO:__main__:Requesting https://nanovms.com
INFO:__main__:Getting metadata for https://nanovms.com
 31%|███       | 327/1049 [05:36<09:56,  1.21it/s]INFO:__main__:Requesting https://www.scruff.com
INFO:__main__:Getting metadata for https://www.scruff.com
 31%|███▏      | 328/1049 [05:36<07:33,  1.59it/s]INFO:__main__:Requesting https://www.scruff.com/en/careers/tl
INFO:__main__:Getting metadata for https://www.scruff.com/en/careers/tl
 31%|███▏      | 329/1049 [05:36<05:45,  2.08it/s]INFO:__main__:Requesting https://ecometrica.com/about-us/careers/python-developer/
INFO:__main__:Getting metadata for https://ecometrica.com/about-us/careers/python-developer
ERROR:__main__:Could not get metadata for https://ecometrica.com/about-us/careers/python-developer
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 31%|███▏      | 330/1049 [05:38<10:59,  1.09it/s]INFO:__main__:Requesting https://ecometrica.com/about-us/careers/python-developer
INFO:__main__:Getting metadata for https://ecometrica.com/about-us/careers/python-developer
ERROR:__main__:Could not get metadata for https://ecometrica.com/about-us/careers/python-developer
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 32%|███▏      | 331/1049 [05:39<12:43,  1.06s/it]INFO:__main__:Requesting https://smapiot.com
INFO:__main__:Getting metadata for https://www.smapiot.com/en/
 32%|███▏      | 332/1049 [05:43<23:36,  1.98s/it]INFO:__main__:Requesting https://newknowledge.com/
INFO:__main__:Getting metadata for https://www.newknowledge.com
 32%|███▏      | 333/1049 [05:44<18:27,  1.55s/it]INFO:__main__:Requesting https://tcrn.ch/2Pfuw6X
ERROR:__main__:Could not reach https://tcrn.ch/2Pfuw6X
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 247, in resolve_redirects
    **adapter_kwargs
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 32%|███▏      | 334/1049 [05:44<14:21,  1.21s/it]INFO:__main__:Requesting https://grnh.se/43037c332
INFO:__main__:Getting metadata for https://boards.greenhouse.io/newknowledge?gh_src=43037c332
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/newknowledge?gh_src=43037c332
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 32%|███▏      | 335/1049 [05:45<12:08,  1.02s/it]INFO:__main__:Requesting https://www.centro.net
INFO:__main__:Getting metadata for https://www.centro.net
 32%|███▏      | 336/1049 [05:45<09:19,  1.27it/s]INFO:__main__:Requesting https://centro.wd5.myworkdayjobs.com/en-US/Centro/job/Toronto/SOFTWARE-ENGINEER--APPLICATIONS_R2923
INFO:__main__:Getting metadata for https://centro.wd5.myworkdayjobs.com/en-US/Centro/job/Toronto/SOFTWARE-ENGINEER--APPLICATIONS_R2923
ERROR:__main__:Could not get metadata for https://centro.wd5.myworkdayjobs.com/en-US/Centro/job/Toronto/SOFTWARE-ENGINEER--APPLICATIONS_R2923
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 32%|███▏      | 337/1049 [05:50<23:04,  1.95s/it]INFO:__main__:Requesting https://www.opslevel.com
INFO:__main__:Getting metadata for https://www.opslevel.com
 32%|███▏      | 338/1049 [05:51<21:18,  1.80s/it]INFO:__main__:Requesting https://www.confidentcannabis.com
INFO:__main__:Getting metadata for https://confidentcannabis.com
 32%|███▏      | 339/1049 [05:51<15:25,  1.30s/it]INFO:__main__:Requesting https://www.enshohealth.com
INFO:__main__:Getting metadata for https://www.enshohealth.com
ERROR:__main__:Could not get metadata for https://www.enshohealth.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 32%|███▏      | 340/1049 [05:54<18:16,  1.55s/it]INFO:__main__:Requesting http://www.workday.com
INFO:__main__:Getting metadata for https://www.workday.com
 33%|███▎      | 341/1049 [05:55<18:50,  1.60s/it]INFO:__main__:Requesting https://grnh.se/5c2325d71
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580232&gh_src=5c2325d71
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580232&gh_src=5c2325d71
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 342/1049 [05:56<17:07,  1.45s/it]INFO:__main__:Requesting https://grnh.se/1f133cdb1
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580229&gh_src=1f133cdb1
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580229&gh_src=1f133cdb1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 343/1049 [05:57<15:18,  1.30s/it]INFO:__main__:Requesting https://grnh.se/22c529821
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580227&gh_src=22c529821
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580227&gh_src=22c529821
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 344/1049 [05:58<13:55,  1.18s/it]INFO:__main__:Requesting https://grnh.se/3a548cc31
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580213&gh_src=3a548cc31
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580213&gh_src=3a548cc31
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 345/1049 [05:59<13:03,  1.11s/it]INFO:__main__:Requesting https://grnh.se/8f4490261
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580224&gh_src=8f4490261
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580224&gh_src=8f4490261
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 346/1049 [06:00<13:13,  1.13s/it]INFO:__main__:Requesting https://grnh.se/619bbb561
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580228&gh_src=619bbb561
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580228&gh_src=619bbb561
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 347/1049 [06:01<12:55,  1.10s/it]INFO:__main__:Requesting https://grnh.se/9cd139de1
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580225&gh_src=9cd139de1
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580225&gh_src=9cd139de1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 348/1049 [06:02<12:27,  1.07s/it]INFO:__main__:Requesting https://grnh.se/230f5df71
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580231&gh_src=230f5df71
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580231&gh_src=230f5df71
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 349/1049 [06:03<12:12,  1.05s/it]INFO:__main__:Requesting https://routific.com
INFO:__main__:Getting metadata for https://routific.com
 33%|███▎      | 350/1049 [06:04<09:26,  1.23it/s]INFO:__main__:Requesting https://www.keyvalues.com/routific
INFO:__main__:Getting metadata for https://www.keyvalues.com/routific
 33%|███▎      | 351/1049 [06:11<32:36,  2.80s/it]INFO:__main__:Requesting https://angel.co/routific/jobs/376543-lead-software-engineer
INFO:__main__:Requesting https://angel.co/routific/jobs/454028-front-end-engineer
 34%|███▎      | 353/1049 [06:11<23:03,  1.99s/it]INFO:__main__:Requesting https://blueprintpower.com
INFO:__main__:Getting metadata for https://www.blueprintpower.com
 34%|███▎      | 354/1049 [06:13<20:30,  1.77s/it]INFO:__main__:Requesting https://www.elationhealth.com/careers/
INFO:__main__:Getting metadata for https://www.elationhealth.com/careers/
 34%|███▍      | 355/1049 [06:13<15:03,  1.30s/it]INFO:__main__:Requesting https://leantaas.com/about/careers/
INFO:__main__:Getting metadata for https://leantaas.com/about/careers/
 34%|███▍      | 356/1049 [06:13<11:18,  1.02it/s]INFO:__main__:Requesting https://hellosign.io
INFO:__main__:Getting metadata for https://hellosign.io
 34%|███▍      | 357/1049 [06:14<11:07,  1.04it/s]INFO:__main__:Requesting https://jobs.lever.co/hellosign/162c2a62-8fa7-4c7e-a4ec-975d4e00a2f7
INFO:__main__:Getting metadata for https://jobs.lever.co/hellosign/162c2a62-8fa7-4c7e-a4ec-975d4e00a2f7
 34%|███▍      | 358/1049 [06:15<09:56,  1.16it/s]INFO:__main__:Requesting https://discordapp.com/jobs/4006662002
INFO:__main__:Getting metadata for https://discordapp.com/jobs/4006662002
 34%|███▍      | 359/1049 [06:15<07:34,  1.52it/s]INFO:__main__:Requesting https://jobs.lever.co/drchrono/41480df6-6786-442a-b500-350a8320b141?lever-origin=applied&lever-source%5B%5D=hackernews%20march2019%20who%20is%20hiring%20thread
INFO:__main__:Getting metadata for https://jobs.lever.co/drchrono/41480df6-6786-442a-b500-350a8320b141?lever-origin=applied&lever-source%5B%5D=hackernews%20march2019%20who%20is%20hiring%20thread
 34%|███▍      | 360/1049 [06:16<08:04,  1.42it/s]INFO:__main__:Requesting https://jobs.lever.co/drchrono/c93b79f7-e8bc-409b-999d-2b2b5935af60?lever-origin=applied&lever-source%5B%5D=hackernews%20march2019%20hiring%20thread
INFO:__main__:Getting metadata for https://jobs.lever.co/drchrono/c93b79f7-e8bc-409b-999d-2b2b5935af60?lever-origin=applied&lever-source%5B%5D=hackernews%20march2019%20hiring%20thread
 34%|███▍      | 361/1049 [06:16<07:44,  1.48it/s]INFO:__main__:Requesting https://jobs.lever.co/drchrono/d9891070-0a99-4207-b72a-d26e92bdcc58?lever-origin=applied&lever-source%5B%5D=hackernews%20march%202019%20who%20is%20hiring
INFO:__main__:Getting metadata for https://jobs.lever.co/drchrono/d9891070-0a99-4207-b72a-d26e92bdcc58?lever-origin=applied&lever-source%5B%5D=hackernews%20march%202019%20who%20is%20hiring
 35%|███▍      | 362/1049 [06:17<07:26,  1.54it/s]INFO:__main__:Requesting https://jobs.lever.co/drchrono/2962f03d-2c1a-4f3d-a6bf-c9c4e8358e31?lever-origin=applied&lever-source%5B%5D=hackernews%20march%202019%20who%20is%20hiring
INFO:__main__:Getting metadata for https://jobs.lever.co/drchrono/2962f03d-2c1a-4f3d-a6bf-c9c4e8358e31?lever-origin=applied&lever-source%5B%5D=hackernews%20march%202019%20who%20is%20hiring
 35%|███▍      | 363/1049 [06:17<07:28,  1.53it/s]INFO:__main__:Requesting https://www.merantix.com
INFO:__main__:Getting metadata for https://www.merantix.com
 35%|███▍      | 364/1049 [06:19<09:46,  1.17it/s]INFO:__main__:Requesting https://merantix.bamboohr.co.uk/jobs/
INFO:__main__:Getting metadata for https://merantix.bamboohr.co.uk/jobs/
 35%|███▍      | 365/1049 [06:20<12:24,  1.09s/it]INFO:__main__:Requesting https://grnh.se/e5301f7f2
INFO:__main__:Getting metadata for https://boards.greenhouse.io/bitmex/jobs/4087164002?gh_src=e5301f7f2
 35%|███▍      | 366/1049 [06:21<10:50,  1.05it/s]INFO:__main__:Requesting https://grnh.se/499fb4222
INFO:__main__:Getting metadata for https://boards.greenhouse.io/bitmex/jobs/4031256002?gh_src=499fb4222
 35%|███▍      | 367/1049 [06:22<09:34,  1.19it/s]INFO:__main__:Requesting http://jobs.jobvite.com/careers/veeva/job/ojWw8fwD?__jvst=JobBoard&__jvsd=Hacker_News
INFO:__main__:Getting metadata for http://jobs.jobvite.com/careers/veeva/job/ojWw8fwD?__jvst=JobBoard&__jvsd=Hacker_News
 35%|███▌      | 368/1049 [06:22<07:30,  1.51it/s]INFO:__main__:Requesting https://paige.ai/careers
INFO:__main__:Getting metadata for https://paige.ai/careers
 35%|███▌      | 369/1049 [06:22<07:05,  1.60it/s]INFO:__main__:Requesting https://sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=25632&siteid=5649&Areq=672673BR&CODES=US_INT_INDEED_PD#jobDetails=2811103_5649
INFO:__main__:Getting metadata for https://sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=25632&siteid=5649&Areq=672673BR&CODES=US_INT_INDEED_PD#jobDetails=2811103_5649
ERROR:__main__:Could not get metadata for https://sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=25632&siteid=5649&Areq=672673BR&CODES=US_INT_INDEED_PD#jobDetails=2811103_5649
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 35%|███▌      | 370/1049 [06:24<09:32,  1.19it/s]INFO:__main__:Requesting https://maven-clinic.workable.com/
INFO:__main__:Getting metadata for https://maven-clinic.workable.com
ERROR:__main__:Could not get metadata for https://maven-clinic.workable.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 35%|███▌      | 371/1049 [06:24<09:00,  1.25it/s]INFO:__main__:Requesting https://www.mavenclinic.com/press
INFO:__main__:Getting metadata for https://www.mavenclinic.com/press
INFO:__main__:Requesting https://www.verishop.com/
INFO:__main__:Getting metadata for https://www.verishop.com
 36%|███▌      | 373/1049 [06:25<07:16,  1.55it/s]INFO:__main__:Requesting https://boards.greenhouse.io/verishop
INFO:__main__:Getting metadata for https://boards.greenhouse.io/verishop
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/verishop
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 36%|███▌      | 374/1049 [06:25<06:23,  1.76it/s]INFO:__main__:Requesting https://twine.com/jobs/
INFO:__main__:Getting metadata for https://twine.com/jobs/
 36%|███▌      | 375/1049 [06:25<04:52,  2.30it/s]INFO:__main__:Requesting https://itunes.apple.com/us/app/twine-easy-saving-investing/id1292080056?mt=8
INFO:__main__:Getting metadata for https://itunes.apple.com/us/app/twine-easy-saving-investing/id1292080056?mt=8
 36%|███▌      | 376/1049 [06:26<06:49,  1.64it/s]INFO:__main__:Requesting https://www.abine.com/
ERROR:__main__:Could not reach https://www.abine.com/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.abine.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 247, in resolve_redirects
    **adapter_kwargs
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.abine.com', port=443): Read timed out. (read timeout=6)
 36%|███▌      | 377/1049 [06:33<25:29,  2.28s/it]INFO:__main__:Requesting https://www.sigmaiq.com/
INFO:__main__:Getting metadata for https://www.sigmaiq.com
 36%|███▌      | 378/1049 [06:34<20:50,  1.86s/it]INFO:__main__:Requesting https://www.sigmaiq.com/careers
INFO:__main__:Getting metadata for https://www.sigmaiq.com/careers
 36%|███▌      | 379/1049 [06:34<15:35,  1.40s/it]INFO:__main__:Requesting https://www.intersection.com
INFO:__main__:Getting metadata for https://www.intersection.com
 36%|███▌      | 380/1049 [06:35<16:12,  1.45s/it]INFO:__main__:Requesting https://rebrand.ly/ixnjobs
INFO:__main__:Getting metadata for https://boards.greenhouse.io/intersection?gh_src=be100a9b1
 36%|███▋      | 381/1049 [06:36<13:42,  1.23s/it]INFO:__main__:Requesting https://lumen5.com
INFO:__main__:Getting metadata for https://lumen5.com
 36%|███▋      | 382/1049 [06:37<10:42,  1.04it/s]INFO:__main__:Requesting https://lumen5.workable.com/j/982A995E5D
INFO:__main__:Getting metadata for https://lumen5.workable.com/j/982A995E5D
 37%|███▋      | 383/1049 [06:37<09:32,  1.16it/s]INFO:__main__:Requesting https://lumen5.workable.com/j/964B167919
INFO:__main__:Getting metadata for https://lumen5.workable.com/j/964B167919
 37%|███▋      | 384/1049 [06:38<08:18,  1.33it/s]INFO:__main__:Requesting https://reasi.com
ERROR:__main__:Could not reach https://reasi.com
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 344, in connect
    ssl_context=context)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/ssl_.py", line 344, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 407, in wrap_socket
    _context=self, _session=session)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 814, in __init__
    self.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1068, in do_handshake
    self._sslobj.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='reasi.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='reasi.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))
 37%|███▋      | 385/1049 [06:38<06:19,  1.75it/s]INFO:__main__:Requesting https://www.righthandrobotics.com/
INFO:__main__:Getting metadata for https://www.righthandrobotics.com
 37%|███▋      | 386/1049 [06:40<10:36,  1.04it/s]INFO:__main__:Requesting http://tenstorrent.com
INFO:__main__:Getting metadata for http://tenstorrent.com
 37%|███▋      | 387/1049 [06:40<08:41,  1.27it/s]INFO:__main__:Requesting http://www.tenstorrent.com/careers.html
INFO:__main__:Getting metadata for http://www.tenstorrent.com/careers.html
 37%|███▋      | 388/1049 [06:40<07:28,  1.47it/s]INFO:__main__:Requesting https://www.h5mag.com/
INFO:__main__:Getting metadata for https://www.h5mag.com
 37%|███▋      | 389/1049 [06:43<13:06,  1.19s/it]INFO:__main__:Requesting https://www.h5mag.com/jobs
INFO:__main__:Getting metadata for https://www.h5mag.com/jobs
 37%|███▋      | 390/1049 [06:45<17:13,  1.57s/it]INFO:__main__:Requesting https://sysdig.com/jobs/
INFO:__main__:Getting metadata for https://sysdig.com/jobs/
ERROR:__main__:Could not get metadata for https://sysdig.com/jobs/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 37%|███▋      | 391/1049 [06:45<12:29,  1.14s/it]INFO:__main__:Requesting https://grnh.se/ab298b881
INFO:__main__:Getting metadata for https://boards.greenhouse.io/sysdig/jobs/1564554?gh_src=ab298b881
 37%|███▋      | 392/1049 [06:46<10:56,  1.00it/s]INFO:__main__:Requesting https://www.clearvoice.com
INFO:__main__:Getting metadata for https://www.clearvoice.com
 37%|███▋      | 393/1049 [06:46<08:41,  1.26it/s]INFO:__main__:Requesting https://clearvoice.workable.com/j/B2A0B579A0
INFO:__main__:Getting metadata for https://clearvoice.workable.com/j/B2A0B579A0
 38%|███▊      | 394/1049 [06:47<08:07,  1.34it/s]INFO:__main__:Requesting https://formassembly.workable.com
INFO:__main__:Getting metadata for https://formassembly.workable.com
ERROR:__main__:Could not get metadata for https://formassembly.workable.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 38%|███▊      | 395/1049 [06:48<07:29,  1.45it/s]INFO:__main__:Requesting https://www.formassembly.com/blog/remote-jobs/
INFO:__main__:Getting metadata for https://www.formassembly.com/blog/remote-jobs/
 38%|███▊      | 396/1049 [06:50<13:53,  1.28s/it]INFO:__main__:Requesting https://jobs.lever.co/rescale
INFO:__main__:Getting metadata for https://jobs.lever.co/rescale
 38%|███▊      | 397/1049 [06:51<12:07,  1.12s/it]INFO:__main__:Requesting https://purelabs.io
INFO:__main__:Getting metadata for https://purelabs.io
 38%|███▊      | 398/1049 [06:52<12:21,  1.14s/it]INFO:__main__:Requesting http://jobs.purelabs.io
INFO:__main__:Getting metadata for http://jobs.purelabs.io
 38%|███▊      | 399/1049 [06:53<10:31,  1.03it/s]INFO:__main__:Requesting https://www.plated.com/careers
INFO:__main__:Getting metadata for https://www.plated.com/careers
 38%|███▊      | 400/1049 [06:53<09:07,  1.19it/s]INFO:__main__:Requesting https://grnh.se/56c2c14f1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1322558?gh_jid=1322558&gh_src=56c2c14f1
 38%|███▊      | 401/1049 [06:54<08:17,  1.30it/s]INFO:__main__:Requesting https://grnh.se/4a7949431
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1223519?gh_jid=1223519&gh_src=4a7949431
 38%|███▊      | 402/1049 [06:54<07:31,  1.43it/s]INFO:__main__:Requesting https://grnh.se/rh1uey1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/470002?gh_jid=470002&gh_src=rh1uey1
 38%|███▊      | 403/1049 [06:55<06:58,  1.54it/s]INFO:__main__:Requesting https://grnh.se/qn7v6a1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1006253?gh_jid=1006253&gh_src=qn7v6a1
 39%|███▊      | 404/1049 [06:56<06:53,  1.56it/s]INFO:__main__:Requesting https://grnh.se/h4psfq1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/76998?gh_jid=76998&gh_src=h4psfq1
 39%|███▊      | 405/1049 [06:56<06:57,  1.54it/s]INFO:__main__:Requesting https://grnh.se/435ca3b81
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1451341?gh_jid=1451341&gh_src=435ca3b81
 39%|███▊      | 406/1049 [06:57<06:39,  1.61it/s]INFO:__main__:Requesting https://grnh.se/a6888fb31
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1477155?gh_jid=1477155&gh_src=a6888fb31
 39%|███▉      | 407/1049 [06:57<06:35,  1.62it/s]INFO:__main__:Requesting https://www.braze.com/perspectives/tag/building-braze
INFO:__main__:Getting metadata for https://www.braze.com/perspectives/tag/building-braze
ERROR:__main__:Could not get metadata for https://www.braze.com/perspectives/tag/building-braze
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 39%|███▉      | 408/1049 [07:00<11:34,  1.08s/it]INFO:__main__:Requesting http://gambitresearch.com
INFO:__main__:Getting metadata for https://www.gambitresearch.com
 39%|███▉      | 409/1049 [07:03<19:56,  1.87s/it]INFO:__main__:Requesting https://www.gambitresearch.com/quiz/
INFO:__main__:Getting metadata for https://www.gambitresearch.com/quiz/
ERROR:__main__:Could not get metadata for https://www.gambitresearch.com/quiz/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 39%|███▉      | 410/1049 [07:06<21:11,  1.99s/it]INFO:__main__:Requesting https://secfirst.org
INFO:__main__:Getting metadata for https://secfirst.org
 39%|███▉      | 411/1049 [07:08<22:41,  2.13s/it]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?165030BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?165030BR
 39%|███▉      | 412/1049 [07:09<19:50,  1.87s/it]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?165571BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?165571BR
 39%|███▉      | 413/1049 [07:10<16:40,  1.57s/it]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?167765BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?167765BR
 39%|███▉      | 414/1049 [07:11<14:28,  1.37s/it]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?167431BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?167431BR
 40%|███▉      | 415/1049 [07:12<13:25,  1.27s/it]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?165215BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?165215BR
 40%|███▉      | 416/1049 [07:13<13:12,  1.25s/it]INFO:__main__:Requesting https://splice.com/
INFO:__main__:Getting metadata for https://splice.com
ERROR:__main__:Could not get metadata for https://splice.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 40%|███▉      | 417/1049 [07:14<10:38,  1.01s/it]INFO:__main__:Requesting https://boards.greenhouse.io/splice
INFO:__main__:Getting metadata for https://boards.greenhouse.io/splice
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/splice
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 40%|███▉      | 418/1049 [07:14<08:35,  1.22it/s]INFO:__main__:Requesting https://legalstart.fr
INFO:__main__:Getting metadata for https://www.legalstart.fr
 40%|███▉      | 419/1049 [07:19<21:29,  2.05s/it]INFO:__main__:Requesting http://smrtr.io/WTSz
INFO:__main__:Getting metadata for https://jobs.smartrecruiters.com/Legalstart/743999682804573-lead-dev-full-stack-python
 40%|████      | 420/1049 [07:20<18:30,  1.76s/it]INFO:__main__:Requesting http://smrtr.io/4NUKgA
INFO:__main__:Getting metadata for https://jobs.smartrecruiters.com/Legalstart/743999665887249-front-end-developer
 40%|████      | 421/1049 [07:21<16:14,  1.55s/it]INFO:__main__:Requesting http://smrtr.io/V4xy
INFO:__main__:Getting metadata for https://jobs.smartrecruiters.com/Legalstart/743999681777219-ux-ui-designer
 40%|████      | 422/1049 [07:22<14:23,  1.38s/it]INFO:__main__:Requesting https://housecallpro.com
INFO:__main__:Getting metadata for https://www.housecallpro.com
 40%|████      | 423/1049 [07:23<12:05,  1.16s/it]INFO:__main__:Requesting https://www.housecallpro.com/careers
INFO:__main__:Getting metadata for https://www.housecallpro.com/careers
 40%|████      | 424/1049 [07:24<10:44,  1.03s/it]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4NYa8xCRLI3U
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4NYa8xCRLI3U
 41%|████      | 425/1049 [07:24<08:20,  1.25it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4JKqoth5B9xJ
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4JKqoth5B9xJ
 41%|████      | 426/1049 [07:24<06:16,  1.65it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4Lkm--iIlF9j
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4Lkm--iIlF9j
 41%|████      | 427/1049 [07:24<05:04,  2.04it/s]INFO:__main__:Requesting https://clearbrain.com
INFO:__main__:Getting metadata for https://clearbrain.com
 41%|████      | 428/1049 [07:25<04:33,  2.27it/s]INFO:__main__:Requesting https://www.keyvalues.com/clearbrain
INFO:__main__:Getting metadata for https://www.keyvalues.com/clearbrain
 41%|████      | 429/1049 [07:26<06:53,  1.50it/s]INFO:__main__:Requesting https://angel.co/clearbrain/jobs/177711-machine-learning-engineer
INFO:__main__:Requesting https://angel.co/atlas-ml/jobs
 41%|████      | 431/1049 [07:26<05:05,  2.03it/s]INFO:__main__:Requesting http://nov.com
INFO:__main__:Getting metadata for https://nov.com
 41%|████      | 432/1049 [07:29<13:31,  1.32s/it]INFO:__main__:Requesting https://www.sanity.io/blog/hiring-sre
INFO:__main__:Getting metadata for https://www.sanity.io/blog/hiring-sre
 41%|████▏     | 433/1049 [07:30<11:48,  1.15s/it]INFO:__main__:Requesting https://wikifactory.com/jobs
INFO:__main__:Getting metadata for https://wikifactory.com/jobs
ERROR:__main__:Could not get metadata for https://wikifactory.com/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 41%|████▏     | 434/1049 [07:32<15:33,  1.52s/it]INFO:__main__:Requesting http://science.sciencemag.org/content/363/6422/88
INFO:__main__:Getting metadata for http://science.sciencemag.org/content/363/6422/88
 41%|████▏     | 435/1049 [07:35<18:50,  1.84s/it]INFO:__main__:Requesting https://doi.org/10.1016/j.molcel.2018.02.028
INFO:__main__:Getting metadata for https://linkinghub.elsevier.com/retrieve/pii/S1097276518301734
ERROR:__main__:Could not get metadata for https://linkinghub.elsevier.com/retrieve/pii/S1097276518301734
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 436/1049 [07:37<21:02,  2.06s/it]INFO:__main__:Requesting https://arbor.bio/careers
INFO:__main__:Getting metadata for https://arbor.bio/careers
ERROR:__main__:Could not get metadata for https://arbor.bio/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 437/1049 [07:38<16:56,  1.66s/it]INFO:__main__:Requesting https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3062
INFO:__main__:Getting metadata for https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3062
 42%|████▏     | 438/1049 [07:38<12:50,  1.26s/it]INFO:__main__:Requesting https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3174
INFO:__main__:Getting metadata for https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3174
 42%|████▏     | 439/1049 [07:39<09:49,  1.03it/s]INFO:__main__:Requesting https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3173
INFO:__main__:Getting metadata for https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3173
 42%|████▏     | 440/1049 [07:39<07:47,  1.30it/s]INFO:__main__:Requesting https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3148
INFO:__main__:Getting metadata for https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3148
 42%|████▏     | 441/1049 [07:39<06:23,  1.59it/s]INFO:__main__:Requesting https://kbra.bamboohr.com/jobs/
INFO:__main__:Getting metadata for https://kbra.bamboohr.com/jobs/
 42%|████▏     | 442/1049 [07:40<06:20,  1.59it/s]INFO:__main__:Requesting https://vimeo.com/307810015
INFO:__main__:Requesting https://redoxchem.com/careers/software-engineer
ERROR:__main__:Could not reach https://redoxchem.com/careers/software-engineer
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 80, in create_connection
    raise err
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 70, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 301, in connect
    conn = self._new_conn()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 164, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97b9bf6160>, 'Connection to redoxchem.com timed out. (connect timeout=6)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='redoxchem.com', port=443): Max retries exceeded with url: /careers/software-engineer (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97b9bf6160>, 'Connection to redoxchem.com timed out. (connect timeout=6)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 504, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='redoxchem.com', port=443): Max retries exceeded with url: /careers/software-engineer (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97b9bf6160>, 'Connection to redoxchem.com timed out. (connect timeout=6)'))
 42%|████▏     | 444/1049 [07:46<13:43,  1.36s/it]INFO:__main__:Requesting https://www.cloverhealth.com/en/about-us/careers
INFO:__main__:Getting metadata for https://www.cloverhealth.com/en/about-us/careers
 42%|████▏     | 445/1049 [07:47<12:49,  1.27s/it]INFO:__main__:Requesting https://technology.cloverhealth.com/
INFO:__main__:Getting metadata for https://technology.cloverhealth.com/?gi=840fe83df4a3
 43%|████▎     | 446/1049 [07:49<13:00,  1.29s/it]INFO:__main__:Requesting https://jobs.apple.com/en-us/details/113638128/firmware-engineer?team=HRDWR
INFO:__main__:Getting metadata for https://jobs.apple.com/en-us/details/113638128/firmware-engineer?team=HRDWR
 43%|████▎     | 447/1049 [07:51<15:21,  1.53s/it]INFO:__main__:Requesting https://www.okta.com/company/careers/
INFO:__main__:Getting metadata for https://www.okta.com/company/careers/
 43%|████▎     | 448/1049 [07:51<11:46,  1.17s/it]INFO:__main__:Requesting https://aula.education/
INFO:__main__:Getting metadata for https://aula.education
 43%|████▎     | 449/1049 [07:52<11:34,  1.16s/it]INFO:__main__:Requesting http://bit.ly/FullstackEngineeratAula
INFO:__main__:Getting metadata for https://www.notion.so/aulaeducation/Remote-Senior-Full-stack-JavaScript-Engineer-React-Node-js-Aula-46e2f5d700a44f99ac7f65177e506a4b
 43%|████▎     | 450/1049 [07:53<09:19,  1.07it/s]INFO:__main__:Requesting http://bit.ly/DevOpsatAula
INFO:__main__:Getting metadata for https://www.notion.so/aulaeducation/Remote-DevOps-Automation-Engineer-Node-js-Terraform-Docker-Aula-8e7c97af8f934044987f226f2c9048fb
 43%|████▎     | 451/1049 [07:53<07:40,  1.30it/s]INFO:__main__:Requesting http://bit.ly/AulaAsyncHiring
INFO:__main__:Getting metadata for https://www.notion.so/aulaeducation/Async-engineering-interviews-at-Aula-bce436a4230c4f0d8b19bc717232d289
 43%|████▎     | 452/1049 [07:53<06:51,  1.45it/s]INFO:__main__:Requesting http://bit.ly/AulaTechStack
INFO:__main__:Getting metadata for https://blog.aula.education/bringing-educational-infrastructure-into-the-21st-century-the-stack-be66b1a743c0?gi=66eb423e2b20
 43%|████▎     | 453/1049 [07:55<09:26,  1.05it/s]INFO:__main__:Requesting https://netscoutrccorp.peoplefluent.com/
INFO:__main__:Getting metadata for https://netscoutrccorp.peoplefluent.com/res_joblist.html
ERROR:__main__:Could not get metadata for https://netscoutrccorp.peoplefluent.com/res_joblist.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 43%|████▎     | 454/1049 [07:56<08:45,  1.13it/s]INFO:__main__:Requesting https://goo.gl/RRPtC2
INFO:__main__:Getting metadata for https://netscoutrccorp.peoplefluent.com/res_viewjob.html?optlink-view=view-9518&ERFormID=res_newjoblist&ERFormCode=any
ERROR:__main__:Could not get metadata for https://netscoutrccorp.peoplefluent.com/res_viewjob.html?optlink-view=view-9518&ERFormID=res_newjoblist&ERFormCode=any
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 43%|████▎     | 455/1049 [07:56<07:53,  1.26it/s]INFO:__main__:Requesting https://www.prima.it/carriera
INFO:__main__:Getting metadata for https://www.prima.it/carriera
 43%|████▎     | 456/1049 [08:01<18:15,  1.85s/it]INFO:__main__:Requesting https://boards.greenhouse.io/instacart
INFO:__main__:Getting metadata for https://boards.greenhouse.io/instacart
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/instacart
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 44%|████▎     | 457/1049 [08:01<14:35,  1.48s/it]INFO:__main__:Requesting https://kiron.ngo/tech-jobs
INFO:__main__:Getting metadata for https://kiron.ngo/tech-jobs
ERROR:__main__:Could not get metadata for https://kiron.ngo/tech-jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 44%|████▎     | 458/1049 [08:02<11:19,  1.15s/it]INFO:__main__:Requesting https://popdog.com
INFO:__main__:Getting metadata for https://popdog.com
 44%|████▍     | 459/1049 [08:02<08:28,  1.16it/s]INFO:__main__:Requesting https://loaded.gg/
INFO:__main__:Getting metadata for https://loaded.gg
 44%|████▍     | 460/1049 [08:02<06:53,  1.42it/s]INFO:__main__:Requesting https://jobs.lever.co/popdog/0c6443a2-09c5-4a27-a536-2270037..
 44%|████▍     | 461/1049 [08:02<05:40,  1.73it/s]INFO:__main__:Requesting https://jobs.lever.co/popdog/3377b4f4-2b54-4a78-a9ad-1a40ed0..
 44%|████▍     | 462/1049 [08:03<04:47,  2.04it/s]INFO:__main__:Requesting https://jobs.lever.co/popdog
INFO:__main__:Getting metadata for https://jobs.lever.co/popdog
 44%|████▍     | 463/1049 [08:03<05:05,  1.92it/s]INFO:__main__:Requesting http://bit.ly/gghackernews
INFO:__main__:Getting metadata for https://glossgenius.recruitee.com/o/senior-growth-engineer?source=hackernews
 44%|████▍     | 464/1049 [08:04<05:33,  1.75it/s]INFO:__main__:Requesting https://okcupid.com/careers
INFO:__main__:Getting metadata for https://www.okcupid.com/careers
 44%|████▍     | 465/1049 [08:05<07:03,  1.38it/s]INFO:__main__:Requesting https://www.freenome.com/careers
INFO:__main__:Getting metadata for https://www.freenome.com/careers
 44%|████▍     | 466/1049 [08:06<07:30,  1.30it/s]INFO:__main__:Requesting https://www.omnisci.com
INFO:__main__:Getting metadata for https://www.omnisci.com
 45%|████▍     | 467/1049 [08:10<16:05,  1.66s/it]INFO:__main__:Requesting http://www.omnisci.com/demos/tweetmap
INFO:__main__:Getting metadata for https://www.omnisci.com/demos/tweetmap/
 45%|████▍     | 468/1049 [08:11<14:22,  1.48s/it]INFO:__main__:Requesting https://www.omnisci.com/demos/ships
INFO:__main__:Getting metadata for https://www.omnisci.com/demos/ships/
ERROR:__main__:Could not get metadata for https://www.omnisci.com/demos/ships/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 45%|████▍     | 469/1049 [08:13<15:35,  1.61s/it]INFO:__main__:Requesting https://www.omnisci.com/company/careers/
INFO:__main__:Getting metadata for https://www.omnisci.com/company/careers/
 45%|████▍     | 470/1049 [08:16<20:47,  2.15s/it]INFO:__main__:Requesting https://customer.io
INFO:__main__:Getting metadata for https://customer.io
 45%|████▍     | 471/1049 [08:16<15:14,  1.58s/it]INFO:__main__:Requesting https://customer.io/careers/
INFO:__main__:Getting metadata for https://customer.io/careers/
 45%|████▍     | 472/1049 [08:17<11:39,  1.21s/it]INFO:__main__:Requesting https://evolyst.com
INFO:__main__:Getting metadata for https://evolyst.com
 45%|████▌     | 473/1049 [08:19<15:26,  1.61s/it]INFO:__main__:Requesting http://www.aurorasolar.com/
INFO:__main__:Getting metadata for https://www.aurorasolar.com
 45%|████▌     | 474/1049 [08:21<14:49,  1.55s/it]INFO:__main__:Requesting https://www.bevi.co/
INFO:__main__:Getting metadata for https://www.bevi.co
 45%|████▌     | 475/1049 [08:21<12:35,  1.32s/it]INFO:__main__:Requesting https://www.workable.com/j/EBF5E7E549
INFO:__main__:Getting metadata for https://bevicareers.workable.com/j/EBF5E7E549
 45%|████▌     | 476/1049 [08:22<11:28,  1.20s/it]INFO:__main__:Requesting https://www.workable.com/j/DEB678EA48
INFO:__main__:Getting metadata for https://bevicareers.workable.com/j/DEB678EA48
 45%|████▌     | 477/1049 [08:23<10:30,  1.10s/it]INFO:__main__:Requesting https://www.workable.com/j/A5CAAB7F50
INFO:__main__:Getting metadata for https://bevicareers.workable.com/j/A5CAAB7F50
 46%|████▌     | 478/1049 [08:24<09:49,  1.03s/it]INFO:__main__:Requesting https://circleup.com
INFO:__main__:Getting metadata for https://circleup.com
ERROR:__main__:Could not get metadata for https://circleup.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 46%|████▌     | 479/1049 [08:26<11:53,  1.25s/it]INFO:__main__:Requesting https://medium.com/@ryancaldbeck/announcing-the-launch-of-he...
 46%|████▌     | 480/1049 [08:26<08:48,  1.08it/s]INFO:__main__:Requesting https://circleup.com/jobs/
INFO:__main__:Getting metadata for https://circleup.com/jobs/
ERROR:__main__:Could not get metadata for https://circleup.com/jobs/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 46%|████▌     | 481/1049 [08:28<10:46,  1.14s/it]INFO:__main__:Requesting https://aws.amazon.com/professional-services/
INFO:__main__:Getting metadata for https://aws.amazon.com/professional-services/
ERROR:__main__:Could not get metadata for https://aws.amazon.com/professional-services/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 46%|████▌     | 482/1049 [08:28<08:38,  1.09it/s]INFO:__main__:Requesting https://www.amazon.jobs/en/search?base_query=professional+services
INFO:__main__:Getting metadata for https://www.amazon.jobs/en/search?base_query=professional+services
 46%|████▌     | 483/1049 [08:29<08:25,  1.12it/s]INFO:__main__:Requesting https://poynt.com
INFO:__main__:Getting metadata for https://poynt.com
ERROR:__main__:Could not get metadata for https://poynt.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 46%|████▌     | 484/1049 [08:29<07:07,  1.32it/s]INFO:__main__:Requesting https://poynt.com/press/
INFO:__main__:Getting metadata for https://poynt.com/press/
 46%|████▌     | 485/1049 [08:30<06:02,  1.56it/s]INFO:__main__:Requesting https://www.LetsEnvision.com/
INFO:__main__:Getting metadata for https://www.letsenvision.com
 46%|████▋     | 486/1049 [08:30<05:40,  1.66it/s]INFO:__main__:Requesting https://denimlabs.com/company/careers/
INFO:__main__:Getting metadata for https://denimlabs.com/company/careers/
 46%|████▋     | 487/1049 [08:35<18:45,  2.00s/it]INFO:__main__:Requesting https://kiprotect.com
INFO:__main__:Getting metadata for https://kiprotect.com
 47%|████▋     | 488/1049 [08:37<17:46,  1.90s/it]INFO:__main__:Requesting https://predata.com/
INFO:__main__:Getting metadata for https://predata.com
 47%|████▋     | 489/1049 [08:38<15:38,  1.68s/it]INFO:__main__:Requesting https://angel.co/predata/jobs/
INFO:__main__:Requesting https://www.bosch.com/internet-of-things/connected-mobility/
INFO:__main__:Getting metadata for https://www.bosch.com/internet-of-things/connected-mobility/
 47%|████▋     | 491/1049 [08:41<14:12,  1.53s/it]INFO:__main__:Requesting https://www.tatari.tv
INFO:__main__:Getting metadata for https://www.tatari.tv
 47%|████▋     | 492/1049 [08:41<11:42,  1.26s/it]INFO:__main__:Requesting https://www.tatari.tv/careers
INFO:__main__:Getting metadata for https://www.tatari.tv/careers
 47%|████▋     | 493/1049 [08:44<14:46,  1.59s/it]INFO:__main__:Requesting https://www.treasuredata.com/company/careers/
INFO:__main__:Getting metadata for https://www.treasuredata.com/company/careers/
 47%|████▋     | 494/1049 [08:44<10:55,  1.18s/it]INFO:__main__:Requesting https://www.treasuredata.com/learn/why-treasure-data/
INFO:__main__:Getting metadata for https://www.treasuredata.com/learn/why-treasure-data/
 47%|████▋     | 495/1049 [08:44<09:28,  1.03s/it]INFO:__main__:Requesting https://azure.microsoft.com/en-us/services/kubernetes-service/
INFO:__main__:Getting metadata for https://azure.microsoft.com/en-us/services/kubernetes-service/
 47%|████▋     | 496/1049 [08:46<11:57,  1.30s/it]INFO:__main__:Requesting https://industryuseng-ms.icims.com/jobs/590353/senior-software-engineer/job?mode=view
INFO:__main__:Getting metadata for https://industryuseng-ms.icims.com/jobs/590353/senior-software-engineer/job?mode=view
 47%|████▋     | 497/1049 [08:47<09:54,  1.08s/it]INFO:__main__:Requesting https://industryuseng-ms.icims.com/jobs/590350/software-engineer/job?mode=view
INFO:__main__:Getting metadata for https://industryuseng-ms.icims.com/jobs/590350/software-engineer/job?mode=view
 47%|████▋     | 498/1049 [08:47<07:58,  1.15it/s]INFO:__main__:Requesting https://jobs.lever.co/jellyfish
INFO:__main__:Getting metadata for https://jobs.lever.co/jellyfish
 48%|████▊     | 499/1049 [08:48<07:08,  1.28it/s]INFO:__main__:Requesting http://certsafe.com/
INFO:__main__:Getting metadata for http://www.certsafe.com
 48%|████▊     | 500/1049 [08:49<07:52,  1.16it/s]INFO:__main__:Requesting http://certsafe.com/careers/
INFO:__main__:Getting metadata for http://www.certsafe.com/careers/
 48%|████▊     | 501/1049 [08:50<08:14,  1.11it/s]INFO:__main__:Requesting https://www.visuallabsinc.com/
INFO:__main__:Getting metadata for https://www.visuallabsinc.com
 48%|████▊     | 502/1049 [08:53<13:12,  1.45s/it]INFO:__main__:Requesting https://youtu.be/WxHIrdqt9Rg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=WxHIrdqt9Rg&feature=youtu.be
 48%|████▊     | 503/1049 [08:54<11:51,  1.30s/it]INFO:__main__:Requesting https://openbuildservice.org
INFO:__main__:Getting metadata for https://openbuildservice.org
 48%|████▊     | 504/1049 [08:55<11:04,  1.22s/it]INFO:__main__:Requesting https://jobs.suse.com/job/nuremberg/full-stack-web-developer/3486/10399103
INFO:__main__:Getting metadata for https://jobs.suse.com/job/nuremberg/full-stack-web-developer/3486/10399103
 48%|████▊     | 505/1049 [08:56<10:33,  1.16s/it]INFO:__main__:Requesting https://altusassessments.com/
INFO:__main__:Getting metadata for https://altusassessments.com
 48%|████▊     | 506/1049 [08:57<09:28,  1.05s/it]INFO:__main__:Requesting http://www.energyhub.com
INFO:__main__:Getting metadata for https://www.energyhub.com
ERROR:__main__:Could not get metadata for https://www.energyhub.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 48%|████▊     | 507/1049 [08:57<08:01,  1.12it/s]INFO:__main__:Requesting https://grnh.se/8c8235d82
INFO:__main__:Getting metadata for https://www.energyhub.com/careers?gh_src=8c8235d82
 48%|████▊     | 508/1049 [08:59<09:44,  1.08s/it]INFO:__main__:Requesting https://vsecurity.com/company/employment.html
INFO:__main__:Getting metadata for https://vsecurity.com/company/employment.html
 49%|████▊     | 509/1049 [08:59<09:19,  1.04s/it]INFO:__main__:Requesting http://onspecta.com/careers.html
INFO:__main__:Getting metadata for http://onspecta.com/careers.html
 49%|████▊     | 510/1049 [09:00<08:11,  1.10it/s]INFO:__main__:Requesting https://www.adjust.com/
INFO:__main__:Getting metadata for https://www.adjust.com
 49%|████▊     | 511/1049 [09:02<10:59,  1.23s/it]INFO:__main__:Requesting https://boards.greenhouse.io/adjust/jobs/4213522002
INFO:__main__:Getting metadata for https://boards.greenhouse.io/adjust/jobs/4213522002
 49%|████▉     | 512/1049 [09:02<08:47,  1.02it/s]INFO:__main__:Requesting https://boards.greenhouse.io/adjust/jobs/4210333002
INFO:__main__:Getting metadata for https://boards.greenhouse.io/adjust/jobs/4210333002
 49%|████▉     | 513/1049 [09:03<07:07,  1.25it/s]INFO:__main__:Requesting https://www.adjust.com/company/careers/
INFO:__main__:Getting metadata for https://www.adjust.com/company/careers/
 49%|████▉     | 514/1049 [09:05<11:10,  1.25s/it]INFO:__main__:Requesting https://grnh.se/dn27gt1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/squarespace?gh_src=dn27gt1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/squarespace?gh_src=dn27gt1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 49%|████▉     | 515/1049 [09:06<09:21,  1.05s/it]INFO:__main__:Requesting https://jobs.lever.co/starskyrobotics/
INFO:__main__:Getting metadata for https://jobs.lever.co/starskyrobotics/
 49%|████▉     | 516/1049 [09:06<08:28,  1.05it/s]INFO:__main__:Requesting https://flowkey.breezy.hr/p/d90cda1664f601-senior-full-stack-engineer-full-time
INFO:__main__:Getting metadata for https://flowkey.breezy.hr/p/d90cda1664f601-senior-full-stack-engineer-full-time
 49%|████▉     | 517/1049 [09:08<08:56,  1.01s/it]INFO:__main__:Requesting https://circle.careers/en/
INFO:__main__:Getting metadata for https://circle.careers/en/
 49%|████▉     | 518/1049 [09:09<08:52,  1.00s/it]INFO:__main__:Requesting https://braincorporation.applytojob.com/apply/
INFO:__main__:Getting metadata for https://braincorporation.applytojob.com/apply/
 49%|████▉     | 519/1049 [09:11<11:27,  1.30s/it]INFO:__main__:Requesting https://www.linkedin.com/in/rawsonleavitt/
INFO:__main__:Requesting https://www.opendoor.com/jobs
INFO:__main__:Getting metadata for https://www.opendoor.com/jobs
 50%|████▉     | 521/1049 [09:12<09:12,  1.05s/it]INFO:__main__:Requesting https://www.quotapath.com/careers/
INFO:__main__:Getting metadata for https://www.quotapath.com/careers/
ERROR:__main__:Could not get metadata for https://www.quotapath.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 50%|████▉     | 522/1049 [09:12<07:36,  1.15it/s]INFO:__main__:Requesting https://www.nexient.com/careers
INFO:__main__:Getting metadata for https://www.nexient.com/careers
ERROR:__main__:Could not get metadata for https://www.nexient.com/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 50%|████▉     | 523/1049 [09:12<06:12,  1.41it/s]INFO:__main__:Requesting https://borrowell.workable.com/jobs/871672
INFO:__main__:Getting metadata for https://borrowell.workable.com/jobs/871672
 50%|████▉     | 524/1049 [09:13<05:54,  1.48it/s]INFO:__main__:Requesting https://cooklist.co
INFO:__main__:Getting metadata for https://www.cooklist.co
ERROR:__main__:Could not get metadata for https://www.cooklist.co
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 50%|█████     | 525/1049 [09:14<05:53,  1.48it/s]INFO:__main__:Requesting https://redislabs.com/company/careers/
INFO:__main__:Getting metadata for https://redislabs.com/company/careers/
 50%|█████     | 526/1049 [09:15<06:56,  1.25it/s]INFO:__main__:Requesting https://university.redislabs.com
INFO:__main__:Getting metadata for https://university.redislabs.com
 50%|█████     | 527/1049 [09:16<08:14,  1.06it/s]INFO:__main__:Requesting https://redislabs.com/careers/product-manager-security/
INFO:__main__:Getting metadata for https://redislabs.com/careers/product-manager-security/
 50%|█████     | 528/1049 [09:17<08:19,  1.04it/s]INFO:__main__:Requesting https://redislabs.com/careers/team-lead/
INFO:__main__:Getting metadata for https://redislabs.com/careers/team-lead/
 50%|█████     | 529/1049 [09:18<08:23,  1.03it/s]INFO:__main__:Requesting https://angel.co/l/2eubtM
 51%|█████     | 530/1049 [09:18<06:09,  1.40it/s]INFO:__main__:Requesting https://axio.com/careers/
INFO:__main__:Getting metadata for https://axio.com/careers/
 51%|█████     | 531/1049 [09:18<05:23,  1.60it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=nYcBqtOwLcg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=nYcBqtOwLcg
 51%|█████     | 532/1049 [09:19<06:12,  1.39it/s]INFO:__main__:Requesting https://www.polarsteps.com/teleporter
INFO:__main__:Getting metadata for https://www.polarsteps.com/teleporter
 51%|█████     | 533/1049 [09:20<05:42,  1.51it/s]INFO:__main__:Requesting https://careers.polarsteps.com/#vacancies
INFO:__main__:Getting metadata for https://careers.polarsteps.com/#vacancies
 51%|█████     | 534/1049 [09:21<07:12,  1.19it/s]INFO:__main__:Requesting https://goo.gl/UuZ3T3
INFO:__main__:Getting metadata for https://www.kyruus.com/careers?gnk=job&gni=8a78839f661391f5016631ae50016229&gns=WWC
 51%|█████     | 535/1049 [09:22<06:25,  1.33it/s]INFO:__main__:Requesting https://www.kyruus.com/about
INFO:__main__:Getting metadata for https://www.kyruus.com/about
 51%|█████     | 536/1049 [09:22<04:58,  1.72it/s]INFO:__main__:Requesting https://www.kyruus.com/careers
INFO:__main__:Getting metadata for https://www.kyruus.com/careers
 51%|█████     | 537/1049 [09:22<03:57,  2.15it/s]INFO:__main__:Requesting http://evtech.careers
INFO:__main__:Getting metadata for https://docs.google.com/document/d/1pvsI1PB4D2u7izgSG1NR83ScgIjMgYiDS16kSrqItkA/edit#heading=h.8qodbcsbswje/
 51%|█████▏    | 538/1049 [09:24<06:29,  1.31it/s]INFO:__main__:Requesting https://stitchlabs.bamboohr.com/jobs/view.php?id=28
INFO:__main__:Getting metadata for https://stitchlabs.bamboohr.com/jobs/view.php?id=28
 51%|█████▏    | 539/1049 [09:24<06:09,  1.38it/s]INFO:__main__:Requesting https://jobs.lever.co/kraken
INFO:__main__:Getting metadata for https://jobs.lever.co/kraken
 51%|█████▏    | 540/1049 [09:25<06:20,  1.34it/s]INFO:__main__:Requesting https://venturebeat.com/2018/12/17/datacamp-raises-25-million-for-customizable-online-data-science-courses/
INFO:__main__:Getting metadata for https://venturebeat.com/2018/12/17/datacamp-raises-25-million-for-customizable-online-data-science-courses/
 52%|█████▏    | 541/1049 [09:26<06:22,  1.33it/s]INFO:__main__:Requesting https://bit.ly/2SUnuae
INFO:__main__:Getting metadata for https://boards.greenhouse.io/datacamp/jobs/1482036
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/datacamp/jobs/1482036
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 52%|█████▏    | 542/1049 [09:26<05:51,  1.44it/s]INFO:__main__:Requesting https://www.datacamp.com/jobs
INFO:__main__:Getting metadata for https://www.datacamp.com/jobs
ERROR:__main__:Could not get metadata for https://www.datacamp.com/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 52%|█████▏    | 543/1049 [09:28<09:27,  1.12s/it]INFO:__main__:Requesting https://bitonic.nl/jobs
INFO:__main__:Getting metadata for https://bitonic.nl/jobs
ERROR:__main__:Could not get metadata for https://bitonic.nl/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 52%|█████▏    | 544/1049 [09:30<09:21,  1.11s/it]INFO:__main__:Requesting https://jobs.disneycareers.com/search-jobs
INFO:__main__:Getting metadata for https://jobs.disneycareers.com/search-jobs
 52%|█████▏    | 545/1049 [09:32<12:43,  1.52s/it]INFO:__main__:Requesting https://octopart.com/jobs
 52%|█████▏    | 546/1049 [09:32<09:37,  1.15s/it]INFO:__main__:Requesting https://chainalysis.com
INFO:__main__:Getting metadata for https://www.chainalysis.com
 52%|█████▏    | 547/1049 [09:34<10:50,  1.30s/it]INFO:__main__:Requesting https://boards.greenhouse.io/chainalysis/jobs/4142080002
INFO:__main__:Getting metadata for https://boards.greenhouse.io/chainalysis/jobs/4142080002
 52%|█████▏    | 548/1049 [09:34<08:30,  1.02s/it]INFO:__main__:Requesting https://fetchrev.bamboohr.com/jobs/view.php?id=24
INFO:__main__:Getting metadata for https://fetchrev.bamboohr.com/jobs/view.php?id=24
 52%|█████▏    | 549/1049 [09:35<07:22,  1.13it/s]INFO:__main__:Requesting https://sourcegraph.com
INFO:__main__:Getting metadata for https://sourcegraph.com/welcome
ERROR:__main__:Could not get metadata for https://sourcegraph.com/welcome
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 52%|█████▏    | 550/1049 [09:35<05:32,  1.50it/s]INFO:__main__:Requesting https://github.com/sourcegraph/careers/
INFO:__main__:Getting metadata for https://github.com/sourcegraph/careers/
 53%|█████▎    | 551/1049 [09:36<06:24,  1.29it/s]INFO:__main__:Requesting https://sourcegraph.com/plan
INFO:__main__:Getting metadata for https://about.sourcegraph.com/plan/
 53%|█████▎    | 552/1049 [09:37<06:34,  1.26it/s]INFO:__main__:Requesting https://github.com/sourcegraph/sourcegraph
INFO:__main__:Getting metadata for https://github.com/sourcegraph/sourcegraph
 53%|█████▎    | 553/1049 [09:38<07:18,  1.13it/s]INFO:__main__:Requesting https://docs.sourcegraph.com/dev/roadmap
INFO:__main__:Getting metadata for https://docs.sourcegraph.com/dev/roadmap
 53%|█████▎    | 554/1049 [09:39<07:18,  1.13it/s]INFO:__main__:Requesting https://www.veezoo.com
INFO:__main__:Getting metadata for https://www.veezoo.com
 53%|█████▎    | 555/1049 [09:41<09:57,  1.21s/it]INFO:__main__:Requesting https://housinganywhere.workable.com/j/C33B03C0C6?viewed=true
INFO:__main__:Getting metadata for https://housinganywhere.workable.com/j/C33B03C0C6?viewed=true
 53%|█████▎    | 556/1049 [09:41<08:31,  1.04s/it]INFO:__main__:Requesting https://amperity.com/careers/
INFO:__main__:Getting metadata for https://amperity.com/careers/
 53%|█████▎    | 557/1049 [09:42<07:05,  1.16it/s]INFO:__main__:Requesting https://blog.expensify.com/2016/06/03/rule-1-get-shit-done/
ERROR:__main__:Could not reach https://blog.expensify.com/2016/06/03/rule-1-get-shit-done/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 53%|█████▎    | 558/1049 [09:42<05:18,  1.54it/s]INFO:__main__:Requesting https://we.are.expensify.com
INFO:__main__:Getting metadata for https://we.are.expensify.com
 53%|█████▎    | 559/1049 [09:43<05:09,  1.58it/s]INFO:__main__:Requesting http://belvederetrading.applicantstack.com/x/detail/a2sa4x0b2oek
INFO:__main__:Getting metadata for http://belvederetrading.applicantstack.com/x/detail/a2sa4x0b2oek
 53%|█████▎    | 560/1049 [09:45<08:30,  1.04s/it]INFO:__main__:Requesting http://www.belvederetrading.com/careers/
INFO:__main__:Getting metadata for http://www.belvederetrading.com/careers/
ERROR:__main__:Could not get metadata for http://www.belvederetrading.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 53%|█████▎    | 561/1049 [09:45<07:16,  1.12it/s]INFO:__main__:Requesting https://launchdarkly.com/careers/
INFO:__main__:Getting metadata for https://launchdarkly.com/careers/
 54%|█████▎    | 562/1049 [09:46<06:25,  1.26it/s]INFO:__main__:Requesting http://blog.coveo.com/coveo-leads-gartner-magic-quadrant-for-insight-engines/
INFO:__main__:Getting metadata for https://blog.coveo.com/coveo-leads-gartner-magic-quadrant-for-insight-engines/
 54%|█████▎    | 563/1049 [09:47<08:12,  1.01s/it]INFO:__main__:Requesting http://blog.coveo.com/coveo-montreal-finally-home/
INFO:__main__:Getting metadata for https://blog.coveo.com/coveo-montreal-finally-home/
 54%|█████▍    | 564/1049 [09:49<08:52,  1.10s/it]INFO:__main__:Requesting https://search.firstround.com/
INFO:__main__:Getting metadata for https://search.firstround.com
 54%|█████▍    | 565/1049 [09:49<07:15,  1.11it/s]INFO:__main__:Requesting https://careers.firstround.com/welcome/firstround
INFO:__main__:Getting metadata for https://careers.firstround.com/welcome/firstround
ERROR:__main__:Could not get metadata for https://careers.firstround.com/welcome/firstround
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 54%|█████▍    | 566/1049 [09:50<08:28,  1.05s/it]INFO:__main__:Requesting https://medium.com/@firstround/were-hiring-for-our-software-engineering-team-bd844ecd42cf
INFO:__main__:Getting metadata for https://medium.com/@firstround/were-hiring-for-our-software-engineering-team-bd844ecd42cf
 54%|█████▍    | 567/1049 [09:51<07:00,  1.15it/s]INFO:__main__:Requesting https://www.replicated.com
INFO:__main__:Getting metadata for https://www.replicated.com
 54%|█████▍    | 568/1049 [09:52<07:55,  1.01it/s]INFO:__main__:Requesting https://www.betterup.co/
INFO:__main__:Getting metadata for https://www.betterup.co
 54%|█████▍    | 569/1049 [09:52<06:02,  1.33it/s]INFO:__main__:Requesting https://boards.greenhouse.io/betterup/jobs/935618
INFO:__main__:Getting metadata for https://boards.greenhouse.io/betterup/jobs/935618
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/betterup/jobs/935618
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 54%|█████▍    | 570/1049 [09:53<05:19,  1.50it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/designpicklecom/view/P_AAAAAAFAAILMte651AZyrP
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/designpicklecom/view/P_AAAAAAFAAILMte651AZyrP
 54%|█████▍    | 571/1049 [09:53<04:17,  1.85it/s]INFO:__main__:Requesting https://www.givecampus.com/careers
INFO:__main__:Getting metadata for https://www.givecampus.com/careers
 55%|█████▍    | 572/1049 [09:53<03:56,  2.02it/s]INFO:__main__:Requesting https://www.washingtonpost.com/news/grade-point/wp/2016/04/19/colleges-are-going-online-to-crowdsource-donations-and-theyre-raising-millions
ERROR:__main__:Could not reach https://www.washingtonpost.com/news/grade-point/wp/2016/04/19/colleges-are-going-online-to-crowdsource-donations-and-theyre-raising-millions
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)
 55%|█████▍    | 573/1049 [10:00<17:18,  2.18s/it]INFO:__main__:Requesting https://steady.health
INFO:__main__:Getting metadata for https://steady.health
 55%|█████▍    | 574/1049 [10:00<13:50,  1.75s/it]INFO:__main__:Requesting https://medium.com/south-park-commons/the-wearable-that-changed-my-life-1a5b9bdbab22
INFO:__main__:Getting metadata for https://medium.com/south-park-commons/the-wearable-that-changed-my-life-1a5b9bdbab22
 55%|█████▍    | 575/1049 [10:01<11:05,  1.40s/it]INFO:__main__:Requesting https://careers.ef.com/job/ohdM8fw8/
INFO:__main__:Getting metadata for https://careers.ef.com/job/ohdM8fw8/
 55%|█████▍    | 576/1049 [10:03<11:30,  1.46s/it]INFO:__main__:Requesting http://class.ef.com/
INFO:__main__:Getting metadata for http://class.ef.com
 55%|█████▌    | 577/1049 [10:03<09:11,  1.17s/it]INFO:__main__:Requesting https://angel.co/firststepcoding/jobs/478698-growth-marketing-manager
INFO:__main__:Requesting https://occipital.com
INFO:__main__:Getting metadata for https://occipital.com
 55%|█████▌    | 579/1049 [10:04<07:29,  1.05it/s]INFO:__main__:Requesting https://occipital.com/jobs
INFO:__main__:Getting metadata for https://occipital.com/jobs
 55%|█████▌    | 580/1049 [10:05<06:45,  1.16it/s]INFO:__main__:Requesting https://thegrommet.com
INFO:__main__:Getting metadata for https://www.thegrommet.com
 55%|█████▌    | 581/1049 [10:05<06:11,  1.26it/s]INFO:__main__:Requesting https://thegrommet.com/careers
INFO:__main__:Getting metadata for https://grommet.applytojob.com
 55%|█████▌    | 582/1049 [10:07<08:04,  1.04s/it]INFO:__main__:Requesting https://grnh.se/dd40b1ab1
INFO:__main__:Getting metadata for https://learningequality.org/about/jobs/?gh_jid=1441505&gh_src=dd40b1ab1
 56%|█████▌    | 583/1049 [10:08<07:57,  1.03s/it]INFO:__main__:Requesting https://learningequality.org/ka-lite/map/
ERROR:__main__:Could not reach https://learningequality.org/ka-lite/map/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='learningequality.org', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='learningequality.org', port=443): Read timed out. (read timeout=6)
 56%|█████▌    | 584/1049 [10:14<19:39,  2.54s/it]INFO:__main__:Requesting https://github.com/learningequality/kolibri
INFO:__main__:Getting metadata for https://github.com/learningequality/kolibri
 56%|█████▌    | 585/1049 [10:15<16:03,  2.08s/it]INFO:__main__:Requesting https://loaneco.net/
INFO:__main__:Getting metadata for https://loaneco.net
 56%|█████▌    | 586/1049 [10:16<14:00,  1.82s/it]INFO:__main__:Requesting https://angel.co/l/28JSu2
INFO:__main__:Requesting http://learn.realscout.com/about
INFO:__main__:Getting metadata for http://learn.realscout.com/about/
 56%|█████▌    | 588/1049 [10:16<10:14,  1.33s/it]INFO:__main__:Requesting https://nycbuyergraph.com/
INFO:__main__:Getting metadata for https://nycbuyergraph.com
 56%|█████▌    | 589/1049 [10:17<09:22,  1.22s/it]INFO:__main__:Requesting https://www.zenysis.com/#careers
INFO:__main__:Getting metadata for https://www.zenysis.com/#careers
 56%|█████▌    | 590/1049 [10:18<07:50,  1.02s/it]INFO:__main__:Requesting https://jobs.apple.com/us/search?job=113644011&openJobId=113644011#&ss=%22SEAR%20-%22&t=0&so=&pN=0
INFO:__main__:Getting metadata for https://jobs.apple.com/en-us/search?job=113644011&openJobId=113644011#&ss=%22SEAR%20-%22&t=0&so=&pN=0
 56%|█████▋    | 591/1049 [10:21<11:20,  1.49s/it]INFO:__main__:Requesting http://mixlr.com/
INFO:__main__:Getting metadata for http://mixlr.com
 56%|█████▋    | 592/1049 [10:21<08:58,  1.18s/it]INFO:__main__:Requesting https://mixlr.workable.com/jobs/923302
INFO:__main__:Getting metadata for https://mixlr.workable.com/jobs/923302
 57%|█████▋    | 593/1049 [10:22<07:47,  1.03s/it]INFO:__main__:Requesting https://madisonwall.bamboohr.com/jobs/view.php?id=38
INFO:__main__:Getting metadata for https://madisonwall.bamboohr.com/jobs/view.php?id=38
 57%|█████▋    | 594/1049 [10:22<07:00,  1.08it/s]INFO:__main__:Requesting https://tulip.co/careers
INFO:__main__:Getting metadata for https://tulip.co/careers/
 57%|█████▋    | 595/1049 [10:23<06:25,  1.18it/s]INFO:__main__:Requesting https://degreed.com
INFO:__main__:Getting metadata for https://degreed.com
 57%|█████▋    | 596/1049 [10:24<05:43,  1.32it/s]INFO:__main__:Requesting https://jobs.lever.co/degreed
INFO:__main__:Getting metadata for https://jobs.lever.co/degreed
 57%|█████▋    | 597/1049 [10:24<05:49,  1.29it/s]INFO:__main__:Requesting https://www.artory.com/
INFO:__main__:Getting metadata for https://www.artory.com
 57%|█████▋    | 598/1049 [10:25<05:08,  1.46it/s]INFO:__main__:Requesting https://www.artory.com/careers/
INFO:__main__:Getting metadata for https://www.artory.com/careers/
 57%|█████▋    | 599/1049 [10:25<04:29,  1.67it/s]INFO:__main__:Requesting https://smarkets.com/careers
INFO:__main__:Getting metadata for https://smarkets.com/careers/
ERROR:__main__:Could not get metadata for https://smarkets.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 57%|█████▋    | 600/1049 [10:27<06:58,  1.07it/s]INFO:__main__:Requesting https://www.geckorobotics.com/
INFO:__main__:Getting metadata for https://www.geckorobotics.com
 57%|█████▋    | 601/1049 [10:27<05:45,  1.30it/s]INFO:__main__:Requesting https://www.geckorobotics.com/company/careers
INFO:__main__:Getting metadata for https://www.geckorobotics.com/company/careers
 57%|█████▋    | 602/1049 [10:28<04:52,  1.53it/s]INFO:__main__:Requesting https://www.rinse.com/careers/senior-software-engineer/
INFO:__main__:Getting metadata for https://www.rinse.com/careers/senior-software-engineer/
 57%|█████▋    | 603/1049 [10:29<05:34,  1.33it/s]INFO:__main__:Requesting https://www.rinse.com/careers/software-engineer/
INFO:__main__:Getting metadata for https://www.rinse.com/careers/software-engineer/
 58%|█████▊    | 604/1049 [10:29<05:17,  1.40it/s]INFO:__main__:Requesting https://www.rinse.com/careers/
INFO:__main__:Getting metadata for https://www.rinse.com/careers/
 58%|█████▊    | 605/1049 [10:30<05:30,  1.34it/s]INFO:__main__:Requesting https://www.uncountable.com/careers
INFO:__main__:Getting metadata for https://www.uncountable.com/careers
ERROR:__main__:Could not get metadata for https://www.uncountable.com/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 58%|█████▊    | 606/1049 [10:31<05:38,  1.31it/s]INFO:__main__:Requesting https://jobs.lever.co/plangrid?lever-via=SzsN-_Jgq1
INFO:__main__:Getting metadata for https://jobs.lever.co/plangrid?lever-via=SzsN-_Jgq1
 58%|█████▊    | 607/1049 [10:32<05:29,  1.34it/s]INFO:__main__:Requesting https://medium.com/plangrid-technology/working-on-the-plangrid-ios-team-1d1757c76be9
INFO:__main__:Getting metadata for https://medium.com/plangrid-technology/working-on-the-plangrid-ios-team-1d1757c76be9
 58%|█████▊    | 608/1049 [10:32<05:08,  1.43it/s]INFO:__main__:Requesting https://atomicobject.com/careers/senior-software-developer-job
INFO:__main__:Getting metadata for https://atomicobject.com/careers/senior-software-developer-job
 58%|█████▊    | 609/1049 [10:33<05:56,  1.23it/s]INFO:__main__:Requesting https://www.counterpointconsulting.com/careers
INFO:__main__:Getting metadata for https://www.counterpointconsulting.com/careers
 58%|█████▊    | 610/1049 [10:34<04:48,  1.52it/s]INFO:__main__:Requesting https://www.counterpointconsulting.com/life-at-counterpoint
INFO:__main__:Getting metadata for https://www.counterpointconsulting.com/life-at-counterpoint
 58%|█████▊    | 611/1049 [10:34<03:55,  1.86it/s]INFO:__main__:Requesting https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=a6543b20-78f9-4c3b-9272-2ce9ade7de8e&ccId=19000101_000001&type=MP&lang=en_US
INFO:__main__:Getting metadata for https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=a6543b20-78f9-4c3b-9272-2ce9ade7de8e&ccId=19000101_000001&type=MP&lang=en_US
ERROR:__main__:Could not get metadata for https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=a6543b20-78f9-4c3b-9272-2ce9ade7de8e&ccId=19000101_000001&type=MP&lang=en_US
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 58%|█████▊    | 612/1049 [10:35<04:35,  1.58it/s]INFO:__main__:Requesting https://www.instructure.com/about/careers
INFO:__main__:Getting metadata for https://www.instructure.com/about/careers
 58%|█████▊    | 613/1049 [10:36<05:00,  1.45it/s]INFO:__main__:Requesting https://www.peardeck.com
INFO:__main__:Getting metadata for https://www.peardeck.com
 59%|█████▊    | 614/1049 [10:36<04:46,  1.52it/s]INFO:__main__:Requesting https://tcrn.ch/2G8eniG
ERROR:__main__:Could not reach https://tcrn.ch/2G8eniG
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 247, in resolve_redirects
    **adapter_kwargs
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 59%|█████▊    | 615/1049 [10:37<04:31,  1.60it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=MBqquBtwaNM
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=MBqquBtwaNM
 59%|█████▊    | 616/1049 [10:38<05:05,  1.42it/s]INFO:__main__:Requesting https://www.thoughtworks.com
INFO:__main__:Getting metadata for https://www.thoughtworks.com
 59%|█████▉    | 617/1049 [10:38<04:04,  1.76it/s]INFO:__main__:Requesting https://conjur.org
INFO:__main__:Getting metadata for https://www.conjur.org
 59%|█████▉    | 618/1049 [10:39<05:47,  1.24it/s]INFO:__main__:Requesting https://www.conjur.org/careers/engineering.html
INFO:__main__:Getting metadata for https://www.conjur.org/careers/engineering.html
 59%|█████▉    | 619/1049 [10:40<06:30,  1.10it/s]INFO:__main__:Requesting https://blog.conjur.org
INFO:__main__:Getting metadata for https://blog.conjur.org
 59%|█████▉    | 620/1049 [10:42<07:16,  1.02s/it]INFO:__main__:Requesting http://www.aha.io
INFO:__main__:Getting metadata for https://www.aha.io
 59%|█████▉    | 621/1049 [10:43<07:33,  1.06s/it]INFO:__main__:Requesting https://getcruise.com/careers
INFO:__main__:Getting metadata for https://getcruise.com/careers
 59%|█████▉    | 622/1049 [10:44<06:43,  1.06it/s]INFO:__main__:Requesting https://www.waldophotos.com
INFO:__main__:Getting metadata for https://waldophotos.com
 59%|█████▉    | 623/1049 [10:45<07:17,  1.03s/it]INFO:__main__:Requesting https://waldo-photos.workable.com/j/48E1F3547F
INFO:__main__:Getting metadata for https://waldo-photos.workable.com/j/48E1F3547F
 59%|█████▉    | 624/1049 [10:45<06:31,  1.08it/s]INFO:__main__:Requesting https://www.level12.io/careers/
INFO:__main__:Getting metadata for https://www.level12.io/careers/
 60%|█████▉    | 625/1049 [10:46<06:43,  1.05it/s]INFO:__main__:Requesting https://modulate.ai
INFO:__main__:Getting metadata for https://modulate.ai
 60%|█████▉    | 626/1049 [10:47<05:46,  1.22it/s]INFO:__main__:Requesting https://modulate.ai/careers
INFO:__main__:Getting metadata for https://modulate.ai/careers
 60%|█████▉    | 627/1049 [10:47<04:41,  1.50it/s]INFO:__main__:Requesting https://jobs.netflix.com/jobs/866321
INFO:__main__:Getting metadata for https://jobs.netflix.com/jobs/866321
 60%|█████▉    | 628/1049 [10:48<05:08,  1.37it/s]INFO:__main__:Requesting https://www.tundra.com
INFO:__main__:Getting metadata for https://www.tundra.com
 60%|█████▉    | 629/1049 [10:49<05:40,  1.23it/s]INFO:__main__:Requesting https://www.angel.co/tundra
INFO:__main__:Requesting https://www.streak.com/careers/vancouver-site-lead
INFO:__main__:Getting metadata for https://www.streak.com/careers/vancouver-site-lead
 60%|██████    | 631/1049 [10:51<05:46,  1.21it/s]INFO:__main__:Requesting https://www.streak.com/offices/vancouver
INFO:__main__:Getting metadata for https://www.streak.com/offices/vancouver
ERROR:__main__:Could not get metadata for https://www.streak.com/offices/vancouver
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 60%|██████    | 632/1049 [10:52<06:46,  1.02it/s]INFO:__main__:Requesting https://www.reforge.com
INFO:__main__:Getting metadata for https://www.reforge.com
 60%|██████    | 633/1049 [10:53<05:56,  1.17it/s]INFO:__main__:Requesting https://www.codeweavers.com/about/jobs
INFO:__main__:Getting metadata for https://www.codeweavers.com/about/jobs
 60%|██████    | 634/1049 [10:54<06:12,  1.11it/s]INFO:__main__:Requesting https://github.com/commaai/openpilot
INFO:__main__:Getting metadata for https://github.com/commaai/openpilot
 61%|██████    | 635/1049 [10:55<06:25,  1.07it/s]INFO:__main__:Requesting http://developer.paypal.com
INFO:__main__:Getting metadata for https://developer.paypal.com
 61%|██████    | 636/1049 [10:57<08:40,  1.26s/it]INFO:__main__:Requesting https://carta.com
INFO:__main__:Getting metadata for https://carta.com
 61%|██████    | 637/1049 [10:57<06:34,  1.04it/s]INFO:__main__:Requesting https://www.patientsknowbest.com/careers.html
INFO:__main__:Getting metadata for https://www.patientsknowbest.com/careers.html
 61%|██████    | 638/1049 [10:58<06:00,  1.14it/s]INFO:__main__:Requesting https://www.amazon.jobs/en/jobs/795613/software-development-manager-hpc
INFO:__main__:Getting metadata for https://www.amazon.jobs/en/jobs/795613/software-development-manager-hpc
 61%|██████    | 639/1049 [10:58<05:15,  1.30it/s]INFO:__main__:Requesting http://boofla.io/jobs
INFO:__main__:Getting metadata for https://github.com/awsboofla/jobs/blob/master/README.md
 61%|██████    | 640/1049 [11:00<06:25,  1.06it/s]INFO:__main__:Requesting https://www.sumologic.com
INFO:__main__:Getting metadata for https://www.sumologic.com
 61%|██████    | 641/1049 [11:00<05:01,  1.35it/s]INFO:__main__:Requesting https://boards.greenhouse.io/sumologic/jobs/1080682
INFO:__main__:Getting metadata for https://boards.greenhouse.io/sumologic/jobs/1080682
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/sumologic/jobs/1080682
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 61%|██████    | 642/1049 [11:00<04:24,  1.54it/s]INFO:__main__:Requesting https://boards.greenhouse.io/sumologic/jobs/1252374
INFO:__main__:Getting metadata for https://boards.greenhouse.io/sumologic/jobs/1252374
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/sumologic/jobs/1252374
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 61%|██████▏   | 643/1049 [11:01<03:55,  1.72it/s]INFO:__main__:Requesting https://boards.greenhouse.io/sumologic/jobs/1284018
INFO:__main__:Getting metadata for https://boards.greenhouse.io/sumologic/jobs/1284018
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/sumologic/jobs/1284018
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 61%|██████▏   | 644/1049 [11:01<03:30,  1.92it/s]INFO:__main__:Requesting https://www.uken.com
INFO:__main__:Getting metadata for https://www.uken.com
ERROR:__main__:Could not get metadata for https://www.uken.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 61%|██████▏   | 645/1049 [11:02<04:26,  1.52it/s]INFO:__main__:Requesting http://uken.com
INFO:__main__:Getting metadata for https://uken.com:443
ERROR:__main__:Could not get metadata for https://uken.com:443
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 62%|██████▏   | 646/1049 [11:03<05:03,  1.33it/s]INFO:__main__:Requesting https://quarkworks.co/careers/
INFO:__main__:Getting metadata for https://quarkworks.co/careers/
 62%|██████▏   | 647/1049 [11:04<05:40,  1.18it/s]INFO:__main__:Requesting https://squareup.com/careers/jobs
INFO:__main__:Getting metadata for https://squareup.com/careers/jobs
ERROR:__main__:Could not get metadata for https://squareup.com/careers/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 62%|██████▏   | 648/1049 [11:06<07:48,  1.17s/it]INFO:__main__:Requesting https://jobs.cisco.com/jobs/ProjectDetail/Software-Engineer/1253714
INFO:__main__:Getting metadata for https://jobs.cisco.com/jobs/ProjectDetail/Software-Engineer/1253714
 62%|██████▏   | 649/1049 [11:08<10:11,  1.53s/it]INFO:__main__:Requesting https://jobs.cisco.com/jobs/ProjectDetail/Software-Engineer/1254547
INFO:__main__:Getting metadata for https://jobs.cisco.com/jobs/Error
 62%|██████▏   | 650/1049 [11:10<10:19,  1.55s/it]INFO:__main__:Requesting http://www.icontracts.com/policy-management
INFO:__main__:Getting metadata for https://www.icontracts.com/policy-management/
 62%|██████▏   | 651/1049 [11:11<09:41,  1.46s/it]INFO:__main__:Requesting http://bit.ly/pstat-jobs-2019-github
INFO:__main__:Getting metadata for https://github.com/PolicyStat/jobs
 62%|██████▏   | 652/1049 [11:12<08:27,  1.28s/it]INFO:__main__:Requesting http://bit.ly/pstat-jobs-react-2019
INFO:__main__:Getting metadata for https://github.com/PolicyStat/jobs/blob/master/front_end_react_engineer.md
 62%|██████▏   | 653/1049 [11:13<07:48,  1.18s/it]INFO:__main__:Requesting http://bit.ly/pstat-jobs-python-django-2019
INFO:__main__:Getting metadata for https://github.com/PolicyStat/jobs/blob/master/python_django_engineer.md
 62%|██████▏   | 654/1049 [11:14<07:20,  1.12s/it]INFO:__main__:Requesting http://bit.ly/pstat-jobs-java-grails-2019
INFO:__main__:Getting metadata for https://github.com/PolicyStat/jobs/blob/master/java_grails_engineer.md
 62%|██████▏   | 655/1049 [11:15<07:42,  1.17s/it]INFO:__main__:Requesting https://angel.co/airgrid/jobs
INFO:__main__:Requesting https://www.airgrid.io/
INFO:__main__:Getting metadata for https://www.airgrid.io
 63%|██████▎   | 657/1049 [11:16<05:49,  1.12it/s]INFO:__main__:Requesting https://cobaltrobotics.com/
 63%|██████▎   | 658/1049 [11:16<04:38,  1.41it/s]INFO:__main__:Requesting https://cobaltrobotics.com/about/
 63%|██████▎   | 659/1049 [11:16<03:44,  1.74it/s]INFO:__main__:Requesting https://cobaltrobotics.com/careers/
 63%|██████▎   | 660/1049 [11:17<02:58,  2.18it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/e00d5c11-7bc1-4255-aca5-ada02dbd6a83
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/e00d5c11-7bc1-4255-aca5-ada02dbd6a83
 63%|██████▎   | 661/1049 [11:17<03:12,  2.02it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/82ae1594-1a43-46f0-b36a-5fa6695ce73c
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/82ae1594-1a43-46f0-b36a-5fa6695ce73c
 63%|██████▎   | 662/1049 [11:18<03:21,  1.92it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/a2caf247-568b-4046-8359-15b07cb813fd
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/a2caf247-568b-4046-8359-15b07cb813fd
 63%|██████▎   | 663/1049 [11:18<03:29,  1.84it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/17b3d320-ccf0-4dc5-bc78-3d1900096ae2
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/17b3d320-ccf0-4dc5-bc78-3d1900096ae2
 63%|██████▎   | 664/1049 [11:19<03:33,  1.80it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/ec249d41-ab2d-4485-a440-ae2e2b682dbc
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/ec249d41-ab2d-4485-a440-ae2e2b682dbc
 63%|██████▎   | 665/1049 [11:19<03:36,  1.77it/s]INFO:__main__:Requesting https://www.worldviz.com/about/virtual-reality-careers
INFO:__main__:Getting metadata for https://www.worldviz.com/about/virtual-reality-careers
 63%|██████▎   | 666/1049 [11:20<03:27,  1.85it/s]INFO:__main__:Requesting https://www.structionsite.com
INFO:__main__:Getting metadata for https://www.structionsite.com
 64%|██████▎   | 667/1049 [11:20<03:14,  1.97it/s]INFO:__main__:Requesting https://www.omadahealth.com/press/press-release-omada-health-adds-new-programs-fortype-2-diabetes-and-hypertension-self-management
INFO:__main__:Getting metadata for https://www.omadahealth.com/press/press-release-omada-health-adds-new-programs-fortype-2-diabetes-and-hypertension-self-management
 64%|██████▎   | 668/1049 [11:21<03:08,  2.02it/s]INFO:__main__:Requesting https://www.omadahealth.com/press/press-release-omada-health-expanding-to-serve-individuals-with-depression-and-anxiety
INFO:__main__:Getting metadata for https://www.omadahealth.com/press/press-release-omada-health-expanding-to-serve-individuals-with-depression-and-anxiety
 64%|██████▍   | 669/1049 [11:21<02:57,  2.14it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1162609
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1162609
 64%|██████▍   | 670/1049 [11:22<02:59,  2.12it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1162607
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1162607
 64%|██████▍   | 671/1049 [11:22<03:08,  2.00it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1069795
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1069795
 64%|██████▍   | 672/1049 [11:23<03:07,  2.01it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1544470
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1544470
 64%|██████▍   | 673/1049 [11:23<03:08,  2.00it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1508368
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1508368
 64%|██████▍   | 674/1049 [11:24<03:05,  2.02it/s]INFO:__main__:Requesting https://www.makelovenotporn.com/
INFO:__main__:Getting metadata for https://www.makelovenotporn.com
ERROR:__main__:Could not get metadata for https://www.makelovenotporn.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 64%|██████▍   | 675/1049 [11:24<03:13,  1.94it/s]INFO:__main__:Requesting https://blog.ted.com/cindy_gallop_ma/
ERROR:__main__:Could not reach https://blog.ted.com/cindy_gallop_ma/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 64%|██████▍   | 676/1049 [11:24<02:30,  2.47it/s]INFO:__main__:Requesting https://nowthisnews.com/videos/future/make-love-not-porn-founder-on-starting-a-social-sex-revolution
INFO:__main__:Getting metadata for https://nowthisnews.com/videos/future/make-love-not-porn-founder-on-starting-a-social-sex-revolution
 65%|██████▍   | 677/1049 [11:25<02:16,  2.73it/s]INFO:__main__:Requesting https://techcrunch.com/2018/01/21/sex-the-final-frontier-cindy-gallop-raises-2m-from-mysterious-investor-for-social-sex-tech/
ERROR:__main__:Could not reach https://techcrunch.com/2018/01/21/sex-the-final-frontier-cindy-gallop-raises-2m-from-mysterious-investor-for-social-sex-tech/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 65%|██████▍   | 678/1049 [11:25<01:48,  3.43it/s]INFO:__main__:Requesting https://makelovenotporn.tv/jobs
INFO:__main__:Getting metadata for https://makelovenotporn.tv/jobs
ERROR:__main__:Could not get metadata for https://makelovenotporn.tv/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 65%|██████▍   | 679/1049 [11:25<01:56,  3.16it/s]INFO:__main__:Requesting https://thinkpacifica.com/
INFO:__main__:Getting metadata for https://www.thinkpacifica.com
 65%|██████▍   | 680/1049 [11:28<05:52,  1.05it/s]INFO:__main__:Requesting http://appliedinformaticsinc.com/
INFO:__main__:Getting metadata for https://appliedinformaticsinc.com
 65%|██████▍   | 681/1049 [11:29<07:20,  1.20s/it]INFO:__main__:Requesting https://matterapp.com
INFO:__main__:Getting metadata for https://matterapp.com
 65%|██████▌   | 682/1049 [11:30<05:59,  1.02it/s]INFO:__main__:Requesting https://slackatwork.com/job/matter-san-francisco-california-2-full-stack-engineer-react-graphql-typescript/
INFO:__main__:Getting metadata for https://slackatwork.com/job/matter-san-francisco-california-2-full-stack-engineer-react-graphql-typescript/
 65%|██████▌   | 683/1049 [11:31<06:15,  1.03s/it]INFO:__main__:Requesting https://aclaimant.com/careers-developer
INFO:__main__:Getting metadata for https://aclaimant.com/careers-developer
 65%|██████▌   | 684/1049 [11:32<05:34,  1.09it/s]INFO:__main__:Requesting https://degica.com
INFO:__main__:Getting metadata for https://degica.com
 65%|██████▌   | 685/1049 [11:32<04:24,  1.38it/s]INFO:__main__:Requesting https://degica.com/careers.html
INFO:__main__:Getting metadata for https://degica.com/careers.html
ERROR:__main__:Could not get metadata for https://degica.com/careers.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 65%|██████▌   | 686/1049 [11:32<03:47,  1.60it/s]INFO:__main__:Requesting https://www.latelieranimation.com/
INFO:__main__:Getting metadata for https://www.latelieranimation.com
ERROR:__main__:Could not get metadata for https://www.latelieranimation.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 65%|██████▌   | 687/1049 [11:35<06:47,  1.13s/it]INFO:__main__:Requesting https://latelieranimation.recruiterbox.com/jobs/fk01o6t/
INFO:__main__:Getting metadata for https://latelieranimation.recruiterbox.com/jobs/fk01o6t/
 66%|██████▌   | 688/1049 [11:35<05:58,  1.01it/s]INFO:__main__:Requesting https://www.ecobee.com/jobs
INFO:__main__:Getting metadata for https://www.ecobee.com/careers/
 66%|██████▌   | 689/1049 [11:38<07:59,  1.33s/it]INFO:__main__:Requesting https://www.kirasystems.com/careers/
INFO:__main__:Getting metadata for https://www.kirasystems.com/careers/
 66%|██████▌   | 690/1049 [11:38<06:06,  1.02s/it]INFO:__main__:Requesting http://bit.ly/2UmKm2w
INFO:__main__:Getting metadata for https://elevate-security.breezy.hr
 66%|██████▌   | 691/1049 [11:39<06:24,  1.07s/it]INFO:__main__:Requesting https://opslock.com/jobs
INFO:__main__:Getting metadata for https://opslock.com/jobs
 66%|██████▌   | 692/1049 [11:41<07:21,  1.24s/it]INFO:__main__:Requesting https://karriere.re-lounge.com/
INFO:__main__:Getting metadata for https://karriere.re-lounge.com
 66%|██████▌   | 693/1049 [11:44<10:48,  1.82s/it]INFO:__main__:Requesting https://sensortower.com
INFO:__main__:Getting metadata for https://sensortower.com
 66%|██████▌   | 694/1049 [11:44<08:14,  1.39s/it]INFO:__main__:Requesting https://www.keyvalues.com/sensor-tower
INFO:__main__:Getting metadata for https://www.keyvalues.com/sensor-tower
 66%|██████▋   | 695/1049 [11:45<07:47,  1.32s/it]INFO:__main__:Requesting https://jobs.lever.co/sensortower/5d633b40-e089-4b81-8f78-8d623403ea9f?lever-origin=applied&lever-source%5B%5D=Key%20Values
INFO:__main__:Getting metadata for https://jobs.lever.co/sensortower/5d633b40-e089-4b81-8f78-8d623403ea9f?lever-origin=applied&lever-source%5B%5D=Key%20Values
 66%|██████▋   | 696/1049 [11:46<06:29,  1.10s/it]INFO:__main__:Requesting https://jobs.lever.co/sensortower/d8e282b5-861a-4495-a951-00acaef2cc35?lever-origin=applied&lever-source%5B%5D=Key%20Values
INFO:__main__:Getting metadata for https://jobs.lever.co/sensortower/d8e282b5-861a-4495-a951-00acaef2cc35?lever-origin=applied&lever-source%5B%5D=Key%20Values
 66%|██████▋   | 697/1049 [11:47<05:33,  1.05it/s]INFO:__main__:Requesting https://jobs.lever.co/sensortower/c171234a-4906-46c3-b609-7d7c8e86963f?lever-origin=applied&lever-source%5B%5D=Key%20Values
INFO:__main__:Getting metadata for https://jobs.lever.co/sensortower/c171234a-4906-46c3-b609-7d7c8e86963f?lever-origin=applied&lever-source%5B%5D=Key%20Values
 67%|██████▋   | 698/1049 [11:47<05:24,  1.08it/s]INFO:__main__:Requesting https://jobs.lever.co/sensortower/a421feb6-2c0e-4f1b-adb1-84d8129b9545?lever-origin=applied&lever-source%5B%5D=Key%20Values
INFO:__main__:Getting metadata for https://jobs.lever.co/sensortower/a421feb6-2c0e-4f1b-adb1-84d8129b9545?lever-origin=applied&lever-source%5B%5D=Key%20Values
 67%|██████▋   | 699/1049 [11:48<04:50,  1.20it/s]INFO:__main__:Requesting https://jobs.lever.co/sensortower/7eb5e065-4107-4bc9-85b5-99dc9009180b?lever-origin=applied&lever-source%5B%5D=Key%20Values
INFO:__main__:Getting metadata for https://jobs.lever.co/sensortower/7eb5e065-4107-4bc9-85b5-99dc9009180b?lever-origin=applied&lever-source%5B%5D=Key%20Values
 67%|██████▋   | 700/1049 [11:49<04:31,  1.28it/s]INFO:__main__:Requesting https://jobs.lever.co/sensortower/7442e664-c7ff-4221-8ac7-6e99bca8b0b8?lever-origin=applied&lever-source%5B%5D=Key%20Values
INFO:__main__:Getting metadata for https://jobs.lever.co/sensortower/7442e664-c7ff-4221-8ac7-6e99bca8b0b8?lever-origin=applied&lever-source%5B%5D=Key%20Values
 67%|██████▋   | 701/1049 [11:49<04:10,  1.39it/s]INFO:__main__:Requesting https://grnh.se/0c1301b91
INFO:__main__:Getting metadata for https://boards.greenhouse.io/mozilla/jobs/1527520?gh_src=0c1301b91
 67%|██████▋   | 702/1049 [11:50<03:58,  1.46it/s]INFO:__main__:Requesting https://grnh.se/7bd67d631
INFO:__main__:Getting metadata for https://boards.greenhouse.io/mozilla/jobs/1527522?gh_src=7bd67d631
 67%|██████▋   | 703/1049 [11:50<03:48,  1.51it/s]INFO:__main__:Requesting https://www.ngpvan.com/careers
INFO:__main__:Getting metadata for https://www.ngpvan.com/careers
 67%|██████▋   | 704/1049 [11:51<03:29,  1.65it/s]INFO:__main__:Requesting https://www.accurx.com/careers
INFO:__main__:Getting metadata for https://www.accurx.com/careers
ERROR:__main__:Could not get metadata for https://www.accurx.com/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 67%|██████▋   | 705/1049 [11:54<07:28,  1.30s/it]INFO:__main__:Requesting https://techcrunch.com/2019/02/24/accurx/
ERROR:__main__:Could not reach https://techcrunch.com/2019/02/24/accurx/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 67%|██████▋   | 706/1049 [11:54<05:25,  1.05it/s]INFO:__main__:Requesting https://www.conductor.com/careers
INFO:__main__:Getting metadata for https://www.conductor.com/careers/
 67%|██████▋   | 707/1049 [11:56<07:19,  1.28s/it]INFO:__main__:Requesting https://gravitational.com
ERROR:__main__:Could not reach https://gravitational.com
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='gravitational.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='gravitational.com', port=443): Read timed out. (read timeout=6)
 67%|██████▋   | 708/1049 [12:02<15:32,  2.74s/it]INFO:__main__:Requesting https://gravitational.com/about#jobs
INFO:__main__:Getting metadata for https://gravitational.com/about#jobs
 68%|██████▊   | 709/1049 [12:03<12:06,  2.14s/it]INFO:__main__:Requesting https://github.com/gravitational/careers/blob/master/systems..
 68%|██████▊   | 710/1049 [12:03<08:52,  1.57s/it]INFO:__main__:Requesting https://www.mailgun.com
INFO:__main__:Getting metadata for https://www.mailgun.com
 68%|██████▊   | 711/1049 [12:03<06:24,  1.14s/it]INFO:__main__:Requesting https://github.com/vulcand/vulcand
INFO:__main__:Getting metadata for https://github.com/vulcand/vulcand
 68%|██████▊   | 712/1049 [12:04<06:08,  1.09s/it]INFO:__main__:Requesting https://www.rackspace.com/cloud/servers/onmetal
INFO:__main__:Getting metadata for https://www.rackspace.com/cloud/servers/onmetal
 68%|██████▊   | 713/1049 [12:06<06:47,  1.21s/it]INFO:__main__:Requesting https://github.com/gravitational/teleport
INFO:__main__:Getting metadata for https://github.com/gravitational/teleport
 68%|██████▊   | 714/1049 [12:07<06:35,  1.18s/it]INFO:__main__:Requesting https://github.com/gravitational/gravity
INFO:__main__:Getting metadata for https://github.com/gravitational/gravity
 68%|██████▊   | 715/1049 [12:08<06:10,  1.11s/it]INFO:__main__:Requesting https://www.teleconsole.com/
INFO:__main__:Getting metadata for https://www.teleconsole.com
 68%|██████▊   | 716/1049 [12:09<06:01,  1.09s/it]INFO:__main__:Requesting https://codelitt-incubator.workable.com/
INFO:__main__:Getting metadata for https://codelitt-incubator.workable.com
ERROR:__main__:Could not get metadata for https://codelitt-incubator.workable.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 68%|██████▊   | 717/1049 [12:09<05:11,  1.06it/s]INFO:__main__:Requesting https://www.investec.co.uk
INFO:__main__:Getting metadata for https://www.investec.com/en_gb.html
 68%|██████▊   | 718/1049 [12:11<05:55,  1.07s/it]INFO:__main__:Requesting http://grnh.se/3rolbe1
INFO:__main__:Getting metadata for https://www.stashinvest.com/careers?gh_src=3rolbe1
 69%|██████▊   | 719/1049 [12:12<05:45,  1.05s/it]INFO:__main__:Requesting https://www.simplesurance.com/
INFO:__main__:Getting metadata for https://www.simplesurance.com
 69%|██████▊   | 720/1049 [12:13<05:34,  1.02s/it]INFO:__main__:Requesting https://blog.ycombinator.com/thoughts-on-insurance/
INFO:__main__:Getting metadata for https://blog.ycombinator.com/thoughts-on-insurance/
 69%|██████▊   | 721/1049 [12:13<04:40,  1.17it/s]INFO:__main__:Requesting https://www.simplesurance.com/careers/
ERROR:__main__:Could not reach https://www.simplesurance.com/careers/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.simplesurance.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.simplesurance.com', port=443): Read timed out. (read timeout=6)
 69%|██████▉   | 722/1049 [12:19<13:11,  2.42s/it]INFO:__main__:Requesting https://jobs.polymathv.com/bbec85be1
INFO:__main__:Getting metadata for https://polymathv.com/join-us/1083600/Desarrollador+M%C3%B3vil+Android/#bbec85be1
 69%|██████▉   | 723/1049 [12:20<10:48,  1.99s/it]INFO:__main__:Requesting https://grnh.se/6d73e4a71
INFO:__main__:Getting metadata for https://newsela.com/company/jobs/?gh_src=6d73e4a71
 69%|██████▉   | 724/1049 [12:21<08:51,  1.64s/it]INFO:__main__:Requesting https://www.tanookilabs.com/jobs
INFO:__main__:Getting metadata for https://www.tanookilabs.com/jobs
ERROR:__main__:Could not get metadata for https://www.tanookilabs.com/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 69%|██████▉   | 725/1049 [12:22<07:23,  1.37s/it]INFO:__main__:Requesting https://getbyrd.com
INFO:__main__:Getting metadata for https://getbyrd.com
 69%|██████▉   | 726/1049 [12:23<07:40,  1.43s/it]INFO:__main__:Requesting https://getbyrd.com/en/jobs/
INFO:__main__:Getting metadata for https://getbyrd.com/en/jobs/
ERROR:__main__:Could not get metadata for https://getbyrd.com/en/jobs/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 69%|██████▉   | 727/1049 [12:25<07:39,  1.43s/it]INFO:__main__:Requesting https://raise.me
ERROR:urllib3.connection:Certificate did not match expected hostname: raise.me. Certificate: {'subject': ((('commonName', '*.raise.me'),),), 'issuer': ((('countryName', 'US'),), (('organizationName', 'Amazon'),), (('organizationalUnitName', 'Server CA 1B'),), (('commonName', 'Amazon'),)), 'version': 3, 'serialNumber': '08E6D1DCEE6609893596902908C163D5', 'notBefore': 'Oct 18 00:00:00 2018 GMT', 'notAfter': 'Nov 18 12:00:00 2019 GMT', 'subjectAltName': (('DNS', '*.raise.me'),), 'OCSP': ('http://ocsp.sca1b.amazontrust.com',), 'caIssuers': ('http://crt.sca1b.amazontrust.com/sca1b.crt',), 'crlDistributionPoints': ('http://crl.sca1b.amazontrust.com/sca1b.crl',)}
ERROR:__main__:Could not reach https://raise.me
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 364, in connect
    _match_hostname(cert, self.assert_hostname or server_hostname)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 374, in _match_hostname
    match_hostname(cert, asserted_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 331, in match_hostname
    % (hostname, dnsnames[0]))
ssl.CertificateError: hostname 'raise.me' doesn't match '*.raise.me'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raise.me', port=443): Max retries exceeded with url: / (Caused by SSLError(CertificateError("hostname 'raise.me' doesn't match '*.raise.me'",),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='raise.me', port=443): Max retries exceeded with url: / (Caused by SSLError(CertificateError("hostname 'raise.me' doesn't match '*.raise.me'",),))
 69%|██████▉   | 728/1049 [12:25<05:31,  1.03s/it]INFO:__main__:Requesting https://impact.vice.com/en_us/article/ne3yvm/students-earned-dollar1-billion-in-college-scholarships-using-their-smartphones
INFO:__main__:Getting metadata for https://impact.vice.com/en_us/article/ne3yvm/students-earned-dollar1-billion-in-college-scholarships-using-their-smartphones
 69%|██████▉   | 729/1049 [12:26<05:56,  1.12s/it]INFO:__main__:Requesting https://www.fastcompany.com/90206816/exclusive-zuckerberg-backed-micro-scholarship-startup-raises-15-million
INFO:__main__:Getting metadata for https://www.fastcompany.com/90206816/exclusive-zuckerberg-backed-micro-scholarship-startup-raises-15-million
 70%|██████▉   | 730/1049 [12:27<04:50,  1.10it/s]INFO:__main__:Requesting https://www.edsurge.com/news/2018-07-26-raiseme-gets-15m-to-help-students-cut-college-costs-if-they-do-well-in-school
INFO:__main__:Getting metadata for https://www.edsurge.com/news/2018-07-26-raiseme-gets-15m-to-help-students-cut-college-costs-if-they-do-well-in-school
ERROR:__main__:Could not get metadata for https://www.edsurge.com/news/2018-07-26-raiseme-gets-15m-to-help-students-cut-college-costs-if-they-do-well-in-school
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|██████▉   | 731/1049 [12:27<04:36,  1.15it/s]INFO:__main__:Requesting https://www.raise.me/jobs
INFO:__main__:Getting metadata for https://www.raise.me/jobs
 70%|██████▉   | 732/1049 [12:28<04:26,  1.19it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/handybookcom/view/P_AAAAAADAAADNLu-DW6w0so
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/handybookcom/view/P_AAAAAADAAADNLu-DW6w0so
 70%|██████▉   | 733/1049 [12:29<03:39,  1.44it/s]INFO:__main__:Requesting https://www.bitexpert.de
INFO:__main__:Getting metadata for https://www.bitexpert.de
ERROR:__main__:Could not get metadata for https://www.bitexpert.de
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|██████▉   | 734/1049 [12:30<04:58,  1.06it/s]INFO:__main__:Requesting https://www.keyvalues.com/bitexpert
INFO:__main__:Getting metadata for https://www.keyvalues.com/bitexpert
 70%|███████   | 735/1049 [12:32<05:35,  1.07s/it]INFO:__main__:Requesting https://www.bitexpert.de/karriere/softwareentwicklerin/?ref=keyvalues
INFO:__main__:Getting metadata for https://www.bitexpert.de/karriere/softwareentwicklerin/?ref=keyvalues
ERROR:__main__:Could not get metadata for https://www.bitexpert.de/karriere/softwareentwicklerin/?ref=keyvalues
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|███████   | 736/1049 [12:33<05:56,  1.14s/it]INFO:__main__:Requesting https://www.bitexpert.de/karriere/magento-entwicklerin/?ref=keyvalues
INFO:__main__:Getting metadata for https://www.bitexpert.de/karriere/magento-entwicklerin/?ref=keyvalues
ERROR:__main__:Could not get metadata for https://www.bitexpert.de/karriere/magento-entwicklerin/?ref=keyvalues
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|███████   | 737/1049 [12:34<06:11,  1.19s/it]INFO:__main__:Requesting https://www.bitexpert.de/karriere/php-entwicklerin/?ref=keyvalues
INFO:__main__:Getting metadata for https://www.bitexpert.de/karriere/php-entwicklerin/?ref=keyvalues
ERROR:__main__:Could not get metadata for https://www.bitexpert.de/karriere/php-entwicklerin/?ref=keyvalues
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|███████   | 738/1049 [12:35<06:19,  1.22s/it]INFO:__main__:Requesting https://www.epirussystems.com/careers
INFO:__main__:Getting metadata for https://www.epirussystems.com/careers
 70%|███████   | 739/1049 [12:36<05:30,  1.06s/it]INFO:__main__:Requesting https://www.swarm.space/
INFO:__main__:Getting metadata for https://www.swarm.space
ERROR:__main__:Could not get metadata for https://www.swarm.space
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 740/1049 [12:37<04:54,  1.05it/s]INFO:__main__:Requesting https://www.swarm.space/careers
INFO:__main__:Getting metadata for https://www.swarm.space/careers
ERROR:__main__:Could not get metadata for https://www.swarm.space/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 741/1049 [12:37<04:10,  1.23it/s]INFO:__main__:Requesting https://www.mapudo.com/content/mapudo/jobs-fullstack-developer-core-platform-team/
INFO:__main__:Getting metadata for https://www.mapudo.com/content/mapudo/jobs-fullstack-developer-core-platform-team/
 71%|███████   | 742/1049 [12:38<04:20,  1.18it/s]INFO:__main__:Requesting https://www.carbonblack.com
INFO:__main__:Getting metadata for https://www.carbonblack.com
 71%|███████   | 743/1049 [12:39<03:43,  1.37it/s]INFO:__main__:Requesting https://www.keyvalues.com/carbon-black
INFO:__main__:Getting metadata for https://www.keyvalues.com/carbon-black
 71%|███████   | 744/1049 [12:40<04:52,  1.04it/s]INFO:__main__:Requesting https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb
INFO:__main__:Getting metadata for https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb
ERROR:__main__:Could not get metadata for https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 745/1049 [12:48<15:32,  3.07s/it]INFO:__main__:Requesting https://www.custora.com
INFO:__main__:Getting metadata for https://www.custora.com
 71%|███████   | 746/1049 [12:49<11:39,  2.31s/it]INFO:__main__:Requesting https://www.keyvalues.com/custora
INFO:__main__:Getting metadata for https://www.keyvalues.com/custora
 71%|███████   | 747/1049 [12:50<09:36,  1.91s/it]INFO:__main__:Requesting https://grnh.se/2f70d01c1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/1174709?gh_src=2f70d01c1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/1174709?gh_src=2f70d01c1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 71%|███████▏  | 748/1049 [12:50<07:45,  1.55s/it]INFO:__main__:Requesting https://grnh.se/cdae713f1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/1390706?gh_src=cdae713f1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/1390706?gh_src=cdae713f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 71%|███████▏  | 749/1049 [12:51<06:17,  1.26s/it]INFO:__main__:Requesting https://grnh.se/18bf836b1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/1320098?gh_src=18bf836b1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/1320098?gh_src=18bf836b1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 71%|███████▏  | 750/1049 [12:52<05:19,  1.07s/it]INFO:__main__:Requesting https://grnh.se/02e167501
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/1315503?gh_src=02e167501
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/1315503?gh_src=02e167501
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 72%|███████▏  | 751/1049 [12:53<05:58,  1.20s/it]INFO:__main__:Requesting https://grnh.se/58b316961
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/54322?gh_src=58b316961
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/54322?gh_src=58b316961
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 72%|███████▏  | 752/1049 [12:54<05:04,  1.03s/it]INFO:__main__:Requesting https://www.pmd.com/reviews
INFO:__main__:Getting metadata for https://www.pmd.com/reviews
 72%|███████▏  | 753/1049 [12:58<10:26,  2.12s/it]INFO:__main__:Requesting https://www.pmd.com/careers
INFO:__main__:Getting metadata for https://www.pmd.com/careers
 72%|███████▏  | 754/1049 [13:00<09:19,  1.90s/it]INFO:__main__:Requesting https://www.lumiata.com/careers.html
INFO:__main__:Getting metadata for https://www.lumiata.com/careers.html
 72%|███████▏  | 755/1049 [13:00<07:23,  1.51s/it]INFO:__main__:Requesting https://www.woflow.com
INFO:__main__:Getting metadata for https://www.woflow.com
 72%|███████▏  | 756/1049 [13:02<07:52,  1.61s/it]INFO:__main__:Requesting https://www.hqo.co
INFO:__main__:Getting metadata for https://www.hqo.co
 72%|███████▏  | 757/1049 [13:03<06:50,  1.41s/it]INFO:__main__:Requesting https://hqo.applytojob.com/apply/0s1ByARDjq/Back-End-Engineer?referrer=20190301164009QPYRPR9O6O5UIE3N
INFO:__main__:Getting metadata for https://hqo.applytojob.com/apply/0s1ByARDjq/Back-End-Engineer?referrer=20190301164009QPYRPR9O6O5UIE3N
 72%|███████▏  | 758/1049 [13:04<06:20,  1.31s/it]INFO:__main__:Requesting https://hqo.applytojob.com/apply/xulftv47ax/Front-End-Engineer?referrer=20190301164037LOMAR2PBCQ81QAPH
INFO:__main__:Getting metadata for https://hqo.applytojob.com/apply/xulftv47ax/Front-End-Engineer?referrer=20190301164037LOMAR2PBCQ81QAPH
 72%|███████▏  | 759/1049 [13:05<05:56,  1.23s/it]INFO:__main__:Requesting https://hqo.applytojob.com/apply/JfW73j99yr/UXUI-Designer?referrer=20190301164129JFPVUQ8HOH1XLXGP
INFO:__main__:Getting metadata for https://hqo.applytojob.com/apply/JfW73j99yr/UXUI-Designer?referrer=20190301164129JFPVUQ8HOH1XLXGP
 72%|███████▏  | 760/1049 [13:06<05:34,  1.16s/it]INFO:__main__:Requesting https://hqo.applytojob.com/apply/cdADITCOdS/Product-Manager?referrer=201903011642173DUESZLFFTQPOXZQ
INFO:__main__:Getting metadata for https://hqo.applytojob.com/apply/cdADITCOdS/Product-Manager?referrer=201903011642173DUESZLFFTQPOXZQ
 73%|███████▎  | 761/1049 [13:07<05:30,  1.15s/it]INFO:__main__:Requesting https://mytrellis.com/
INFO:__main__:Getting metadata for https://mytrellis.com
 73%|███████▎  | 762/1049 [13:08<04:54,  1.03s/it]INFO:__main__:Requesting https://mytrellis.com/available-opportunities/software-developer
INFO:__main__:Getting metadata for https://mytrellis.com/available-opportunities/software-developer
 73%|███████▎  | 763/1049 [13:09<04:23,  1.08it/s]INFO:__main__:Requesting https://www.patientcolife.com/jobs/team-lead-software-engineering/
INFO:__main__:Getting metadata for https://www.patientcolife.com/jobs/team-lead-software-engineering/
ERROR:__main__:Could not get metadata for https://www.patientcolife.com/jobs/team-lead-software-engineering/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 73%|███████▎  | 764/1049 [13:09<03:20,  1.42it/s]INFO:__main__:Requesting https://www.linkedin.com/jobs/view/python-backend-web-developer-software-developer-iii-non-it-at-bio-rad-laboratories-921319545/
 73%|███████▎  | 765/1049 [13:09<02:51,  1.66it/s]INFO:__main__:Requesting https://boards.greenhouse.io/theinfatuation
INFO:__main__:Getting metadata for https://boards.greenhouse.io/theinfatuation
 73%|███████▎  | 766/1049 [13:10<02:27,  1.92it/s]INFO:__main__:Requesting https://15five.com
INFO:__main__:Getting metadata for https://www.15five.com
 73%|███████▎  | 767/1049 [13:10<02:31,  1.86it/s]INFO:__main__:Requesting https://jobs.lever.co/15five/87e81f76-7785-4bef-a005-c8ae3d6796b5?lever-origin=applied&lever-source%5B%5D=HN
INFO:__main__:Getting metadata for https://jobs.lever.co/15five/87e81f76-7785-4bef-a005-c8ae3d6796b5?lever-origin=applied&lever-source%5B%5D=HN
 73%|███████▎  | 768/1049 [13:11<02:52,  1.63it/s]INFO:__main__:Requesting https://jobs.lever.co/15five/4fc7917c-3706-450f-9bc0-d7fb080d2e24?lever-source%5B%5D=HN
INFO:__main__:Getting metadata for https://jobs.lever.co/15five/4fc7917c-3706-450f-9bc0-d7fb080d2e24?lever-source%5B%5D=HN
 73%|███████▎  | 769/1049 [13:12<02:55,  1.60it/s]INFO:__main__:Requesting https://jobs.lever.co/15five/b6e90d36-36b5-4062-b9cb-d5af4687e2d3?lever-origin=applied&lever-source%5B%5D=HN
INFO:__main__:Getting metadata for https://jobs.lever.co/15five/b6e90d36-36b5-4062-b9cb-d5af4687e2d3?lever-origin=applied&lever-source%5B%5D=HN
 73%|███████▎  | 770/1049 [13:12<02:52,  1.62it/s]INFO:__main__:Requesting https://www.15five.com/core-values/
INFO:__main__:Getting metadata for https://www.15five.com/core-values/
 73%|███████▎  | 771/1049 [13:13<02:27,  1.88it/s]INFO:__main__:Requesting https://www.bluecatnetworks.com/careers/
INFO:__main__:Getting metadata for https://www.bluecatnetworks.com/careers/
 74%|███████▎  | 772/1049 [13:13<02:12,  2.10it/s]INFO:__main__:Requesting https://careers.smartrecruiters.com/Thinknum/
INFO:__main__:Getting metadata for https://careers.smartrecruiters.com/Thinknum/
 74%|███████▎  | 773/1049 [13:15<03:57,  1.16it/s]INFO:__main__:Requesting https://www.thinknum.com
INFO:__main__:Getting metadata for https://www.thinknum.com
 74%|███████▍  | 774/1049 [13:16<03:49,  1.20it/s]INFO:__main__:Requesting https://www.bigfishgames.com
INFO:__main__:Getting metadata for https://www.bigfishgames.com
 74%|███████▍  | 775/1049 [13:17<04:56,  1.08s/it]INFO:__main__:Requesting https://app.jobvite.com/j?cj=o3yX8fwq&s=HN
INFO:__main__:Getting metadata for http://jobs.jobvite.com/careers/bigfish/job/o3yX8fwq?__jvst=Job+Board&__jvsd=HN
 74%|███████▍  | 776/1049 [13:18<04:20,  1.05it/s]INFO:__main__:Requesting http://www.recursionpharma.com/careers
INFO:__main__:Getting metadata for https://www.recursionpharma.com/careers/
 74%|███████▍  | 777/1049 [13:18<03:49,  1.19it/s]INFO:__main__:Requesting http://www.recursionpharma.com/team
INFO:__main__:Getting metadata for https://www.recursionpharma.com/team/
 74%|███████▍  | 778/1049 [13:19<03:36,  1.25it/s]INFO:__main__:Requesting http://www.driveworks.co.uk/jobs/
INFO:__main__:Getting metadata for https://www.driveworks.co.uk/jobs/
 74%|███████▍  | 779/1049 [13:23<07:27,  1.66s/it]INFO:__main__:Requesting https://www.etecture.de/
INFO:__main__:Getting metadata for https://www.etecture.de
 74%|███████▍  | 780/1049 [13:26<09:04,  2.02s/it]INFO:__main__:Requesting https://www.depop.com/about/jobs/66BFF78BC7/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/66BFF78BC7/
 74%|███████▍  | 781/1049 [13:26<06:49,  1.53s/it]INFO:__main__:Requesting https://www.depop.com/about/jobs/CC5C89E62B/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/CC5C89E62B/
 75%|███████▍  | 782/1049 [13:26<05:22,  1.21s/it]INFO:__main__:Requesting https://www.depop.com/about/jobs/92DBE64C63/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/92DBE64C63/
 75%|███████▍  | 783/1049 [13:27<04:24,  1.01it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/E6A167938B/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/E6A167938B/
 75%|███████▍  | 784/1049 [13:27<03:40,  1.20it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/0E6DE2B5C9/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/0E6DE2B5C9/
 75%|███████▍  | 785/1049 [13:28<03:14,  1.36it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/450747CCF9/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/450747CCF9/
 75%|███████▍  | 786/1049 [13:29<03:16,  1.34it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/6B70F6DB04/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/6B70F6DB04/
 75%|███████▌  | 787/1049 [13:29<02:42,  1.61it/s]INFO:__main__:Requesting https://techcrunch.com/2019/01/25/the-predictive-index-brings-in-50m-to-help-businesses-create-winning-teams/
ERROR:__main__:Could not reach https://techcrunch.com/2019/01/25/the-predictive-index-brings-in-50m-to-help-businesses-create-winning-teams/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 75%|███████▌  | 788/1049 [13:29<02:02,  2.13it/s]INFO:__main__:Requesting https://grnh.se/dfc2b9a82
INFO:__main__:Getting metadata for https://boards.greenhouse.io/predictiveindex/jobs/4201099002?gh_src=dfc2b9a82
 75%|███████▌  | 789/1049 [13:30<02:12,  1.96it/s]INFO:__main__:Requesting https://corrux.io/
 75%|███████▌  | 790/1049 [13:30<02:01,  2.14it/s]INFO:__main__:Requesting https://corrux.io/career/
 75%|███████▌  | 791/1049 [13:30<01:38,  2.61it/s]INFO:__main__:Requesting https://www.handelsblatt.com/unternehmen/industrie/start-up-corrux-warum-die-mathematikerin-laura-toennies-als-bagger-fluesterin-gilt/23965996.html
INFO:__main__:Getting metadata for https://www.handelsblatt.com/unternehmen/industrie/start-up-corrux-warum-die-mathematikerin-laura-toennies-als-bagger-fluesterin-gilt/23965996.html?ticket=ST-1977789-XyP1LcOcmWHgOb0BSlDL-ap2
 76%|███████▌  | 792/1049 [13:34<05:59,  1.40s/it]INFO:__main__:Requesting https://tray.io
INFO:__main__:Getting metadata for https://tray.io
 76%|███████▌  | 793/1049 [13:34<04:28,  1.05s/it]INFO:__main__:Requesting https://tray-io.workable.com/jobs/954594
INFO:__main__:Getting metadata for https://tray-io.workable.com/jobs/954594
 76%|███████▌  | 794/1049 [13:35<04:03,  1.05it/s]INFO:__main__:Requesting https://tray-io.workable.com/j/A989E2788E
INFO:__main__:Getting metadata for https://tray-io.workable.com/j/A989E2788E
 76%|███████▌  | 795/1049 [13:36<03:37,  1.17it/s]INFO:__main__:Requesting https://tray-io.workable.com/j/50E49D5631
INFO:__main__:Getting metadata for https://tray-io.workable.com/j/50E49D5631
 76%|███████▌  | 796/1049 [13:36<03:22,  1.25it/s]INFO:__main__:Requesting https://tray-io.workable.com/j/ECA9DB9833
INFO:__main__:Getting metadata for https://tray-io.workable.com/j/ECA9DB9833
 76%|███████▌  | 797/1049 [13:37<03:22,  1.24it/s]INFO:__main__:Requesting https://tray-io.workable.com/j/B966DEFE9F
INFO:__main__:Getting metadata for https://tray-io.workable.com/j/B966DEFE9F
 76%|███████▌  | 798/1049 [13:38<03:13,  1.30it/s]INFO:__main__:Requesting https://tray.io/jobs
INFO:__main__:Getting metadata for https://tray.io/jobs
 76%|███████▌  | 799/1049 [13:38<02:27,  1.70it/s]INFO:__main__:Requesting https://opench.bamboohr.co.uk/jobs/view.php?id=42
INFO:__main__:Getting metadata for https://opench.bamboohr.co.uk/jobs/view.php?id=42
 76%|███████▋  | 800/1049 [13:40<03:40,  1.13it/s]INFO:__main__:Requesting https://opench.bamboohr.co.uk/jobs/view.php?id=111
INFO:__main__:Getting metadata for https://opench.bamboohr.co.uk/jobs/view.php?id=111
 76%|███████▋  | 801/1049 [13:41<04:30,  1.09s/it]INFO:__main__:Requesting https://www.levvel.io
INFO:__main__:Getting metadata for https://www.levvel.io
 76%|███████▋  | 802/1049 [13:43<04:56,  1.20s/it]INFO:__main__:Requesting https://www.levvel.io/our-ideas/Inc-500-Award-2018
INFO:__main__:Getting metadata for https://www.levvel.io/our-ideas/Inc-500-Award-2018
 77%|███████▋  | 803/1049 [13:44<04:36,  1.12s/it]INFO:__main__:Requesting https://www.policygenius.com
INFO:__main__:Getting metadata for https://www.policygenius.com
 77%|███████▋  | 804/1049 [13:44<03:26,  1.19it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1544126
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1544126
 77%|███████▋  | 805/1049 [13:44<02:55,  1.39it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1544131
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1544131
 77%|███████▋  | 806/1049 [13:45<02:30,  1.61it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1558455
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1558455
 77%|███████▋  | 807/1049 [13:45<02:11,  1.84it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1558446
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1558446
 77%|███████▋  | 808/1049 [13:45<02:00,  2.01it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1301195
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1301195
 77%|███████▋  | 809/1049 [13:46<01:51,  2.14it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1301194
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1301194
 77%|███████▋  | 810/1049 [13:46<01:48,  2.21it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1301193
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1301193
 77%|███████▋  | 811/1049 [13:47<01:43,  2.30it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius
 77%|███████▋  | 812/1049 [13:47<01:38,  2.42it/s]INFO:__main__:Requesting https://www.continental-corporation.com/en
INFO:__main__:Getting metadata for https://www.continental-corporation.com/en
 78%|███████▊  | 813/1049 [13:47<01:32,  2.55it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=Cbw716NsIVQ
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=Cbw716NsIVQ
 78%|███████▊  | 814/1049 [13:48<02:03,  1.90it/s]INFO:__main__:Requesting https://www.continental-jobs.com/index.php?ac=jobad&id=999144
INFO:__main__:Getting metadata for https://www.continental-jobs.com/index.php?ac=jobad&id=999144
ERROR:__main__:Could not get metadata for https://www.continental-jobs.com/index.php?ac=jobad&id=999144
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 78%|███████▊  | 815/1049 [13:50<03:33,  1.10it/s]INFO:__main__:Requesting https://jobs.scot.nhs.uk/_results.aspx?catID=&regionID=&orgID=&word=medical%20devices%20unit
INFO:__main__:Getting metadata for https://jobs.scot.nhs.uk/_results.aspx?catID=&regionID=&orgID=&word=medical%20devices%20unit
 78%|███████▊  | 816/1049 [13:53<06:10,  1.59s/it]INFO:__main__:Requesting https://nsidc.org/about/jobs/devops-administrator
INFO:__main__:Getting metadata for https://nsidc.org/about/jobs/devops-administrator
 78%|███████▊  | 817/1049 [13:54<05:22,  1.39s/it]INFO:__main__:Requesting https://jobs.colorado.edu/jobs/JobDetail/?jobId=15411
INFO:__main__:Getting metadata for https://jobs.colorado.edu/jobs/JobDetail/?jobId=15411
 78%|███████▊  | 818/1049 [13:55<04:54,  1.27s/it]INFO:__main__:Requesting https://www.thetradedesk.com/join-us/open-positions
INFO:__main__:Getting metadata for https://www.thetradedesk.com/careers/open-positions
 78%|███████▊  | 819/1049 [13:56<04:31,  1.18s/it]INFO:__main__:Requesting https://synthetic-minds.com/pages/jobs.html
INFO:__main__:Getting metadata for https://synthetic-minds.com/pages/jobs.html
 78%|███████▊  | 820/1049 [13:56<03:42,  1.03it/s]INFO:__main__:Requesting https://medium.com/@vidiborskiy/software-writes-software-program-synthesis-101-294a9a35177
INFO:__main__:Getting metadata for https://medium.com/@vidiborskiy/software-writes-software-program-synthesis-101-294a9a35177
 78%|███████▊  | 821/1049 [13:57<03:10,  1.20it/s]INFO:__main__:Requesting https://github.com/Z3Prover/z3
INFO:__main__:Getting metadata for https://github.com/Z3Prover/z3
 78%|███████▊  | 822/1049 [13:58<03:12,  1.18it/s]INFO:__main__:Requesting https://github.com/ethereum/solidity/blob/develop/libsolidity/ast/AST.cpp
INFO:__main__:Getting metadata for https://github.com/ethereum/solidity/blob/develop/libsolidity/ast/AST.cpp
 78%|███████▊  | 823/1049 [13:59<03:19,  1.14it/s]INFO:__main__:Requesting https://solidity.readthedocs.io/en/v0.4.21/solidity-by-example.html
INFO:__main__:Getting metadata for https://solidity.readthedocs.io/en/v0.4.21/solidity-by-example.html
 79%|███████▊  | 824/1049 [14:00<04:06,  1.10s/it]INFO:__main__:Requesting https://www.forbes.com/sites/darrynpollock/2018/10/22/investment-boost-for-synthetic-minds-helps-build-automated-smarter-smart-contracts/#6c1994462a63
INFO:__main__:Getting metadata for https://www.forbes.com/sites/darrynpollock/2018/10/22/investment-boost-for-synthetic-minds-helps-build-automated-smarter-smart-contracts/#6c1994462a63
 79%|███████▊  | 825/1049 [14:01<03:47,  1.02s/it]INFO:__main__:Requesting https://medium.com/darklang/the-design-of-dark-59f5d38e52d2
INFO:__main__:Getting metadata for https://medium.com/darklang/the-design-of-dark-59f5d38e52d2
 79%|███████▊  | 826/1049 [14:02<03:17,  1.13it/s]INFO:__main__:Requesting http://darklang.com/careers/infrastructure-engineer
INFO:__main__:Getting metadata for https://darklang.com/careers/infrastructure-engineer/
ERROR:__main__:Could not get metadata for https://darklang.com/careers/infrastructure-engineer/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 79%|███████▉  | 827/1049 [14:03<03:33,  1.04it/s]INFO:__main__:Requesting http://darklang.com/careers/software-engineer
INFO:__main__:Getting metadata for https://darklang.com/careers/software-engineer/
ERROR:__main__:Could not get metadata for https://darklang.com/careers/software-engineer/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 79%|███████▉  | 828/1049 [14:04<03:33,  1.04it/s]INFO:__main__:Requesting https://darklang.com/careers/frontend-engineer/
INFO:__main__:Getting metadata for https://darklang.com/careers/frontend-engineer/
ERROR:__main__:Could not get metadata for https://darklang.com/careers/frontend-engineer/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 79%|███████▉  | 829/1049 [14:05<03:20,  1.10it/s]INFO:__main__:Requesting https://www.igalia.com/
INFO:__main__:Getting metadata for https://www.igalia.com
 79%|███████▉  | 830/1049 [14:09<06:59,  1.91s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/chromium-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/chromium-developer
 79%|███████▉  | 831/1049 [14:12<08:34,  2.36s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/webkit-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/webkit-developer
 79%|███████▉  | 832/1049 [14:16<09:41,  2.68s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/webkit-graphics-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/webkit-graphics-developer
 79%|███████▉  | 833/1049 [14:19<10:30,  2.92s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/graphics-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/graphics-developer
 80%|███████▉  | 834/1049 [14:23<11:01,  3.08s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/javascript-engine-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/javascript-engine-developer
 80%|███████▉  | 835/1049 [14:26<11:21,  3.18s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/compilers-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/compilers-developer
 80%|███████▉  | 836/1049 [14:30<11:32,  3.25s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/multimedia-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/multimedia-developer
 80%|███████▉  | 837/1049 [14:33<11:35,  3.28s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/web-platform-engineer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/web-platform-engineer
 80%|███████▉  | 838/1049 [14:36<11:39,  3.32s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/developer-advocate
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/developer-advocate
 80%|███████▉  | 839/1049 [14:40<11:42,  3.34s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/senior-systems-administrator-galicia-spain
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/senior-systems-administrator-galicia-spain
 80%|████████  | 840/1049 [14:43<11:48,  3.39s/it]INFO:__main__:Requesting https://www.zoomforth.com
INFO:__main__:Getting metadata for https://www.zoomforth.com
 80%|████████  | 841/1049 [14:44<08:34,  2.48s/it]INFO:__main__:Requesting https://goo.gl/forms/8WOjyVeQ91lc4U0K3
INFO:__main__:Getting metadata for https://docs.google.com/forms/d/e/1FAIpQLSf3mwlnyNkFejV3hJ5nJpDLyjYMve4bZON5SlItlwUIJUBK5A/viewform?usp=send_form
 80%|████████  | 842/1049 [14:44<06:41,  1.94s/it]INFO:__main__:Requesting https://www.lever.co
INFO:__main__:Getting metadata for https://www.lever.co
 80%|████████  | 843/1049 [14:45<05:17,  1.54s/it]INFO:__main__:Requesting https://www.keyvalues.com/lever
INFO:__main__:Getting metadata for https://www.keyvalues.com/lever
 80%|████████  | 844/1049 [14:46<04:52,  1.43s/it]INFO:__main__:Requesting https://jobs.lever.co/lever/5dc41b9b-3166-41ee-b048-71eb53a79bd3?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/5dc41b9b-3166-41ee-b048-71eb53a79bd3?lever-source=KeyValues
 81%|████████  | 845/1049 [14:47<04:01,  1.19s/it]INFO:__main__:Requesting https://jobs.lever.co/lever/5075f462-d149-4081-ba15-6080cbbbd5fd?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/5075f462-d149-4081-ba15-6080cbbbd5fd?lever-source=KeyValues
 81%|████████  | 846/1049 [14:47<03:25,  1.01s/it]INFO:__main__:Requesting https://jobs.lever.co/lever/ea11e377-ad86-4173-86d2-2b8b1fc32dd6?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/ea11e377-ad86-4173-86d2-2b8b1fc32dd6?lever-source=KeyValues
 81%|████████  | 847/1049 [14:48<03:00,  1.12it/s]INFO:__main__:Requesting https://jobs.lever.co/lever/f6eb3fa6-0ba5-4178-b1ae-e4e0448ba175?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/f6eb3fa6-0ba5-4178-b1ae-e4e0448ba175?lever-source=KeyValues
 81%|████████  | 848/1049 [14:49<02:45,  1.22it/s]INFO:__main__:Requesting https://jobs.lever.co/lever/dd9a8568-623b-404c-b853-d6a46ebeb9ae?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/dd9a8568-623b-404c-b853-d6a46ebeb9ae?lever-source=KeyValues
 81%|████████  | 849/1049 [14:49<02:32,  1.31it/s]INFO:__main__:Requesting https://fulcrum.lever.co/the-lever-tech-stack-1b30e27d2bb0
INFO:__main__:Getting metadata for https://fulcrum.lever.co/the-lever-tech-stack-1b30e27d2bb0?gi=4e713e402244
 81%|████████  | 850/1049 [14:50<02:55,  1.13it/s]INFO:__main__:Requesting https://www.noredink.com/jobs
INFO:__main__:Getting metadata for https://www.noredink.com/jobs
 81%|████████  | 851/1049 [14:51<02:26,  1.36it/s]INFO:__main__:Requesting https://www.noredink.com/about/team
INFO:__main__:Getting metadata for https://www.noredink.com/about/team
 81%|████████  | 852/1049 [14:53<03:44,  1.14s/it]INFO:__main__:Requesting http://tech.noredink.com/
INFO:__main__:Getting metadata for https://blog.noredink.com/#_=_
 81%|████████▏ | 853/1049 [14:54<03:29,  1.07s/it]INFO:__main__:Requesting https://github.com/NoRedInk/
INFO:__main__:Getting metadata for https://github.com/NoRedInk/
 81%|████████▏ | 854/1049 [14:55<03:26,  1.06s/it]INFO:__main__:Requesting http://tech.noredink.com/post/136615783598/welcome-evan
INFO:__main__:Getting metadata for https://blog.noredink.com/post/136615783598/welcome-evan#_=_
 82%|████████▏ | 855/1049 [14:56<03:10,  1.02it/s]INFO:__main__:Requesting http://tech.noredink.com/post/145260396603/our-engineering-hiring-process
INFO:__main__:Getting metadata for https://blog.noredink.com/post/145260396603/our-engineering-hiring-process#_=_
 82%|████████▏ | 856/1049 [14:56<02:57,  1.08it/s]INFO:__main__:Requesting http://tech.noredink.com/post/143787279069/on-boarding-as-a-new-remote-engineer-think-about
INFO:__main__:Getting metadata for https://blog.noredink.com/post/143787279069/on-boarding-as-a-new-remote-engineer#_=_
 82%|████████▏ | 857/1049 [14:57<02:50,  1.12it/s]INFO:__main__:Requesting https://hazelanalytics.com
INFO:__main__:Getting metadata for https://hazelanalytics.com
 82%|████████▏ | 858/1049 [14:58<02:55,  1.09it/s]INFO:__main__:Requesting http://www.espn.com/espn/feature/story/_/id/25316231/health-inspection-reports-find-critical-violations-nfl-nhl-nba-mlb-stadiums-2018-espn-lines
INFO:__main__:Getting metadata for http://www.espn.com/espn/feature/story/_/id/25316231/health-inspection-reports-find-critical-violations-nfl-nhl-nba-mlb-stadiums-2018-espn-lines
 82%|████████▏ | 859/1049 [14:59<02:30,  1.26it/s]INFO:__main__:Requesting https://jobs.lever.co/hazelanalytics/7c4ae7ec-ed3f-45cf-b2e9-0a8146b89840?lever-origin=applied&lever-source%5B%5D=Hacker%20News
INFO:__main__:Getting metadata for https://jobs.lever.co/hazelanalytics/7c4ae7ec-ed3f-45cf-b2e9-0a8146b89840?lever-origin=applied&lever-source%5B%5D=Hacker%20News
 82%|████████▏ | 860/1049 [14:59<02:18,  1.36it/s]INFO:__main__:Requesting https://jobs.lever.co/hazelanalytics/d2df0869-51e3-4e92-9136-78ca3077c2cb?lever-origin=applied&lever-source%5B%5D=Hacker%20News
INFO:__main__:Getting metadata for https://jobs.lever.co/hazelanalytics/d2df0869-51e3-4e92-9136-78ca3077c2cb?lever-origin=applied&lever-source%5B%5D=Hacker%20News
 82%|████████▏ | 861/1049 [15:00<02:10,  1.44it/s]INFO:__main__:Requesting https://jobs.lever.co/hazelanalytics/e959f02d-06e7-4f8b-971b-b7a4af640a0f?lever-origin=applied&lever-source%5B%5D=Hacker%20News
INFO:__main__:Getting metadata for https://jobs.lever.co/hazelanalytics/e959f02d-06e7-4f8b-971b-b7a4af640a0f?lever-origin=applied&lever-source%5B%5D=Hacker%20News
 82%|████████▏ | 862/1049 [15:00<02:04,  1.50it/s]INFO:__main__:Requesting https://www.samsara.com
INFO:__main__:Getting metadata for https://www.samsara.com
 82%|████████▏ | 863/1049 [15:02<03:14,  1.05s/it]INFO:__main__:Requesting https://www.keyvalues.com/samsara
INFO:__main__:Getting metadata for https://www.keyvalues.com/samsara
 82%|████████▏ | 864/1049 [15:04<03:21,  1.09s/it]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1254967?gh_src=d9387f701
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1254967?gh_src=d9387f701
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1254967?gh_src=d9387f701
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 82%|████████▏ | 865/1049 [15:04<02:48,  1.09it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1470418?gh_src=5d66cb4c1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1470418?gh_src=5d66cb4c1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1470418?gh_src=5d66cb4c1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 83%|████████▎ | 866/1049 [15:05<02:27,  1.24it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/870567?gh_src=5a99136f1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/870567?gh_src=5a99136f1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/870567?gh_src=5a99136f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 83%|████████▎ | 867/1049 [15:05<02:05,  1.45it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1385260?gh_src=e5adf49e1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 83%|████████▎ | 868/1049 [15:06<02:45,  1.09it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1470416?gh_src=b91f86491
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1470416?gh_src=b91f86491
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1470416?gh_src=b91f86491
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 83%|████████▎ | 869/1049 [15:07<02:21,  1.27it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1392257?gh_src=890fd7db1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1392257?gh_src=890fd7db1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1392257?gh_src=890fd7db1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 83%|████████▎ | 870/1049 [15:07<02:01,  1.47it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/946181
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/946181
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/946181
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 83%|████████▎ | 871/1049 [15:08<01:46,  1.67it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/946228?gh_src=0d2920b21
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/946228?gh_src=0d2920b21
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/946228?gh_src=0d2920b21
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 83%|████████▎ | 872/1049 [15:08<01:41,  1.75it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1470413?gh_src=782386f71
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1470413?gh_src=782386f71
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1470413?gh_src=782386f71
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 83%|████████▎ | 873/1049 [15:09<01:38,  1.80it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1271489?gh_src=79bc46e41
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1271489?gh_src=79bc46e41
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1271489?gh_src=79bc46e41
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 83%|████████▎ | 874/1049 [15:09<01:33,  1.88it/s]INFO:__main__:Requesting https://jobs.lever.co/quora/4ea5b0e2-b570-439f-a3a1-1f3010422273?lever-origin=applied&lever-source%5B%5D=ycombinator
INFO:__main__:Getting metadata for https://jobs.lever.co/quora/4ea5b0e2-b570-439f-a3a1-1f3010422273?lever-origin=applied&lever-source%5B%5D=ycombinator
 83%|████████▎ | 875/1049 [15:10<01:35,  1.82it/s]INFO:__main__:Requesting https://jobs.lever.co/quora/5ae871e6-12a7-40d2-829a-64041e24da42?lever-origin=applied&lever-source%5B%5D=ycombinator
INFO:__main__:Getting metadata for https://jobs.lever.co/quora/5ae871e6-12a7-40d2-829a-64041e24da42?lever-origin=applied&lever-source%5B%5D=ycombinator
 84%|████████▎ | 876/1049 [15:11<01:40,  1.72it/s]INFO:__main__:Requesting https://jobs.lever.co/quora/447265db-74b3-4970-bb46-11083af8e4d5?lever-origin=applied&lever-source%5B%5D=ycombinator
INFO:__main__:Getting metadata for https://jobs.lever.co/quora/447265db-74b3-4970-bb46-11083af8e4d5?lever-origin=applied&lever-source%5B%5D=ycombinator
 84%|████████▎ | 877/1049 [15:11<01:40,  1.72it/s]INFO:__main__:Requesting https://jobs.lever.co/quora/6be9efa2-49db-4fe1-bf42-fe45e5ae6cb9?lever-origin=applied&lever-source%5B%5D=ycombinator
INFO:__main__:Getting metadata for https://jobs.lever.co/quora/6be9efa2-49db-4fe1-bf42-fe45e5ae6cb9?lever-origin=applied&lever-source%5B%5D=ycombinator
 84%|████████▎ | 878/1049 [15:12<01:39,  1.71it/s]INFO:__main__:Requesting https://engineering.quora.com/Dataset-release-and-Kaggle-competition-Question-Sincerity
INFO:__main__:Getting metadata for https://engineering.quora.com/Dataset-release-and-Kaggle-competition-Question-Sincerity
ERROR:__main__:Could not get metadata for https://engineering.quora.com/Dataset-release-and-Kaggle-competition-Question-Sincerity
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 84%|████████▍ | 879/1049 [15:14<03:02,  1.07s/it]INFO:__main__:Requesting https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics
INFO:__main__:Getting metadata for https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics
ERROR:__main__:Could not get metadata for https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 84%|████████▍ | 880/1049 [15:17<04:47,  1.70s/it]INFO:__main__:Requesting https://blog.quora.com/Introducing-Spaces
INFO:__main__:Getting metadata for https://blog.quora.com/Introducing-Spaces
ERROR:__main__:Could not get metadata for https://blog.quora.com/Introducing-Spaces
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 84%|████████▍ | 881/1049 [15:24<09:18,  3.32s/it]INFO:__main__:Requesting https://relayr.io/
INFO:__main__:Getting metadata for https://relayr.io
 84%|████████▍ | 882/1049 [15:26<07:53,  2.84s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=39
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=39
 84%|████████▍ | 883/1049 [15:28<06:55,  2.51s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=38
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=38
 84%|████████▍ | 884/1049 [15:29<06:21,  2.31s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=74
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=74
 84%|████████▍ | 885/1049 [15:31<05:48,  2.13s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=37
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=37
 84%|████████▍ | 886/1049 [15:33<05:25,  2.00s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=5
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=5
 85%|████████▍ | 887/1049 [15:34<05:01,  1.86s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=110
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=110
 85%|████████▍ | 888/1049 [15:36<04:45,  1.77s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=71
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=71
 85%|████████▍ | 889/1049 [15:38<04:31,  1.70s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=119
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=119
 85%|████████▍ | 890/1049 [15:39<04:19,  1.64s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=118
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=118
 85%|████████▍ | 891/1049 [15:41<04:13,  1.60s/it]INFO:__main__:Requesting https://relayr.io/about/join-us/
INFO:__main__:Getting metadata for https://relayr.io/about/join-us/
 85%|████████▌ | 892/1049 [15:42<04:18,  1.65s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/
 85%|████████▌ | 893/1049 [15:43<03:44,  1.44s/it]INFO:__main__:Requesting https://www.aquabyte.ai
ERROR:__main__:Could not reach https://www.aquabyte.ai
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 80, in create_connection
    raise err
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 70, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 301, in connect
    conn = self._new_conn()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 164, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97e419b748>, 'Connection to www.aquabyte.ai timed out. (connect timeout=6)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.aquabyte.ai', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97e419b748>, 'Connection to www.aquabyte.ai timed out. (connect timeout=6)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 504, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.aquabyte.ai', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f97e419b748>, 'Connection to www.aquabyte.ai timed out. (connect timeout=6)'))
 85%|████████▌ | 894/1049 [15:49<07:17,  2.82s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/557f4987-5ed6-4aae-b8c7-b0d3011e59eb
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/557f4987-5ed6-4aae-b8c7-b0d3011e59eb
 85%|████████▌ | 895/1049 [15:50<05:32,  2.16s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/738c2aa4-faf3-4783-bda4-d14af2199bf0
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/738c2aa4-faf3-4783-bda4-d14af2199bf0
 85%|████████▌ | 896/1049 [15:51<04:24,  1.73s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/59b53335-e773-4003-86a7-a008dd474292
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/59b53335-e773-4003-86a7-a008dd474292
 86%|████████▌ | 897/1049 [15:51<03:31,  1.39s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/c4fa7f35-bc53-400a-a830-4fe1bdabfa47
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/c4fa7f35-bc53-400a-a830-4fe1bdabfa47
 86%|████████▌ | 898/1049 [15:52<02:54,  1.15s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/b951497b-b4e6-4c94-b35f-83bc8624f312
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/b951497b-b4e6-4c94-b35f-83bc8624f312
 86%|████████▌ | 899/1049 [15:52<02:27,  1.02it/s]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/e6683e22-cdcb-4dac-b601-ba37a6da3b8e
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/e6683e22-cdcb-4dac-b601-ba37a6da3b8e
 86%|████████▌ | 900/1049 [15:53<02:08,  1.16it/s]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/ce704fb7-3d7a-40b8-93e3-9d21f23cea07
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/ce704fb7-3d7a-40b8-93e3-9d21f23cea07
 86%|████████▌ | 901/1049 [15:54<01:56,  1.27it/s]INFO:__main__:Requesting https://www.tanium.com/careers/?gh_src=qprker8f1
INFO:__main__:Getting metadata for https://www.tanium.com/careers/?gh_src=qprker8f1
 86%|████████▌ | 902/1049 [15:54<01:44,  1.40it/s]INFO:__main__:Requesting https://www.tanium.com/careers/?p=department&t=Engineering&gh_src=b44d958b1#openings
INFO:__main__:Getting metadata for https://www.tanium.com/careers/?p=department&t=Engineering&gh_src=b44d958b1#openings
 86%|████████▌ | 903/1049 [15:55<01:29,  1.62it/s]INFO:__main__:Requesting https://www.tanium.com/careers/?p=department&t=Technical%20Account%20Management&gh_src=r64ytqkl1#openings
INFO:__main__:Getting metadata for https://www.tanium.com/careers/?p=department&t=Technical%20Account%20Management&gh_src=r64ytqkl1#openings
 86%|████████▌ | 904/1049 [15:55<01:24,  1.72it/s]INFO:__main__:Requesting https://grnh.se/ec5df4181
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1131458&gh_src=ec5df4181
 86%|████████▋ | 905/1049 [15:56<01:32,  1.55it/s]INFO:__main__:Requesting https://grnh.se/hf4v4o8l1
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=497373&gh_src=hf4v4o8l1
 86%|████████▋ | 906/1049 [15:56<01:32,  1.54it/s]INFO:__main__:Requesting https://grnh.se/fd4e8ed81
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1416291&gh_src=fd4e8ed81
 86%|████████▋ | 907/1049 [15:57<01:31,  1.54it/s]INFO:__main__:Requesting https://grnh.se/5a0b1fd61
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1416292&gh_src=5a0b1fd61
 87%|████████▋ | 908/1049 [15:58<01:33,  1.52it/s]INFO:__main__:Requesting https://grnh.se/79ee36481
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1420039&gh_src=79ee36481
 87%|████████▋ | 909/1049 [15:59<01:34,  1.48it/s]INFO:__main__:Requesting https://grnh.se/0101307e1
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1148597&gh_src=0101307e1
 87%|████████▋ | 910/1049 [15:59<01:34,  1.46it/s]INFO:__main__:Requesting https://grnh.se/c2d947de1
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1148600&gh_src=c2d947de1
 87%|████████▋ | 911/1049 [16:00<01:30,  1.52it/s]INFO:__main__:Requesting https://grnh.se/deaf94841
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1141995&gh_src=deaf94841
 87%|████████▋ | 912/1049 [16:01<01:32,  1.48it/s]INFO:__main__:Requesting http://fortune.com/most-important-private-companies/tanium-24/
INFO:__main__:Requesting https://www.forbes.com/companies/tanium/#3bbe09173eea
INFO:__main__:Getting metadata for https://www.forbes.com/companies/tanium/#3bbe09173eea
 87%|████████▋ | 914/1049 [16:01<01:22,  1.64it/s]INFO:__main__:Requesting https://www.fedscoop.com/air-force-cio-says-role-become-much-prominent-prepares-retire/
INFO:__main__:Getting metadata for https://www.fedscoop.com/air-force-cio-says-role-become-much-prominent-prepares-retire/
 87%|████████▋ | 915/1049 [16:02<01:33,  1.44it/s]INFO:__main__:Requesting https://federalnewsnetwork.com/dod-reporters-notebook-jared-serbu/2018/12/air-force-to-release-new-fast-track-cyber-approval-process/
INFO:__main__:Getting metadata for https://federalnewsnetwork.com/dod-reporters-notebook-jared-serbu/2018/12/air-force-to-release-new-fast-track-cyber-approval-process/
 87%|████████▋ | 916/1049 [16:02<01:09,  1.92it/s]INFO:__main__:Requesting http://fortune.com/best-medium-workplaces/tanium-55/
INFO:__main__:Requesting http://reviews.greatplacetowork.com/tanium
INFO:__main__:Getting metadata for https://www.greatplacetowork.com/certified-company/5003402
 88%|████████▊ | 918/1049 [16:03<01:06,  1.97it/s]INFO:__main__:Requesting https://auth0.com/
INFO:__main__:Getting metadata for https://auth0.com
 88%|████████▊ | 919/1049 [16:04<00:55,  2.36it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/335316b1-9a71-4488-bd0c-c589c4fac03f
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/335316b1-9a71-4488-bd0c-c589c4fac03f
 88%|████████▊ | 920/1049 [16:05<01:15,  1.71it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/f2a6fd71-f536-4aee-8cd1-76d96a04f894
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/f2a6fd71-f536-4aee-8cd1-76d96a04f894
 88%|████████▊ | 921/1049 [16:05<01:17,  1.65it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/577e4a81-c5bf-438c-ac86-766a597f30bc
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/577e4a81-c5bf-438c-ac86-766a597f30bc
 88%|████████▊ | 922/1049 [16:06<01:17,  1.65it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/ba4c9c85-ad15-4af3-b98d-a81fb6ba46dd
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/ba4c9c85-ad15-4af3-b98d-a81fb6ba46dd
 88%|████████▊ | 923/1049 [16:07<01:18,  1.61it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/dd370211-cc49-403e-b001-5eb1c8207f7c
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/dd370211-cc49-403e-b001-5eb1c8207f7c
 88%|████████▊ | 924/1049 [16:07<01:17,  1.62it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/f402a708-f59e-4b7c-b144-a1d154e2949b
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/f402a708-f59e-4b7c-b144-a1d154e2949b
 88%|████████▊ | 925/1049 [16:08<01:15,  1.64it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/90483251-ce4e-4129-9682-ce46482508f3
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/90483251-ce4e-4129-9682-ce46482508f3
 88%|████████▊ | 926/1049 [16:08<01:14,  1.64it/s]INFO:__main__:Requesting https://auth0.com/blog/how-we-hire-engineers/
INFO:__main__:Getting metadata for https://auth0.com/blog/how-we-hire-engineers/
 88%|████████▊ | 927/1049 [16:09<01:05,  1.85it/s]INFO:__main__:Requesting https://twitter.com/vibronet/status/997608152811044872
INFO:__main__:Getting metadata for https://twitter.com/vibronet/status/997608152811044872
 88%|████████▊ | 928/1049 [16:10<01:16,  1.59it/s]INFO:__main__:Requesting https://iterable.com
INFO:__main__:Getting metadata for https://iterable.com
 89%|████████▊ | 929/1049 [16:10<00:56,  2.12it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1475142
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1475142
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1475142
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1374138
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1374138
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1374138
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 931/1049 [16:11<00:55,  2.12it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=228990
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=228990
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=228990
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 932/1049 [16:11<01:08,  1.71it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=511439
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=511439
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=511439
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 933/1049 [16:12<01:13,  1.58it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=511410
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=511410
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=511410
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 934/1049 [16:13<01:18,  1.46it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1321405
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1321405
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1321405
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 935/1049 [16:14<01:22,  1.38it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1536262
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1536262
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1536262
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 936/1049 [16:15<01:25,  1.33it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1111156
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1111156
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1111156
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 937/1049 [16:15<01:24,  1.32it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1118621
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1118621
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1118621
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 938/1049 [16:16<01:18,  1.41it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1463678
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1463678
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1463678
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|████████▉ | 939/1049 [16:17<01:23,  1.32it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1565139
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1565139
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1565139
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|████████▉ | 940/1049 [16:18<01:30,  1.20it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1451971
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1451971
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1451971
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|████████▉ | 941/1049 [16:19<01:27,  1.23it/s]INFO:__main__:Requesting https://grnh.se/5363f6b61
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1276367?gh_jid=1276367&gh_src=5363f6b61
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1276367?gh_jid=1276367&gh_src=5363f6b61
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|████████▉ | 942/1049 [16:20<01:37,  1.10it/s]INFO:__main__:Requesting https://grnh.se/c7a1b74f1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1440108?gh_jid=1440108&gh_src=c7a1b74f1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1440108?gh_jid=1440108&gh_src=c7a1b74f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|████████▉ | 943/1049 [16:21<01:41,  1.04it/s]INFO:__main__:Requesting https://grnh.se/3f67a13d1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1440097?gh_jid=1440097&gh_src=3f67a13d1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1440097?gh_jid=1440097&gh_src=3f67a13d1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|████████▉ | 944/1049 [16:22<01:44,  1.00it/s]INFO:__main__:Requesting https://grnh.se/c37a43151
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1510047?gh_jid=1510047&gh_src=c37a43151
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1510047?gh_jid=1510047&gh_src=c37a43151
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|█████████ | 945/1049 [16:23<01:48,  1.04s/it]INFO:__main__:Requesting https://grnh.se/6c2ba6b11
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173542?gh_jid=1173542&gh_src=6c2ba6b11
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173542?gh_jid=1173542&gh_src=6c2ba6b11
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|█████████ | 946/1049 [16:25<02:01,  1.18s/it]INFO:__main__:Requesting https://grnh.se/a4c0a8731
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173581?gh_jid=1173581&gh_src=a4c0a8731
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173581?gh_jid=1173581&gh_src=a4c0a8731
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|█████████ | 947/1049 [16:26<01:56,  1.15s/it]INFO:__main__:Requesting https://grnh.se/b8fefccb1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1505260?gh_jid=1505260&gh_src=b8fefccb1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1505260?gh_jid=1505260&gh_src=b8fefccb1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|█████████ | 948/1049 [16:27<01:55,  1.14s/it]INFO:__main__:Requesting https://grnh.se/d7514f0c1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173526?gh_jid=1173526&gh_src=d7514f0c1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173526?gh_jid=1173526&gh_src=d7514f0c1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 90%|█████████ | 949/1049 [16:28<01:55,  1.15s/it]INFO:__main__:Requesting https://grnh.se/d7ca9c1f1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173588?gh_jid=1173588&gh_src=d7ca9c1f1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173588?gh_jid=1173588&gh_src=d7ca9c1f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 91%|█████████ | 950/1049 [16:29<01:51,  1.13s/it]INFO:__main__:Requesting https://grnh.se/1d737c291
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173565?gh_jid=1173565&gh_src=1d737c291
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173565?gh_jid=1173565&gh_src=1d737c291
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 91%|█████████ | 951/1049 [16:30<01:49,  1.12s/it]INFO:__main__:Requesting https://grnh.se/db1fe84f1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173605?gh_jid=1173605&gh_src=db1fe84f1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173605?gh_jid=1173605&gh_src=db1fe84f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 91%|█████████ | 952/1049 [16:31<01:51,  1.14s/it]INFO:__main__:Requesting https://grnh.se/df42e0021
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173515?gh_jid=1173515&gh_src=df42e0021
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173515?gh_jid=1173515&gh_src=df42e0021
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 91%|█████████ | 953/1049 [16:32<01:47,  1.12s/it]INFO:__main__:Requesting https://grnh.se/196c74d81
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173551?gh_jid=1173551&gh_src=196c74d81
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173551?gh_jid=1173551&gh_src=196c74d81
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 91%|█████████ | 954/1049 [16:33<01:45,  1.11s/it]INFO:__main__:Requesting https://grnh.se/04c41e691
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173601?gh_jid=1173601&gh_src=04c41e691
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173601?gh_jid=1173601&gh_src=04c41e691
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 91%|█████████ | 955/1049 [16:35<01:46,  1.13s/it]INFO:__main__:Requesting https://grnh.se/5ced83341
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173574?gh_jid=1173574&gh_src=5ced83341
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173574?gh_jid=1173574&gh_src=5ced83341
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 91%|█████████ | 956/1049 [16:36<01:44,  1.12s/it]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/director-of-engineering-editorial-experience-czdJ-Yl7ar6ANxcR_n82lY?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/director-of-engineering-editorial-experience-czdJ-Yl7ar6ANxcR_n82lY?ref=rss&sid=68
 91%|█████████ | 957/1049 [16:36<01:27,  1.06it/s]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/software-engineer-ecommerce-cM-GPUfpar6BIhdUfHqP9G?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/software-engineer-ecommerce-cM-GPUfpar6BIhdUfHqP9G?ref=rss&sid=68
 91%|█████████▏| 958/1049 [16:37<01:17,  1.18it/s]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/software-engineer-subscriptions-dzTa3YgcGr6AkBeUHD3cl-?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/software-engineer-subscriptions-dzTa3YgcGr6AkBeUHD3cl-?ref=rss&sid=68
 91%|█████████▏| 959/1049 [16:38<01:14,  1.21it/s]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/devops-engineer-d-A7HMI1Sr6kIvdG1ZS6tF?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/devops-engineer-d-A7HMI1Sr6kIvdG1ZS6tF?ref=rss&sid=68
 92%|█████████▏| 960/1049 [16:38<01:06,  1.35it/s]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/release-engineer-byijqWI1Wr6kIvdG1ZS6tF?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/release-engineer-byijqWI1Wr6kIvdG1ZS6tF?ref=rss&sid=68
 92%|█████████▏| 961/1049 [16:39<01:17,  1.13it/s]INFO:__main__:Requesting https://www.insider-inc.com/careers#careers-open-roles
INFO:__main__:Getting metadata for https://www.insider-inc.com/careers#careers-open-roles
ERROR:__main__:Could not get metadata for https://www.insider-inc.com/careers#careers-open-roles
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 92%|█████████▏| 962/1049 [16:40<01:13,  1.18it/s]INFO:__main__:Requesting https://drive.google.com/open?id=10xFqw6R_HPJrpd5Fkv2enAszAs..
 92%|█████████▏| 963/1049 [16:40<00:53,  1.60it/s]INFO:__main__:Requesting https://www.haproxy.com/privacy-policy/
INFO:__main__:Getting metadata for https://www.haproxy.com/privacy-policy/
ERROR:__main__:Could not get metadata for https://www.haproxy.com/privacy-policy/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 92%|█████████▏| 964/1049 [16:41<00:50,  1.68it/s]INFO:__main__:Requesting https://blog.zulip.org/2019/03/01/zulip-2-0-released/
INFO:__main__:Getting metadata for https://blog.zulip.org/2019/03/01/zulip-2-0-released/
 92%|█████████▏| 965/1049 [16:42<00:52,  1.59it/s]INFO:__main__:Requesting https://zulip.readthedocs.io/en/stable/production/email.html
INFO:__main__:Getting metadata for https://zulip.readthedocs.io/en/stable/production/email.html
 92%|█████████▏| 966/1049 [16:44<01:29,  1.08s/it]INFO:__main__:Requesting https://www.3cx.com/docs/fqdn-management-allocation/
INFO:__main__:Getting metadata for https://www.3cx.com/docs/fqdn-management-allocation/
 92%|█████████▏| 967/1049 [16:45<01:26,  1.05s/it]INFO:__main__:Requesting https://github.com/zulip/zulip/issues/3618
INFO:__main__:Getting metadata for https://github.com/zulip/zulip/issues/3618
 92%|█████████▏| 968/1049 [16:46<01:36,  1.19s/it]INFO:__main__:Requesting https://www.codeshelter.co/
INFO:__main__:Getting metadata for https://www.codeshelter.co
 92%|█████████▏| 969/1049 [16:51<03:02,  2.28s/it]INFO:__main__:Requesting https://github.com/Canop/miaou
INFO:__main__:Getting metadata for https://github.com/Canop/miaou
 92%|█████████▏| 970/1049 [16:52<02:25,  1.85s/it]INFO:__main__:Requesting https://github.com/zulip/zulip/pull/11622
INFO:__main__:Getting metadata for https://github.com/zulip/zulip/pull/11622
 93%|█████████▎| 971/1049 [16:55<02:55,  2.25s/it]INFO:__main__:Requesting https://www.keyvalues.com
INFO:__main__:Getting metadata for https://www.keyvalues.com
 93%|█████████▎| 972/1049 [16:57<02:55,  2.28s/it]INFO:__main__:Requesting https://codewithoutrules.com/2019/01/31/does-company-have-worklife-balance/
INFO:__main__:Getting metadata for https://codewithoutrules.com/2019/01/31/does-company-have-worklife-balance/
 93%|█████████▎| 973/1049 [16:58<02:06,  1.66s/it]INFO:__main__:Requesting https://levels.fyi
INFO:__main__:Getting metadata for https://www.levels.fyi
 93%|█████████▎| 974/1049 [16:58<01:35,  1.28s/it]INFO:__main__:Requesting https://mattermark.com/
INFO:__main__:Getting metadata for https://mattermark.com
 93%|█████████▎| 975/1049 [16:58<01:15,  1.03s/it]INFO:__main__:Requesting https://www.transparentcareer.com
INFO:__main__:Getting metadata for https://www.transparentcareer.com
 93%|█████████▎| 976/1049 [16:59<01:03,  1.14it/s]INFO:__main__:Requesting https://last10k.com
ERROR:__main__:Could not reach https://last10k.com
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 93%|█████████▎| 977/1049 [16:59<00:47,  1.51it/s]INFO:__main__:Requesting https://www.kununu.com/
INFO:__main__:Getting metadata for https://www.kununu.com/us
 93%|█████████▎| 978/1049 [17:03<01:53,  1.60s/it]INFO:__main__:Requesting https://krebsonsecurity.com/2017/11/how-to-opt-out-of-equifax-revealing-your-salary-history/
INFO:__main__:Getting metadata for https://krebsonsecurity.com/2017/11/how-to-opt-out-of-equifax-revealing-your-salary-history/
 93%|█████████▎| 979/1049 [17:05<02:09,  1.85s/it]INFO:__main__:Requesting https://circleci.com/blog/7-steps-to-building-an-engineering-competency-matrix/
INFO:__main__:Getting metadata for https://circleci.com/blog/7-steps-to-building-an-engineering-competency-matrix/
 93%|█████████▎| 980/1049 [17:06<01:38,  1.43s/it]INFO:__main__:Requesting https://linustechtips.com/main/topic/72936-english-swedish-german-and-finnish-decline-dog/
INFO:__main__:Getting metadata for https://linustechtips.com/main/topic/72936-english-swedish-german-and-finnish-decline-dog/
 94%|█████████▎| 981/1049 [17:06<01:20,  1.18s/it]INFO:__main__:Requesting https://www.gocomics.com/calvinandhobbes/1993/01/25
INFO:__main__:Getting metadata for https://www.gocomics.com/calvinandhobbes/1993/01/25
 94%|█████████▎| 982/1049 [17:07<01:06,  1.01it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Word#Word_boundaries
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Word#Word_boundaries
 94%|█████████▎| 983/1049 [17:08<01:12,  1.10s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Agglutination
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Agglutination
 94%|█████████▍| 984/1049 [17:09<01:11,  1.10s/it]INFO:__main__:Requesting https://goo.gl/images/m5QgbE
INFO:__main__:Getting metadata for https://www.google.com/imgres?imgurl=https://xperiencepoland.com/wp-content/uploads/2017/01/polish-language-is-hard.jpg&imgrefurl=https://www.xperiencepoland.com/5-reasons-polish-language-is-hard/&docid=mTM1ITI-MbaumM&tbnid=g2Omi15crZPXJM:&vet=1&w=700&h=525&source=sh/x/im
 94%|█████████▍| 985/1049 [17:10<00:58,  1.09it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Declension
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Declension
 94%|█████████▍| 986/1049 [17:11<01:00,  1.05it/s]INFO:__main__:Requesting https://www.filosoft.ee/gene_et/
INFO:__main__:Getting metadata for https://www.filosoft.ee/gene_et/
 94%|█████████▍| 987/1049 [17:13<01:25,  1.38s/it]INFO:__main__:Requesting https://en.m.wikipedia.org/wiki/Longest_word_in_Turkish
INFO:__main__:Getting metadata for https://en.m.wikipedia.org/wiki/Longest_word_in_Turkish
 94%|█████████▍| 988/1049 [17:14<01:15,  1.23s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Gravitas
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Gravitas
 94%|█████████▍| 989/1049 [17:15<01:10,  1.17s/it]INFO:__main__:Requesting https://docs.google.com/presentation/d/1boPxbgNrTU0ddsc144rcXayGA_WF53k96imRH8Mp34Y/edit#slide=id.p
INFO:__main__:Getting metadata for https://docs.google.com/presentation/d/1boPxbgNrTU0ddsc144rcXayGA_WF53k96imRH8Mp34Y/preview?sle=true#slide=id.p
 94%|█████████▍| 990/1049 [17:19<01:56,  1.98s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=w8lm4GV7ahg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=w8lm4GV7ahg
 94%|█████████▍| 991/1049 [17:20<01:35,  1.65s/it]INFO:__main__:Requesting https://sniphub.net/2019/02/28/Amazon-Translate.html
INFO:__main__:Getting metadata for https://sniphub.net/2019/02/28/Amazon-Translate.html
 95%|█████████▍| 992/1049 [17:20<01:09,  1.21s/it]INFO:__main__:Requesting https://www.translationparty.com
INFO:__main__:Getting metadata for https://www.translationparty.com
ERROR:__main__:Could not get metadata for https://www.translationparty.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 95%|█████████▍| 993/1049 [17:21<01:06,  1.19s/it]INFO:__main__:Requesting http://musl.cc/
INFO:__main__:Getting metadata for http://musl.cc
 95%|█████████▍| 994/1049 [17:22<00:56,  1.03s/it]INFO:__main__:Requesting https://twitter.com/RichFelker/status/1101157783620255744
INFO:__main__:Getting metadata for https://twitter.com/RichFelker/status/1101157783620255744
 95%|█████████▍| 995/1049 [17:23<00:51,  1.06it/s]INFO:__main__:Requesting https://www.patreon.com/musl/overview
INFO:__main__:Getting metadata for https://www.patreon.com/musl/overview
 95%|█████████▍| 996/1049 [17:23<00:43,  1.23it/s]INFO:__main__:Requesting http://ellcc.org/
INFO:__main__:Getting metadata for http://ellcc.org
 95%|█████████▌| 997/1049 [17:25<00:54,  1.05s/it]INFO:__main__:Requesting http://abovethecrowd.com/2019/02/27/money-out-of-nowhere-how-internet-marketplaces-unlock-economic-wealth/
INFO:__main__:Getting metadata for http://abovethecrowd.com/2019/02/27/money-out-of-nowhere-how-internet-marketplaces-unlock-economic-wealth/
 95%|█████████▌| 998/1049 [17:25<00:40,  1.26it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Comparative_advantage#Criticism
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Comparative_advantage#Criticism
 95%|█████████▌| 999/1049 [17:27<00:54,  1.09s/it]INFO:__main__:Requesting https://www.nber.org/papers/w5625
INFO:__main__:Getting metadata for https://www.nber.org/papers/w5625
 95%|█████████▌| 1000/1049 [17:31<01:38,  2.02s/it]INFO:__main__:Requesting https://www.amazon.com/Radical-Markets-Uprooting-Capitalism-Democracy/dp/0691177503
INFO:__main__:Getting metadata for https://www.amazon.com/Radical-Markets-Uprooting-Capitalism-Democracy/dp/0691177503
 95%|█████████▌| 1001/1049 [17:34<01:46,  2.22s/it]INFO:__main__:Requesting https://aeon.co/essays/why-american-revolutionaries-admired-the-rebels-of-mysore
INFO:__main__:Getting metadata for https://aeon.co/essays/why-american-revolutionaries-admired-the-rebels-of-mysore
 96%|█████████▌| 1002/1049 [17:35<01:25,  1.82s/it]INFO:__main__:Requesting https://blog.keepertax.com/posts/should-i-still-track-expenses-for-part-time-1099-work
INFO:__main__:Getting metadata for https://blog.keepertax.com/posts/should-i-still-track-expenses-for-part-time-1099-work
 96%|█████████▌| 1003/1049 [17:35<01:03,  1.39s/it]INFO:__main__:Requesting https://blog.keepertax.com/posts/should-i-claim-mileage-or-actual-car-expenses
INFO:__main__:Getting metadata for https://blog.keepertax.com/posts/should-i-claim-mileage-or-actual-car-expenses
 96%|█████████▌| 1004/1049 [17:35<00:47,  1.06s/it]INFO:__main__:Requesting https://www.nytimes.com/2017/04/24/technology/personal-data-firm-slice-unroll-me-backlash-uber.html
INFO:__main__:Getting metadata for https://www.nytimes.com/2017/04/24/technology/personal-data-firm-slice-unroll-me-backlash-uber.html
 96%|█████████▌| 1005/1049 [17:36<00:45,  1.04s/it]INFO:__main__:Requesting https://unroll.me/your-data
INFO:__main__:Getting metadata for https://unroll.me/your-data/
 96%|█████████▌| 1006/1049 [17:37<00:39,  1.09it/s]INFO:__main__:Requesting https://www.bna.com/confidentiality-tax-practice-n73014474017/
INFO:__main__:Getting metadata for https://www.bna.com/confidentiality-tax-practice-n73014474017/
 96%|█████████▌| 1007/1049 [17:39<00:48,  1.16s/it]INFO:__main__:Requesting https://plaid.com/products
INFO:__main__:Getting metadata for https://plaid.com/products/
 96%|█████████▌| 1008/1049 [17:39<00:39,  1.04it/s]INFO:__main__:Requesting https://groups.google.com/forum/#!topic/mozilla.dev.security.policy/JFwqZx7RLL0
INFO:__main__:Getting metadata for https://groups.google.com/forum/#!topic/mozilla.dev.security.policy/JFwqZx7RLL0
 96%|█████████▌| 1009/1049 [17:40<00:38,  1.05it/s]INFO:__main__:Requesting https://techcrunch.com/2019/03/01/wsj-amazon-to-open-new-u-s-grocery-chain-separate-from-whole-foods
ERROR:__main__:Could not reach https://techcrunch.com/2019/03/01/wsj-amazon-to-open-new-u-s-grocery-chain-separate-from-whole-foods
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 96%|█████████▋| 1010/1049 [17:40<00:27,  1.43it/s]INFO:__main__:Requesting http://www.esa.int/Our_Activities/Space_Science/Mars_Express/First_evidence_of_planet-wide_groundwater_system_on_Mars
INFO:__main__:Getting metadata for http://www.esa.int/Our_Activities/Space_Science/Mars_Express/First_evidence_of_planet-wide_groundwater_system_on_Mars
 96%|█████████▋| 1011/1049 [17:40<00:21,  1.80it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Water_on_Mars#Evidence_from_rocks_and_minerals
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Water_on_Mars#Evidence_from_rocks_and_minerals
 96%|█████████▋| 1012/1049 [17:45<01:03,  1.72s/it]INFO:__main__:Requesting https://research.swtch.com/tlog
INFO:__main__:Getting metadata for https://research.swtch.com/tlog
 97%|█████████▋| 1013/1049 [17:46<00:54,  1.51s/it]INFO:__main__:Requesting https://github.com/mafintosh/hypercore
INFO:__main__:Getting metadata for https://github.com/mafintosh/hypercore
 97%|█████████▋| 1014/1049 [17:47<00:46,  1.33s/it]INFO:__main__:Requesting https://www.datprotocol.com/
INFO:__main__:Getting metadata for https://www.datprotocol.com
 97%|█████████▋| 1015/1049 [17:47<00:39,  1.16s/it]INFO:__main__:Requesting https://datprotocol.github.io/how-dat-works/
INFO:__main__:Getting metadata for https://datprotocol.github.io/how-dat-works/
 97%|█████████▋| 1016/1049 [17:48<00:34,  1.05s/it]INFO:__main__:Requesting https://github.com/datrs/hypercore
INFO:__main__:Getting metadata for https://github.com/datrs/hypercore
 97%|█████████▋| 1017/1049 [17:49<00:32,  1.03s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Hash_chain#Hash_chain_vs._blockchain
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Hash_chain#Hash_chain_vs._blockchain
 97%|█████████▋| 1018/1049 [17:50<00:29,  1.04it/s]INFO:__main__:Requesting http://re2c.org/
INFO:__main__:Getting metadata for http://re2c.org
 97%|█████████▋| 1019/1049 [17:51<00:24,  1.23it/s]INFO:__main__:Requesting https://github.com/ninja-build/ninja/blob/master/src/lexer.in.cc#L123
INFO:__main__:Getting metadata for https://github.com/ninja-build/ninja/blob/master/src/lexer.in.cc#L123
 97%|█████████▋| 1020/1049 [17:51<00:23,  1.22it/s]INFO:__main__:Requesting http://www.oilshell.org/blog/2017/12/15.html
INFO:__main__:Getting metadata for http://www.oilshell.org/blog/2017/12/15.html
ERROR:__main__:Could not get metadata for http://www.oilshell.org/blog/2017/12/15.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 97%|█████████▋| 1021/1049 [17:52<00:20,  1.37it/s]INFO:__main__:Requesting https://github.com/cjohansson/emacs-phps-mode/blob/master/phps-mode-lexer.el
INFO:__main__:Getting metadata for https://github.com/cjohansson/emacs-phps-mode/blob/master/phps-mode-lexer.el
 97%|█████████▋| 1022/1049 [17:54<00:27,  1.01s/it]INFO:__main__:Requesting https://megous.com/git/sjson/tree/sjson.c
INFO:__main__:Getting metadata for https://megous.com/git/sjson/tree/sjson.c
ERROR:__main__:Could not get metadata for https://megous.com/git/sjson/tree/sjson.c
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 98%|█████████▊| 1023/1049 [17:59<01:03,  2.44s/it]INFO:__main__:Requesting https://externals.io/message/102796
INFO:__main__:Getting metadata for https://externals.io/message/102796
 98%|█████████▊| 1024/1049 [18:03<01:12,  2.92s/it]INFO:__main__:Requesting https://github.com/php/php-src/blob/master/Zend/zend_language_scanner.l
INFO:__main__:Getting metadata for https://github.com/php/php-src/blob/master/Zend/zend_language_scanner.l
 98%|█████████▊| 1025/1049 [18:05<01:00,  2.52s/it]INFO:__main__:Requesting https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/net/URL.re?at=prefetch&fileviewer=file-view-default#URL.re-106
INFO:__main__:Getting metadata for https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/net/URL.re?at=prefetch&fileviewer=file-view-default#URL.re-106
ERROR:__main__:Could not get metadata for https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/net/URL.re?at=prefetch&fileviewer=file-view-default#URL.re-106
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 98%|█████████▊| 1026/1049 [18:08<01:00,  2.65s/it]INFO:__main__:Requesting https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/system/Time.re?at=prefetch&fileviewer=file-view-default#Time.re-168
INFO:__main__:Getting metadata for https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/system/Time.re?at=prefetch&fileviewer=file-view-default#Time.re-168
ERROR:__main__:Could not get metadata for https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/system/Time.re?at=prefetch&fileviewer=file-view-default#Time.re-168
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 98%|█████████▊| 1027/1049 [18:10<00:56,  2.58s/it]INFO:__main__:Requesting https://myrlang.org/doc/libregex/
INFO:__main__:Getting metadata for https://myrlang.org/doc/libregex/
 98%|█████████▊| 1028/1049 [18:12<00:48,  2.33s/it]INFO:__main__:Requesting http://sourceware.org/git/gitweb.cgi?p=systemtap.git;a=blob;f=README.stapregex
INFO:__main__:Getting metadata for http://sourceware.org/git/gitweb.cgi?p=systemtap.git;a=blob;f=README.stapregex
ERROR:__main__:Could not get metadata for http://sourceware.org/git/gitweb.cgi?p=systemtap.git;a=blob;f=README.stapregex
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 98%|█████████▊| 1029/1049 [18:13<00:41,  2.05s/it]INFO:__main__:Requesting https://github.com/fbb-git/flexcpp
INFO:__main__:Getting metadata for https://github.com/fbb-git/flexcpp
 98%|█████████▊| 1030/1049 [18:14<00:31,  1.64s/it]INFO:__main__:Requesting https://github.com/fbb-git/bisoncpp
INFO:__main__:Getting metadata for https://github.com/fbb-git/bisoncpp
 98%|█████████▊| 1031/1049 [18:15<00:24,  1.38s/it]INFO:__main__:Requesting http://www.colm.net/open-source/ragel/
INFO:__main__:Getting metadata for http://www.colm.net/open-source/ragel/
 98%|█████████▊| 1032/1049 [18:15<00:18,  1.09s/it]INFO:__main__:Requesting https://hackaday.com/2019/02/25/nasa-is-building-a-space-station-in-a-weird-orbit-heres-why/
ERROR:__main__:Could not reach https://hackaday.com/2019/02/25/nasa-is-building-a-space-station-in-a-weird-orbit-heres-why/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 98%|█████████▊| 1033/1049 [18:15<00:12,  1.24it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=buLzhqgQbpA
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=buLzhqgQbpA
 99%|█████████▊| 1034/1049 [18:16<00:12,  1.23it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Sun-synchronous_orbit
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Sun-synchronous_orbit
 99%|█████████▊| 1035/1049 [18:18<00:13,  1.05it/s]INFO:__main__:Requesting https://hackadaycom.files.wordpress.com/2019/02/moonpossiblelandings.png
INFO:__main__:Getting metadata for https://hackadaycom.files.wordpress.com/2019/02/moonpossiblelandings.png
ERROR:__main__:Could not get metadata for https://hackadaycom.files.wordpress.com/2019/02/moonpossiblelandings.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 99%|█████████▉| 1036/1049 [18:35<01:15,  5.82s/it]INFO:__main__:Requesting https://blogs.scientificamerican.com/beautiful-minds/when-does-intelligence-peak/
INFO:__main__:Getting metadata for https://blogs.scientificamerican.com/beautiful-minds/when-does-intelligence-peak/
 99%|█████████▉| 1037/1049 [18:36<00:51,  4.31s/it]INFO:__main__:Requesting https://sci-hub.tw/10.1177/0956797614567339
INFO:__main__:Getting metadata for https://sci-hub.tw/10.1177/0956797614567339
 99%|█████████▉| 1038/1049 [18:43<00:57,  5.19s/it]INFO:__main__:Requesting https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3637652/
INFO:__main__:Getting metadata for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3637652/
 99%|█████████▉| 1039/1049 [18:44<00:39,  3.97s/it]INFO:__main__:Requesting http://www.irisonboard.com/careers/
INFO:__main__:Getting metadata for https://www.irisonboard.com/careers/
 99%|█████████▉| 1040/1049 [18:49<00:38,  4.29s/it]INFO:__main__:Requesting https://medium.com/@anthonyheddings/vice-media-had-youtube-shut-down-my-gaming-channel-without-even-contacting-me-4298d13da841
INFO:__main__:Getting metadata for https://medium.com/@anthonyheddings/vice-media-had-youtube-shut-down-my-gaming-channel-without-even-contacting-me-4298d13da841
 99%|█████████▉| 1041/1049 [18:49<00:25,  3.13s/it]INFO:__main__:Requesting https://help.archive.org/hc/en-us/articles/360016399952-Collections-A-Basic-Guide-
INFO:__main__:Getting metadata for https://help.archive.org/hc/en-us/articles/360016399952-Collections-A-Basic-Guide-
 99%|█████████▉| 1042/1049 [18:50<00:16,  2.35s/it]INFO:__main__:Requesting https://www.backblaze.com/b2/cloud-storage-pricing.html
INFO:__main__:Getting metadata for https://www.backblaze.com/b2/cloud-storage-pricing.html
 99%|█████████▉| 1043/1049 [18:51<00:12,  2.08s/it]INFO:__main__:Requesting https://blog.littlevgl.com/2019-02-20/micropython-bindings
INFO:__main__:Getting metadata for https://blog.littlevgl.com/2019-02-20/micropython-bindings
100%|█████████▉| 1044/1049 [18:52<00:08,  1.62s/it]INFO:__main__:Requesting https://github.com/robertmuth/Pytorinox/blob/master/spi_display.py
INFO:__main__:Getting metadata for https://github.com/robertmuth/Pytorinox/blob/master/spi_display.py
100%|█████████▉| 1045/1049 [18:53<00:06,  1.54s/it]INFO:__main__:Requesting https://github.com/littlevgl/lvgl/graphs/code-frequency
INFO:__main__:Getting metadata for https://github.com/littlevgl/lvgl/graphs/code-frequency
100%|█████████▉| 1046/1049 [18:54<00:03,  1.28s/it]INFO:__main__:Requesting http://appjar.info/
INFO:__main__:Getting metadata for http://appjar.info
100%|█████████▉| 1047/1049 [18:54<00:02,  1.03s/it]INFO:__main__:Requesting https://techcrunch.com/2019/02/28/facebook-research-teens/
ERROR:__main__:Could not reach https://techcrunch.com/2019/02/28/facebook-research-teens/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
100%|█████████▉| 1048/1049 [18:54<00:00,  1.32it/s]INFO:__main__:Requesting https://github.com/giann/croissant
INFO:__main__:Getting metadata for https://github.com/giann/croissant
100%|██████████| 1049/1049 [18:55<00:00,  1.29it/s]
