INFO:__main__:Get urls from stories
  0%|          | 0/30 [00:00<?, ?it/s]  3%|▎         | 1/30 [00:01<00:43,  1.49s/it]  7%|▋         | 2/30 [00:03<00:41,  1.50s/it] 10%|█         | 3/30 [00:06<00:55,  2.04s/it] 13%|█▎        | 4/30 [00:06<00:41,  1.59s/it] 17%|█▋        | 5/30 [00:07<00:36,  1.45s/it] 23%|██▎       | 7/30 [00:08<00:23,  1.04s/it] 30%|███       | 9/30 [00:08<00:17,  1.21it/s] 37%|███▋      | 11/30 [00:08<00:11,  1.64it/s] 40%|████      | 12/30 [00:09<00:09,  1.85it/s] 47%|████▋     | 14/30 [00:09<00:06,  2.52it/s] 50%|█████     | 15/30 [00:09<00:05,  2.69it/s] 57%|█████▋    | 17/30 [00:10<00:03,  3.40it/s] 60%|██████    | 18/30 [00:12<00:13,  1.09s/it] 63%|██████▎   | 19/30 [00:16<00:19,  1.77s/it] 70%|███████   | 21/30 [00:16<00:11,  1.26s/it] 73%|███████▎  | 22/30 [00:18<00:12,  1.56s/it] 77%|███████▋  | 23/30 [00:19<00:09,  1.40s/it] 80%|████████  | 24/30 [00:20<00:06,  1.14s/it] 87%|████████▋ | 26/30 [00:20<00:03,  1.12it/s] 90%|█████████ | 27/30 [00:21<00:02,  1.40it/s] 93%|█████████▎| 28/30 [00:21<00:01,  1.47it/s] 97%|█████████▋| 29/30 [00:22<00:00,  1.50it/s]100%|██████████| 30/30 [00:23<00:00,  1.24it/s]
  0%|          | 0/859 [00:00<?, ?it/s]INFO:__main__:Requesting https://www.sec.gov/Archives/edgar/data/1759509/000119312519059849/d633517ds1.htm
INFO:__main__:Getting metadata for https://www.sec.gov/Archives/edgar/data/1759509/000119312519059849/d633517ds1.htm
  0%|          | 1/859 [00:16<3:58:06, 16.65s/it]INFO:__main__:Requesting https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/a-new-collaboration-with-google-cloud.html
INFO:__main__:Getting metadata for https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/a-new-collaboration-with-google-cloud.html
  0%|          | 2/859 [00:17<2:50:50, 11.96s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Y_Combinator
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Y_Combinator
  0%|          | 3/859 [00:18<2:04:59,  8.76s/it]INFO:__main__:Requesting https://news.ycombinator.com/newsguidelines.html
INFO:__main__:Getting metadata for https://news.ycombinator.com/newsguidelines.html
ERROR:__main__:Could not get metadata for https://news.ycombinator.com/newsguidelines.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  0%|          | 4/859 [00:20<1:32:04,  6.46s/it]INFO:__main__:Requesting https://www.reuters.com/article/us-uber-results/uber-posts-50-billion-in-annual-bookings-as-profit-remains-elusive-ahead-of-ipo-idUSKCN1Q42CI
INFO:__main__:Getting metadata for https://www.reuters.com/article/us-uber-results/uber-posts-50-billion-in-annual-bookings-as-profit-remains-elusive-ahead-of-ipo-idUSKCN1Q42CI
  1%|          | 5/859 [00:20<1:05:34,  4.61s/it]INFO:__main__:Requesting https://www.bloomberg.com/news/articles/2018-11-14/uber-revenue-slows-as-quarterly-loss-surges-to-1-1-billion
INFO:__main__:Getting metadata for https://www.bloomberg.com/tosv2.html?vid=&uuid=7eb325a0-3c54-11e9-8837-fb17e887e7f5&url=L25ld3MvYXJ0aWNsZXMvMjAxOC0xMS0xNC91YmVyLXJldmVudWUtc2xvd3MtYXMtcXVhcnRlcmx5LWxvc3Mtc3VyZ2VzLXRvLTEtMS1iaWxsaW9u
  1%|          | 6/859 [00:21<49:05,  3.45s/it]  INFO:__main__:Requesting https://twitter.com/modestproposal1/status/1101542179481288704
INFO:__main__:Getting metadata for https://twitter.com/modestproposal1/status/1101542179481288704
  1%|          | 7/859 [00:22<38:28,  2.71s/it]INFO:__main__:Requesting https://play.google.com/store/apps/details?id=com.ubercab.fleet&hl=en
INFO:__main__:Getting metadata for https://play.google.com/store/apps/details?id=com.ubercab.fleet&hl=en
  1%|          | 8/859 [00:22<28:40,  2.02s/it]INFO:__main__:Requesting https://www.bloomberg.com/opinion/articles/2019-02-12/lyft-doesn-t-need-investors-to-vote
INFO:__main__:Getting metadata for https://www.bloomberg.com/tosv2.html?vid=&uuid=7ff9d670-3c54-11e9-97c2-cd576105ba15&url=L29waW5pb24vYXJ0aWNsZXMvMjAxOS0wMi0xMi9seWZ0LWRvZXNuLXQtbmVlZC1pbnZlc3RvcnMtdG8tdm90ZQ==
  1%|          | 9/859 [00:23<22:24,  1.58s/it]INFO:__main__:Requesting https://blog.bolt.io/casper-glow-e4f8819376d7
INFO:__main__:Getting metadata for https://blog.bolt.io/casper-glow-e4f8819376d7?gi=a254f551fbf9
  1%|          | 10/859 [00:24<20:15,  1.43s/it]INFO:__main__:Requesting https://bedtimebulb.com/
INFO:__main__:Getting metadata for https://bedtimebulb.com
  1%|▏         | 11/859 [00:24<17:03,  1.21s/it]INFO:__main__:Requesting https://i.imgur.com/fHJKxWA.png
INFO:__main__:Getting metadata for https://i.imgur.com/fHJKxWA.png
ERROR:__main__:Could not get metadata for https://i.imgur.com/fHJKxWA.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  1%|▏         | 12/859 [00:27<23:58,  1.70s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Intrinsically_photosensitive_retinal_ganglion_cells
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Intrinsically_photosensitive_retinal_ganglion_cells
  2%|▏         | 13/859 [00:28<22:10,  1.57s/it]INFO:__main__:Requesting https://www.ies.org/fires/melanopic-green-the-other-side-of-blue/
INFO:__main__:Getting metadata for https://www.ies.org/fires/melanopic-green-the-other-side-of-blue/
  2%|▏         | 14/859 [00:33<35:24,  2.51s/it]INFO:__main__:Requesting https://fluxometer.com/rainbow/#!id=iPad%20Pro/6500K-iPad%20Pro
INFO:__main__:Getting metadata for https://fluxometer.com/rainbow/#!id=iPad%20Pro/6500K-iPad%20Pro
  2%|▏         | 15/859 [00:34<28:18,  2.01s/it]INFO:__main__:Requesting https://i.stack.imgur.com/5snTb.png
INFO:__main__:Getting metadata for https://i.stack.imgur.com/5snTb.png
ERROR:__main__:Could not get metadata for https://i.stack.imgur.com/5snTb.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  2%|▏         | 16/859 [00:35<23:15,  1.66s/it]INFO:__main__:Requesting https://medium.com/@BenEinstein/heres-why-juicero-s-press-is-so-expensive-6add74594e50
INFO:__main__:Getting metadata for https://medium.com/@BenEinstein/heres-why-juicero-s-press-is-so-expensive-6add74594e50
  2%|▏         | 17/859 [00:35<18:49,  1.34s/it]INFO:__main__:Requesting https://www.recode.net/2017/9/23/13153814/casper-sleepopolis-lawsuits-mattress-reviews
INFO:__main__:Getting metadata for https://www.recode.net/2017/9/23/13153814/casper-sleepopolis-lawsuits-mattress-reviews
  2%|▏         | 18/859 [00:36<16:03,  1.15s/it]INFO:__main__:Requesting https://i.imgur.com/NCr148L.png
INFO:__main__:Getting metadata for https://i.imgur.com/NCr148L.png
ERROR:__main__:Could not get metadata for https://i.imgur.com/NCr148L.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  2%|▏         | 19/859 [00:48<59:41,  4.26s/it]INFO:__main__:Requesting https://twitter.com/tmincey/status/1097990987849158657
INFO:__main__:Getting metadata for https://twitter.com/tmincey/status/1097990987849158657
  2%|▏         | 20/859 [00:48<44:59,  3.22s/it]INFO:__main__:Requesting https://www.macrumors.com/review/casper-glow-light/
INFO:__main__:Getting metadata for https://www.macrumors.com/review/casper-glow-light/
ERROR:__main__:Could not get metadata for https://www.macrumors.com/review/casper-glow-light/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  2%|▏         | 21/859 [00:49<34:02,  2.44s/it]INFO:__main__:Requesting https://thewirecutter.com/reviews/best-sunrise-alarm-clock/
INFO:__main__:Getting metadata for https://thewirecutter.com/reviews/best-sunrise-alarm-clock/
  3%|▎         | 22/859 [00:51<31:05,  2.23s/it]INFO:__main__:Requesting https://casper.com/glow-light/buy/
INFO:__main__:Getting metadata for https://casper.com/glow-light/buy/
  3%|▎         | 23/859 [00:51<24:38,  1.77s/it]INFO:__main__:Requesting https://slashdot.org/story/01/10/23/1816257/apple-releases-ipod
INFO:__main__:Getting metadata for https://slashdot.org/story/01/10/23/1816257/apple-releases-ipod
  3%|▎         | 24/859 [00:53<21:32,  1.55s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=rvlA9UxGvSg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=rvlA9UxGvSg
  3%|▎         | 25/859 [00:53<18:49,  1.35s/it]INFO:__main__:Requesting https://bolt.io/portfolio
INFO:__main__:Getting metadata for https://bolt.io/portfolio
  3%|▎         | 26/859 [00:54<16:17,  1.17s/it]INFO:__main__:Requesting https://theconversation.com/europes-electronic-waste-has-become-africas-burden-17123
INFO:__main__:Getting metadata for https://theconversation.com/europes-electronic-waste-has-become-africas-burden-17123
  3%|▎         | 27/859 [00:55<14:17,  1.03s/it]INFO:__main__:Requesting https://quarkworks.co/careers/
INFO:__main__:Getting metadata for https://quarkworks.co/careers/
  3%|▎         | 28/859 [00:56<14:56,  1.08s/it]INFO:__main__:Requesting https://paige.ai/careers
INFO:__main__:Getting metadata for https://paige.ai/careers
  3%|▎         | 29/859 [00:57<12:40,  1.09it/s]INFO:__main__:Requesting https://newknowledge.com/
INFO:__main__:Getting metadata for https://www.newknowledge.com
  3%|▎         | 30/859 [00:57<11:03,  1.25it/s]INFO:__main__:Requesting https://tcrn.ch/2Pfuw6X
ERROR:__main__:Could not reach https://tcrn.ch/2Pfuw6X
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 247, in resolve_redirects
    **adapter_kwargs
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
  4%|▎         | 31/859 [00:58<10:11,  1.35it/s]INFO:__main__:Requesting https://grnh.se/43037c332
INFO:__main__:Getting metadata for https://boards.greenhouse.io/newknowledge?gh_src=43037c332
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/newknowledge?gh_src=43037c332
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  4%|▎         | 32/859 [00:58<09:34,  1.44it/s]INFO:__main__:Requesting https://faithlife.com/jobs/SeniorFaithlifeFullStackSoftwareDeveloper
INFO:__main__:Getting metadata for https://faithlife.com/jobs/SeniorFaithlifeFullStackSoftwareDeveloper
ERROR:__main__:Could not get metadata for https://faithlife.com/jobs/SeniorFaithlifeFullStackSoftwareDeveloper
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  4%|▍         | 33/859 [01:00<13:49,  1.00s/it]INFO:__main__:Requesting https://faithlife.com/careers
INFO:__main__:Getting metadata for https://faithlife.com/careers
ERROR:__main__:Could not get metadata for https://faithlife.com/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  4%|▍         | 34/859 [01:03<20:47,  1.51s/it]INFO:__main__:Requesting https://routific.com
INFO:__main__:Getting metadata for https://routific.com
  4%|▍         | 35/859 [01:03<15:30,  1.13s/it]INFO:__main__:Requesting https://www.keyvalues.com/routific
INFO:__main__:Getting metadata for https://www.keyvalues.com/routific
  4%|▍         | 36/859 [01:04<15:35,  1.14s/it]INFO:__main__:Requesting https://angel.co/routific/jobs/376543-lead-software-engineer
INFO:__main__:Requesting https://angel.co/routific/jobs/454028-front-end-engineer
  4%|▍         | 38/859 [01:04<11:12,  1.22it/s]INFO:__main__:Requesting https://grnh.se/56c2c14f1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1322558?gh_jid=1322558&gh_src=56c2c14f1
  5%|▍         | 39/859 [01:05<10:10,  1.34it/s]INFO:__main__:Requesting https://grnh.se/4a7949431
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1223519?gh_jid=1223519&gh_src=4a7949431
  5%|▍         | 40/859 [01:05<09:22,  1.46it/s]INFO:__main__:Requesting https://grnh.se/rh1uey1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/470002?gh_jid=470002&gh_src=rh1uey1
  5%|▍         | 41/859 [01:06<08:47,  1.55it/s]INFO:__main__:Requesting https://grnh.se/qn7v6a1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1006253?gh_jid=1006253&gh_src=qn7v6a1
  5%|▍         | 42/859 [01:07<08:27,  1.61it/s]INFO:__main__:Requesting https://grnh.se/h4psfq1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/76998?gh_jid=76998&gh_src=h4psfq1
  5%|▌         | 43/859 [01:07<09:10,  1.48it/s]INFO:__main__:Requesting https://grnh.se/435ca3b81
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1451341?gh_jid=1451341&gh_src=435ca3b81
  5%|▌         | 44/859 [01:08<08:38,  1.57it/s]INFO:__main__:Requesting https://grnh.se/a6888fb31
INFO:__main__:Getting metadata for https://boards.greenhouse.io/braze/jobs/1477155?gh_jid=1477155&gh_src=a6888fb31
  5%|▌         | 45/859 [01:08<08:29,  1.60it/s]INFO:__main__:Requesting https://www.braze.com/perspectives/tag/building-braze
INFO:__main__:Getting metadata for https://www.braze.com/perspectives/tag/building-braze
ERROR:__main__:Could not get metadata for https://www.braze.com/perspectives/tag/building-braze
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  5%|▌         | 46/859 [01:11<15:50,  1.17s/it]INFO:__main__:Requesting https://nanovms.com
INFO:__main__:Getting metadata for https://nanovms.com
  5%|▌         | 47/859 [01:12<16:09,  1.19s/it]INFO:__main__:Requesting https://www.elationhealth.com/careers/
INFO:__main__:Getting metadata for https://www.elationhealth.com/careers/
  6%|▌         | 48/859 [01:12<11:58,  1.13it/s]INFO:__main__:Requesting https://www.dialpad.com/
INFO:__main__:Getting metadata for https://www.dialpad.com
  6%|▌         | 49/859 [01:13<09:27,  1.43it/s]INFO:__main__:Requesting https://www.dialpad.com/jobs
INFO:__main__:Getting metadata for https://www.dialpad.com/careers/
  6%|▌         | 50/859 [01:13<08:05,  1.67it/s]INFO:__main__:Requesting https://www.clearvoice.com
INFO:__main__:Getting metadata for https://www.clearvoice.com
  6%|▌         | 51/859 [01:13<06:34,  2.05it/s]INFO:__main__:Requesting https://clearvoice.workable.com/j/B2A0B579A0
INFO:__main__:Getting metadata for https://clearvoice.workable.com/j/B2A0B579A0
  6%|▌         | 52/859 [01:14<07:12,  1.86it/s]INFO:__main__:Requesting https://cobaltrobotics.com/
  6%|▌         | 53/859 [01:14<06:01,  2.23it/s]INFO:__main__:Requesting https://cobaltrobotics.com/about/
  6%|▋         | 54/859 [01:14<05:03,  2.65it/s]INFO:__main__:Requesting https://cobaltrobotics.com/careers/
  6%|▋         | 55/859 [01:14<04:21,  3.07it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/e00d5c11-7bc1-4255-aca5-ada02dbd6a83
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/e00d5c11-7bc1-4255-aca5-ada02dbd6a83
  7%|▋         | 56/859 [01:15<05:36,  2.39it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/82ae1594-1a43-46f0-b36a-5fa6695ce73c
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/82ae1594-1a43-46f0-b36a-5fa6695ce73c
  7%|▋         | 57/859 [01:16<06:22,  2.10it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/a2caf247-568b-4046-8359-15b07cb813fd
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/a2caf247-568b-4046-8359-15b07cb813fd
  7%|▋         | 58/859 [01:16<06:53,  1.94it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/17b3d320-ccf0-4dc5-bc78-3d1900096ae2
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/17b3d320-ccf0-4dc5-bc78-3d1900096ae2
  7%|▋         | 59/859 [01:17<07:11,  1.85it/s]INFO:__main__:Requesting https://jobs.lever.co/cobaltrobotics/ec249d41-ab2d-4485-a440-ae2e2b682dbc
INFO:__main__:Getting metadata for https://jobs.lever.co/cobaltrobotics/ec249d41-ab2d-4485-a440-ae2e2b682dbc
  7%|▋         | 60/859 [01:18<07:23,  1.80it/s]INFO:__main__:Requesting https://twine.com/jobs/
INFO:__main__:Getting metadata for https://twine.com/jobs/
  7%|▋         | 61/859 [01:18<05:43,  2.32it/s]INFO:__main__:Requesting https://itunes.apple.com/us/app/twine-easy-saving-investing/id1292080056?mt=8
INFO:__main__:Getting metadata for https://itunes.apple.com/us/app/twine-easy-saving-investing/id1292080056?mt=8
  7%|▋         | 62/859 [01:18<06:22,  2.09it/s]INFO:__main__:Requesting https://kiron.ngo/tech-jobs
INFO:__main__:Getting metadata for https://kiron.ngo/tech-jobs
ERROR:__main__:Could not get metadata for https://kiron.ngo/tech-jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  7%|▋         | 63/859 [01:20<09:52,  1.34it/s]INFO:__main__:Requesting https://www.intersection.com
INFO:__main__:Getting metadata for https://www.intersection.com
  7%|▋         | 64/859 [01:20<08:32,  1.55it/s]INFO:__main__:Requesting https://rebrand.ly/ixnjobs
INFO:__main__:Getting metadata for https://boards.greenhouse.io/intersection?gh_src=be100a9b1
  8%|▊         | 65/859 [01:21<09:13,  1.43it/s]INFO:__main__:Requesting https://jobs.amd.com/
INFO:__main__:Getting metadata for https://jobs.amd.com
  8%|▊         | 66/859 [01:22<09:06,  1.45it/s]INFO:__main__:Requesting https://balena.io
INFO:__main__:Getting metadata for https://www.balena.io
  8%|▊         | 67/859 [01:22<10:10,  1.30it/s]INFO:__main__:Requesting https://balena.workable.com/j/39F9C34AA8
INFO:__main__:Getting metadata for https://balena.workable.com/j/39F9C34AA8
  8%|▊         | 68/859 [01:23<09:51,  1.34it/s]INFO:__main__:Requesting https://boards.greenhouse.io/instacart
INFO:__main__:Getting metadata for https://boards.greenhouse.io/instacart
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/instacart
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  8%|▊         | 69/859 [01:24<08:35,  1.53it/s]INFO:__main__:Requesting https://lsst.org
ERROR:__main__:Could not reach https://lsst.org
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 344, in connect
    ssl_context=context)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/ssl_.py", line 344, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 407, in wrap_socket
    _context=self, _session=session)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 814, in __init__
    self.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1068, in do_handshake
    self._sslobj.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='lsst.org', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='lsst.org', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))
  8%|▊         | 70/859 [01:24<06:39,  1.98it/s]INFO:__main__:Requesting http://ls.st/6oc
INFO:__main__:Getting metadata for https://recruiting2.ultipro.com/SPA1004AURA/JobBoard/3a88e9d0-e68e-418e-9433-d36443ba8c5b/OpportunityDetail?opportunityId=82ec7171-6f4d-4023-bf1c-20a3ffc3cfd7
ERROR:__main__:Could not get metadata for https://recruiting2.ultipro.com/SPA1004AURA/JobBoard/3a88e9d0-e68e-418e-9433-d36443ba8c5b/OpportunityDetail?opportunityId=82ec7171-6f4d-4023-bf1c-20a3ffc3cfd7
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  8%|▊         | 71/859 [01:27<16:55,  1.29s/it]INFO:__main__:Requesting https://www.amazon.jobs/en/jobs/795613/software-development-manager-hpc
INFO:__main__:Getting metadata for https://www.amazon.jobs/en/jobs/795613/software-development-manager-hpc
  8%|▊         | 72/859 [01:27<13:49,  1.05s/it]INFO:__main__:Requesting http://boofla.io/jobs
INFO:__main__:Getting metadata for https://github.com/awsboofla/jobs/blob/master/README.md
  8%|▊         | 73/859 [01:29<14:34,  1.11s/it]INFO:__main__:Requesting https://www.rapid7.com/careers/jobs/
INFO:__main__:Getting metadata for https://www.rapid7.com/careers/jobs/
ERROR:__main__:Could not get metadata for https://www.rapid7.com/careers/jobs/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
  9%|▊         | 74/859 [01:29<11:33,  1.13it/s]INFO:__main__:Requesting https://secfirst.org
INFO:__main__:Getting metadata for https://secfirst.org
  9%|▊         | 75/859 [01:31<17:47,  1.36s/it]INFO:__main__:Requesting https://reasi.com
ERROR:__main__:Could not reach https://reasi.com
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 344, in connect
    ssl_context=context)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/ssl_.py", line 344, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 407, in wrap_socket
    _context=self, _session=session)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 814, in __init__
    self.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1068, in do_handshake
    self._sslobj.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='reasi.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='reasi.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))
  9%|▉         | 76/859 [01:32<13:04,  1.00s/it]INFO:__main__:Requesting https://vimeo.com/307810015
INFO:__main__:Requesting https://redoxchem.com/careers/software-engineer
INFO:__main__:Getting metadata for https://redoxchem.com/careers/software-engineer
  9%|▉         | 78/859 [01:33<12:45,  1.02it/s]INFO:__main__:Requesting https://www.voom.flights
INFO:__main__:Getting metadata for https://www.voom.flights/en
  9%|▉         | 79/859 [01:36<16:51,  1.30s/it]INFO:__main__:Requesting https://www.keyvalues.com/voom
INFO:__main__:Getting metadata for https://www.keyvalues.com/voom
  9%|▉         | 80/859 [01:37<16:26,  1.27s/it]INFO:__main__:Requesting https://grnh.se/ba1fd7e92
INFO:__main__:Getting metadata for https://www.voom.flights/careers?gh_jid=4009041002&gh_src=ba1fd7e92
  9%|▉         | 81/859 [01:41<28:54,  2.23s/it]INFO:__main__:Requesting https://grnh.se/c279ceca2
INFO:__main__:Getting metadata for https://www.voom.flights/careers?gh_jid=4009043002&gh_src=c279ceca2
 10%|▉         | 82/859 [01:43<27:11,  2.10s/it]INFO:__main__:Requesting https://grnh.se/7365f3d92
INFO:__main__:Getting metadata for https://www.voom.flights/careers?gh_jid=4122366002&gh_src=7365f3d92
 10%|▉         | 83/859 [01:45<26:39,  2.06s/it]INFO:__main__:Requesting https://www.thorn.org
INFO:__main__:Getting metadata for https://www.thorn.org
 10%|▉         | 84/859 [01:45<20:37,  1.60s/it]INFO:__main__:Requesting https://grnh.se/d96da8052
INFO:__main__:Getting metadata for https://www.thorn.org/careers/application/?gh_jid=4131539002&gh_src=d96da8052
 10%|▉         | 85/859 [01:46<16:32,  1.28s/it]INFO:__main__:Requesting https://grnh.se/c9baa7dd2
INFO:__main__:Getting metadata for https://www.thorn.org/careers/application/?gh_jid=4131953002&gh_src=c9baa7dd2
 10%|█         | 86/859 [01:47<13:48,  1.07s/it]INFO:__main__:Requesting https://grnh.se/35ead91b2
INFO:__main__:Getting metadata for https://www.thorn.org/careers/application/?gh_jid=4131960002&gh_src=35ead91b2
 10%|█         | 87/859 [01:47<11:46,  1.09it/s]INFO:__main__:Requesting https://lumen5.com
INFO:__main__:Getting metadata for https://lumen5.com
 10%|█         | 88/859 [01:48<09:41,  1.33it/s]INFO:__main__:Requesting https://lumen5.workable.com/j/982A995E5D
INFO:__main__:Getting metadata for https://lumen5.workable.com/j/982A995E5D
 10%|█         | 89/859 [01:48<10:03,  1.28it/s]INFO:__main__:Requesting https://lumen5.workable.com/j/964B167919
INFO:__main__:Getting metadata for https://lumen5.workable.com/j/964B167919
 10%|█         | 90/859 [01:49<10:11,  1.26it/s]INFO:__main__:Requesting https://vetspire.com
INFO:__main__:Getting metadata for https://vetspire.com
 11%|█         | 91/859 [01:50<10:46,  1.19it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/vetspirecom/view/P_AAAAAAHAABwItYGm-ime-H
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/vetspirecom/view/P_AAAAAAHAABwItYGm-ime-H
 11%|█         | 92/859 [01:51<09:03,  1.41it/s]INFO:__main__:Requesting https://smapiot.com
INFO:__main__:Getting metadata for https://www.smapiot.com/en/
 11%|█         | 93/859 [01:55<21:48,  1.71s/it]INFO:__main__:Requesting https://jobs.lever.co/jellyfish
INFO:__main__:Getting metadata for https://jobs.lever.co/jellyfish
 11%|█         | 94/859 [01:55<17:44,  1.39s/it]INFO:__main__:Requesting https://about.gitlab.com/jobs/
INFO:__main__:Getting metadata for https://about.gitlab.com/jobs/
 11%|█         | 95/859 [01:56<13:45,  1.08s/it]INFO:__main__:Requesting https://about.gitlab.com/2018/03/15/working-at-gitlab-affects-my-life/
INFO:__main__:Getting metadata for https://about.gitlab.com/2018/03/15/working-at-gitlab-affects-my-life/
 11%|█         | 96/859 [01:56<10:52,  1.17it/s]INFO:__main__:Requesting https://about.gitlab.com/handbook/
INFO:__main__:Getting metadata for https://about.gitlab.com/handbook/
 11%|█▏        | 97/859 [01:56<08:36,  1.47it/s]INFO:__main__:Requesting https://instructure.com/
INFO:__main__:Getting metadata for https://www.instructure.com
 11%|█▏        | 98/859 [01:57<10:13,  1.24it/s]INFO:__main__:Requesting https://code.instructure.com/
INFO:__main__:Getting metadata for https://code.instructure.com
 12%|█▏        | 99/859 [01:58<08:44,  1.45it/s]INFO:__main__:Requesting https://jobs.lever.co/instructure?lever-via=IQ-V_FRhae&team=Engineering
INFO:__main__:Getting metadata for https://jobs.lever.co/instructure?lever-via=IQ-V_FRhae&team=Engineering
 12%|█▏        | 100/859 [01:58<08:51,  1.43it/s]INFO:__main__:Requesting https://www.rigetti.com/
INFO:__main__:Getting metadata for https://www.rigetti.com
 12%|█▏        | 101/859 [01:59<06:56,  1.82it/s]INFO:__main__:Requesting https://bitonic.nl/jobs
INFO:__main__:Getting metadata for https://bitonic.nl/jobs
ERROR:__main__:Could not get metadata for https://bitonic.nl/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 12%|█▏        | 102/859 [02:00<09:10,  1.37it/s]INFO:__main__:Requesting https://formassembly.workable.com
INFO:__main__:Getting metadata for https://formassembly.workable.com
ERROR:__main__:Could not get metadata for https://formassembly.workable.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 12%|█▏        | 103/859 [02:00<08:45,  1.44it/s]INFO:__main__:Requesting https://www.formassembly.com/blog/remote-jobs/
INFO:__main__:Getting metadata for https://www.formassembly.com/blog/remote-jobs/
 12%|█▏        | 104/859 [02:03<15:54,  1.26s/it]INFO:__main__:Requesting https://octopart.com/jobs
 12%|█▏        | 105/859 [02:03<12:05,  1.04it/s]INFO:__main__:Requesting https://kbra.bamboohr.com/jobs/
INFO:__main__:Getting metadata for https://kbra.bamboohr.com/jobs/
 12%|█▏        | 106/859 [02:04<11:22,  1.10it/s]INFO:__main__:Requesting https://www.biggerpockets.com
INFO:__main__:Getting metadata for https://www.biggerpockets.com
ERROR:__main__:Could not get metadata for https://www.biggerpockets.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 12%|█▏        | 107/859 [02:05<12:47,  1.02s/it]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/biggerpocketscom/view/P_AAAAAACAAGcKW6a4VbvODl
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/biggerpocketscom/view/P_AAAAAACAAGcKW6a4VbvODl
 13%|█▎        | 108/859 [02:06<10:02,  1.25it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/biggerpocketscom/view/P_AAAAAACAAADJV1i6e-Ig6T
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/biggerpocketscom/view/P_AAAAAACAAADJV1i6e-Ig6T
 13%|█▎        | 109/859 [02:06<07:58,  1.57it/s]INFO:__main__:Requesting https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3062
INFO:__main__:Getting metadata for https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3062
 13%|█▎        | 110/859 [02:06<06:52,  1.82it/s]INFO:__main__:Requesting https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3174
INFO:__main__:Getting metadata for https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3174
 13%|█▎        | 111/859 [02:07<05:56,  2.10it/s]INFO:__main__:Requesting https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3173
INFO:__main__:Getting metadata for https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3173
 13%|█▎        | 112/859 [02:07<05:26,  2.29it/s]INFO:__main__:Requesting https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3148
INFO:__main__:Getting metadata for https://chp.tbe.taleo.net/chp04/ats/careers/v2/viewRequisition?org=GAMES2K&cws=68&rid=3148
 13%|█▎        | 113/859 [02:07<05:15,  2.37it/s]INFO:__main__:Requesting https://borrowell.workable.com/jobs/871672
INFO:__main__:Getting metadata for https://borrowell.workable.com/jobs/871672
 13%|█▎        | 114/859 [02:08<06:10,  2.01it/s]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?165030BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?165030BR
 13%|█▎        | 115/859 [02:09<08:00,  1.55it/s]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?165571BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?165571BR
 14%|█▎        | 116/859 [02:10<09:30,  1.30it/s]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?167765BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?167765BR
 14%|█▎        | 117/859 [02:11<10:16,  1.20it/s]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?167431BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?167431BR
 14%|█▎        | 118/859 [02:12<11:13,  1.10it/s]INFO:__main__:Requesting https://www.warnerbroscareers.com/find-jobs/?165215BR
INFO:__main__:Getting metadata for https://www.warnerbroscareers.com/find-jobs/?165215BR
 14%|█▍        | 119/859 [02:13<12:00,  1.03it/s]INFO:__main__:Requesting https://jobs.lever.co/rescale
INFO:__main__:Getting metadata for https://jobs.lever.co/rescale
 14%|█▍        | 120/859 [02:14<10:49,  1.14it/s]INFO:__main__:Requesting https://www.opendoor.com/jobs
INFO:__main__:Getting metadata for https://www.opendoor.com/jobs
 14%|█▍        | 121/859 [02:15<10:59,  1.12it/s]INFO:__main__:Requesting https://purelabs.io
INFO:__main__:Getting metadata for https://purelabs.io
 14%|█▍        | 122/859 [02:16<12:16,  1.00it/s]INFO:__main__:Requesting http://jobs.purelabs.io
INFO:__main__:Getting metadata for http://jobs.purelabs.io
 14%|█▍        | 123/859 [02:17<11:11,  1.10it/s]INFO:__main__:Requesting https://narrativ.com/careers#positions
INFO:__main__:Getting metadata for https://narrativ.com/careers#positions
 14%|█▍        | 124/859 [02:17<10:12,  1.20it/s]INFO:__main__:Requesting https://circle.careers/en/
INFO:__main__:Getting metadata for https://circle.careers/en/
 15%|█▍        | 125/859 [02:18<11:14,  1.09it/s]INFO:__main__:Requesting http://blog.coveo.com/coveo-leads-gartner-magic-quadrant-for-insight-engines/
INFO:__main__:Getting metadata for https://blog.coveo.com/coveo-leads-gartner-magic-quadrant-for-insight-engines/
 15%|█▍        | 126/859 [02:20<12:49,  1.05s/it]INFO:__main__:Requesting http://blog.coveo.com/coveo-montreal-finally-home/
INFO:__main__:Getting metadata for https://blog.coveo.com/coveo-montreal-finally-home/
 15%|█▍        | 127/859 [02:23<20:08,  1.65s/it]INFO:__main__:Requesting https://www.freenome.com/careers
INFO:__main__:Getting metadata for https://www.freenome.com/careers
 15%|█▍        | 128/859 [02:24<16:46,  1.38s/it]INFO:__main__:Requesting https://housecallpro.com
INFO:__main__:Getting metadata for https://www.housecallpro.com
 15%|█▌        | 129/859 [02:24<14:20,  1.18s/it]INFO:__main__:Requesting https://www.housecallpro.com/careers
INFO:__main__:Getting metadata for https://www.housecallpro.com/careers
 15%|█▌        | 130/859 [02:25<12:38,  1.04s/it]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4NYa8xCRLI3U
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4NYa8xCRLI3U
 15%|█▌        | 131/859 [02:25<09:41,  1.25it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4JKqoth5B9xJ
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4JKqoth5B9xJ
 15%|█▌        | 132/859 [02:25<07:30,  1.62it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4Lkm--iIlF9j
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/housecallprocom/view/P_AAAAAACAAI4Lkm--iIlF9j
 15%|█▌        | 133/859 [02:26<06:08,  1.97it/s]INFO:__main__:Requesting https://www.okta.com/company/careers/
INFO:__main__:Getting metadata for https://www.okta.com/company/careers/
 16%|█▌        | 134/859 [02:26<05:33,  2.17it/s]INFO:__main__:Requesting https://legalstart.fr
INFO:__main__:Getting metadata for https://www.legalstart.fr
 16%|█▌        | 135/859 [02:31<22:01,  1.83s/it]INFO:__main__:Requesting http://smrtr.io/WTSz
INFO:__main__:Getting metadata for https://jobs.smartrecruiters.com/Legalstart/743999682804573-lead-dev-full-stack-python
 16%|█▌        | 136/859 [02:32<19:27,  1.61s/it]INFO:__main__:Requesting http://smrtr.io/4NUKgA
INFO:__main__:Getting metadata for https://jobs.smartrecruiters.com/Legalstart/743999665887249-front-end-developer
 16%|█▌        | 137/859 [02:33<17:53,  1.49s/it]INFO:__main__:Requesting http://smrtr.io/V4xy
INFO:__main__:Getting metadata for https://jobs.smartrecruiters.com/Legalstart/743999681777219-ux-ui-designer
 16%|█▌        | 138/859 [02:35<16:28,  1.37s/it]INFO:__main__:Requesting https://splice.com/
INFO:__main__:Getting metadata for https://splice.com
ERROR:__main__:Could not get metadata for https://splice.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 16%|█▌        | 139/859 [02:35<13:08,  1.09s/it]INFO:__main__:Requesting https://boards.greenhouse.io/splice
INFO:__main__:Getting metadata for https://boards.greenhouse.io/splice
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/splice
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 16%|█▋        | 140/859 [02:35<10:31,  1.14it/s]INFO:__main__:Requesting http://www.Gastrograph.com/
INFO:__main__:Getting metadata for https://www.gastrograph.com
 16%|█▋        | 141/859 [02:36<09:31,  1.26it/s]INFO:__main__:Requesting https://jobs.target.com/job/brooklyn-park/senior-engineer-cyber-security-engineering/1118/9827943
INFO:__main__:Getting metadata for https://jobs.target.com/job/brooklyn-park/senior-engineer-cyber-security-engineering/1118/9827943
 17%|█▋        | 142/859 [02:37<08:49,  1.35it/s]INFO:__main__:Requesting https://jobs.target.com/search-jobs/Cyber%20Security/Minneapolis%2C%20MN/1118/1/4/6252001-5037779-5029877-5037649/44x97997/-93x26384/50/2
INFO:__main__:Getting metadata for https://jobs.target.com/search-jobs/Cyber%20Security/Minneapolis%2C%20MN/1118/1/4/6252001-5037779-5029877-5037649/44x97997/-93x26384/50/2
 17%|█▋        | 143/859 [02:37<06:53,  1.73it/s]INFO:__main__:Requesting https://jobs.apple.com/en-us/details/113638128/firmware-engineer?team=HRDWR
INFO:__main__:Getting metadata for https://jobs.apple.com/en-us/details/113638128/firmware-engineer?team=HRDWR
 17%|█▋        | 144/859 [02:39<11:57,  1.00s/it]INFO:__main__:Requesting https://wikifactory.com/jobs
INFO:__main__:Getting metadata for https://wikifactory.com/jobs
ERROR:__main__:Could not get metadata for https://wikifactory.com/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 17%|█▋        | 145/859 [02:41<16:52,  1.42s/it]INFO:__main__:Requesting https://www.grain.co
INFO:__main__:Getting metadata for https://www.grain.co
ERROR:__main__:Could not get metadata for https://www.grain.co
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 17%|█▋        | 146/859 [02:41<13:04,  1.10s/it]INFO:__main__:Requesting https://www.grain.co/careers
INFO:__main__:Getting metadata for https://www.grain.co/careers
ERROR:__main__:Could not get metadata for https://www.grain.co/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 17%|█▋        | 147/859 [02:42<10:11,  1.16it/s]INFO:__main__:Requesting https://grnh.se/dn27gt1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/squarespace?gh_src=dn27gt1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/squarespace?gh_src=dn27gt1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 17%|█▋        | 148/859 [02:42<09:00,  1.32it/s]INFO:__main__:Requesting https://sysdig.com/jobs/
INFO:__main__:Getting metadata for https://sysdig.com/jobs/
ERROR:__main__:Could not get metadata for https://sysdig.com/jobs/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 17%|█▋        | 149/859 [02:42<06:50,  1.73it/s]INFO:__main__:Requesting https://grnh.se/ab298b881
INFO:__main__:Getting metadata for https://boards.greenhouse.io/sysdig/jobs/1564554?gh_src=ab298b881
 17%|█▋        | 150/859 [02:43<07:15,  1.63it/s]INFO:__main__:Requesting http://science.sciencemag.org/content/363/6422/88
INFO:__main__:Getting metadata for http://science.sciencemag.org/content/363/6422/88
 18%|█▊        | 151/859 [02:46<14:51,  1.26s/it]INFO:__main__:Requesting https://doi.org/10.1016/j.molcel.2018.02.028
INFO:__main__:Getting metadata for https://linkinghub.elsevier.com/retrieve/pii/S1097276518301734
ERROR:__main__:Could not get metadata for https://linkinghub.elsevier.com/retrieve/pii/S1097276518301734
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 18%|█▊        | 152/859 [02:48<19:07,  1.62s/it]INFO:__main__:Requesting https://arbor.bio/careers
INFO:__main__:Getting metadata for https://arbor.bio/careers
ERROR:__main__:Could not get metadata for https://arbor.bio/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 18%|█▊        | 153/859 [02:49<15:59,  1.36s/it]INFO:__main__:Requesting https://grnh.se/273a4c161
INFO:__main__:Getting metadata for https://boards.greenhouse.io/wikimedia/jobs/1436353?gh_src=273a4c161
 18%|█▊        | 154/859 [02:50<13:32,  1.15s/it]INFO:__main__:Requesting https://wikimediafoundation.org/about
INFO:__main__:Getting metadata for https://wikimediafoundation.org/about/
 18%|█▊        | 155/859 [02:51<13:14,  1.13s/it]INFO:__main__:Requesting https://wikitech.wikimedia.org/wiki/Help:Cloud_Services_Introduction
INFO:__main__:Getting metadata for https://wikitech.wikimedia.org/wiki/Help:Cloud_Services_Introduction
 18%|█▊        | 156/859 [02:51<11:20,  1.03it/s]INFO:__main__:Requesting https://www.omadahealth.com/press/press-release-omada-health-adds-new-programs-fortype-2-diabetes-and-hypertension-self-management
INFO:__main__:Getting metadata for https://www.omadahealth.com/press/press-release-omada-health-adds-new-programs-fortype-2-diabetes-and-hypertension-self-management
 18%|█▊        | 157/859 [02:52<09:52,  1.18it/s]INFO:__main__:Requesting https://www.omadahealth.com/press/press-release-omada-health-expanding-to-serve-individuals-with-depression-and-anxiety
INFO:__main__:Getting metadata for https://www.omadahealth.com/press/press-release-omada-health-expanding-to-serve-individuals-with-depression-and-anxiety
 18%|█▊        | 158/859 [02:53<08:33,  1.36it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1162609
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1162609
 19%|█▊        | 159/859 [02:53<07:31,  1.55it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1162607
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1162607
 19%|█▊        | 160/859 [02:53<06:48,  1.71it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1069795
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1069795
 19%|█▊        | 161/859 [02:54<06:13,  1.87it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1544470
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1544470
 19%|█▉        | 162/859 [02:54<05:49,  1.99it/s]INFO:__main__:Requesting https://boards.greenhouse.io/omadahealth/jobs/1508368
INFO:__main__:Getting metadata for https://boards.greenhouse.io/omadahealth/jobs/1508368
 19%|█▉        | 163/859 [02:55<05:38,  2.06it/s]INFO:__main__:Requesting https://denimlabs.com/company/careers/
INFO:__main__:Getting metadata for https://denimlabs.com/company/careers/
 19%|█▉        | 164/859 [02:57<12:23,  1.07s/it]INFO:__main__:Requesting https://aula.education/
INFO:__main__:Getting metadata for https://aula.education
 19%|█▉        | 165/859 [02:58<12:27,  1.08s/it]INFO:__main__:Requesting http://bit.ly/FullstackEngineeratAula
INFO:__main__:Getting metadata for https://www.notion.so/aulaeducation/Remote-Senior-Full-stack-JavaScript-Engineer-React-Node-js-Aula-46e2f5d700a44f99ac7f65177e506a4b
 19%|█▉        | 166/859 [02:59<09:56,  1.16it/s]INFO:__main__:Requesting http://bit.ly/DevOpsatAula
INFO:__main__:Getting metadata for https://www.notion.so/aulaeducation/Remote-DevOps-Automation-Engineer-Node-js-Terraform-Docker-Aula-8e7c97af8f934044987f226f2c9048fb
 19%|█▉        | 167/859 [02:59<08:31,  1.35it/s]INFO:__main__:Requesting http://bit.ly/AulaAsyncHiring
INFO:__main__:Getting metadata for https://www.notion.so/aulaeducation/Async-engineering-interviews-at-Aula-bce436a4230c4f0d8b19bc717232d289
 20%|█▉        | 168/859 [03:00<07:41,  1.50it/s]INFO:__main__:Requesting http://bit.ly/AulaTechStack
INFO:__main__:Getting metadata for https://blog.aula.education/bringing-educational-infrastructure-into-the-21st-century-the-stack-be66b1a743c0?gi=f2db42847dae
 20%|█▉        | 169/859 [03:02<12:48,  1.11s/it]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/designpicklecom/view/P_AAAAAAFAAILMte651AZyrP
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/designpicklecom/view/P_AAAAAAFAAILMte651AZyrP
 20%|█▉        | 170/859 [03:02<09:37,  1.19it/s]INFO:__main__:Requesting https://clearbrain.com
INFO:__main__:Getting metadata for https://clearbrain.com
 20%|█▉        | 171/859 [03:02<07:29,  1.53it/s]INFO:__main__:Requesting https://www.keyvalues.com/clearbrain
INFO:__main__:Getting metadata for https://www.keyvalues.com/clearbrain
 20%|██        | 172/859 [03:03<09:26,  1.21it/s]INFO:__main__:Requesting https://angel.co/clearbrain/jobs/177711-machine-learning-engineer
INFO:__main__:Requesting https://grnh.se/e5301f7f2
INFO:__main__:Getting metadata for https://boards.greenhouse.io/bitmex/jobs/4087164002?gh_src=e5301f7f2
 20%|██        | 174/859 [03:04<08:00,  1.43it/s]INFO:__main__:Requesting https://grnh.se/499fb4222
INFO:__main__:Getting metadata for https://boards.greenhouse.io/bitmex/jobs/4031256002?gh_src=499fb4222
 20%|██        | 175/859 [03:05<07:37,  1.49it/s]INFO:__main__:Requesting https://www.LetsEnvision.com/
INFO:__main__:Getting metadata for https://www.letsenvision.com
 20%|██        | 176/859 [03:05<06:46,  1.68it/s]INFO:__main__:Requesting https://www.shortform.io/
INFO:__main__:Getting metadata for https://www.shortform.io
ERROR:__main__:Could not get metadata for https://www.shortform.io
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 21%|██        | 177/859 [03:06<06:26,  1.77it/s]INFO:__main__:Requesting https://www.omnisci.com
INFO:__main__:Getting metadata for https://www.omnisci.com
 21%|██        | 178/859 [03:10<17:45,  1.56s/it]INFO:__main__:Requesting http://www.omnisci.com/demos/tweetmap
INFO:__main__:Getting metadata for https://www.omnisci.com/demos/tweetmap/
 21%|██        | 179/859 [03:11<16:05,  1.42s/it]INFO:__main__:Requesting https://www.omnisci.com/demos/ships
INFO:__main__:Getting metadata for https://www.omnisci.com/demos/ships/
ERROR:__main__:Could not get metadata for https://www.omnisci.com/demos/ships/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 21%|██        | 180/859 [03:12<17:15,  1.53s/it]INFO:__main__:Requesting https://www.omnisci.com/company/careers/
INFO:__main__:Getting metadata for https://www.omnisci.com/company/careers/
 21%|██        | 181/859 [03:16<24:15,  2.15s/it]INFO:__main__:Requesting http://www.metabase.com/
INFO:__main__:Getting metadata for https://www.metabase.com
 21%|██        | 182/859 [03:17<18:54,  1.68s/it]INFO:__main__:Requesting http://www.metabase.com/jobs
INFO:__main__:Getting metadata for https://www.metabase.com/jobs/
 21%|██▏       | 183/859 [03:17<14:19,  1.27s/it]INFO:__main__:Requesting https://www.cloverhealth.com/en/about-us/careers
INFO:__main__:Getting metadata for https://www.cloverhealth.com/en/about-us/careers
 21%|██▏       | 184/859 [03:18<13:18,  1.18s/it]INFO:__main__:Requesting https://technology.cloverhealth.com/
INFO:__main__:Getting metadata for https://technology.cloverhealth.com/?gi=c93b30daa59
 22%|██▏       | 185/859 [03:19<13:29,  1.20s/it]INFO:__main__:Requesting https://www.secfi.com/#gif-container
INFO:__main__:Getting metadata for https://www.secfi.com/#gif-container
 22%|██▏       | 186/859 [03:19<10:20,  1.08it/s]INFO:__main__:Requesting https://www.secfi.com/careers
INFO:__main__:Getting metadata for https://www.secfi.com/careers
 22%|██▏       | 187/859 [03:20<08:03,  1.39it/s]INFO:__main__:Requesting https://www.justwatch.com/us/talent
INFO:__main__:Getting metadata for https://www.justwatch.com/us/talent
ERROR:__main__:Could not get metadata for https://www.justwatch.com/us/talent
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 22%|██▏       | 188/859 [03:22<13:29,  1.21s/it]INFO:__main__:Requesting https://housinganywhere.workable.com/j/C33B03C0C6?viewed=true
INFO:__main__:Getting metadata for https://housinganywhere.workable.com/j/C33B03C0C6?viewed=true
 22%|██▏       | 189/859 [03:23<11:42,  1.05s/it]INFO:__main__:Requesting https://www.nexient.com/careers
INFO:__main__:Getting metadata for https://www.nexient.com/careers
ERROR:__main__:Could not get metadata for https://www.nexient.com/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 22%|██▏       | 190/859 [03:23<09:28,  1.18it/s]INFO:__main__:Requesting https://openbuildservice.org
INFO:__main__:Getting metadata for https://openbuildservice.org
 22%|██▏       | 191/859 [03:24<09:59,  1.11it/s]INFO:__main__:Requesting https://jobs.suse.com/job/nuremberg/full-stack-web-developer/3486/10399103
INFO:__main__:Getting metadata for https://jobs.suse.com/job/nuremberg/full-stack-web-developer/3486/10399103
 22%|██▏       | 192/859 [03:25<10:22,  1.07it/s]INFO:__main__:Requesting https://angel.co/airgrid/jobs
INFO:__main__:Requesting https://www.airgrid.io/
INFO:__main__:Getting metadata for https://www.airgrid.io
 23%|██▎       | 194/859 [03:26<08:09,  1.36it/s]INFO:__main__:Requesting https://zulipchat.com/
INFO:__main__:Getting metadata for https://zulipchat.com
 23%|██▎       | 195/859 [03:26<06:52,  1.61it/s]INFO:__main__:Requesting https://aws.amazon.com/professional-services/
INFO:__main__:Getting metadata for https://aws.amazon.com/professional-services/
ERROR:__main__:Could not get metadata for https://aws.amazon.com/professional-services/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 23%|██▎       | 196/859 [03:26<06:16,  1.76it/s]INFO:__main__:Requesting https://www.amazon.jobs/en/search?base_query=professional+services
INFO:__main__:Getting metadata for https://www.amazon.jobs/en/search?base_query=professional+services
 23%|██▎       | 197/859 [03:27<06:59,  1.58it/s]INFO:__main__:Requesting https://www.replicated.com
INFO:__main__:Getting metadata for https://www.replicated.com
 23%|██▎       | 198/859 [03:28<09:03,  1.22it/s]INFO:__main__:Requesting https://leantaas.com/about/careers/
INFO:__main__:Getting metadata for https://leantaas.com/about/careers/
 23%|██▎       | 199/859 [03:29<07:10,  1.53it/s]INFO:__main__:Requesting https://popdog.com
INFO:__main__:Getting metadata for https://popdog.com
 23%|██▎       | 200/859 [03:29<05:51,  1.88it/s]INFO:__main__:Requesting https://loaded.gg/
INFO:__main__:Getting metadata for https://loaded.gg
 23%|██▎       | 201/859 [03:29<05:36,  1.95it/s]INFO:__main__:Requesting https://jobs.lever.co/popdog/0c6443a2-09c5-4a27-a536-2270037..
 24%|██▎       | 202/859 [03:30<04:56,  2.22it/s]INFO:__main__:Requesting https://jobs.lever.co/popdog/3377b4f4-2b54-4a78-a9ad-1a40ed0..
 24%|██▎       | 203/859 [03:30<04:23,  2.49it/s]INFO:__main__:Requesting https://jobs.lever.co/popdog
INFO:__main__:Getting metadata for https://jobs.lever.co/popdog
 24%|██▎       | 204/859 [03:31<05:32,  1.97it/s]INFO:__main__:Requesting http://www.energyhub.com
INFO:__main__:Getting metadata for https://www.energyhub.com
ERROR:__main__:Could not get metadata for https://www.energyhub.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 24%|██▍       | 205/859 [03:31<05:22,  2.03it/s]INFO:__main__:Requesting https://grnh.se/8c8235d82
INFO:__main__:Getting metadata for https://www.energyhub.com/careers?gh_src=8c8235d82
 24%|██▍       | 206/859 [03:32<05:38,  1.93it/s]INFO:__main__:Requesting https://www.givecampus.com/careers
 24%|██▍       | 207/859 [03:32<04:25,  2.46it/s]INFO:__main__:Requesting https://www.washingtonpost.com/news/grade-point/wp/2016/04/19/colleges-are-going-online-to-crowdsource-donations-and-theyre-raising-millions
ERROR:__main__:Could not reach https://www.washingtonpost.com/news/grade-point/wp/2016/04/19/colleges-are-going-online-to-crowdsource-donations-and-theyre-raising-millions
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)
 24%|██▍       | 208/859 [03:38<22:54,  2.11s/it]INFO:__main__:Requesting https://thegrommet.com
INFO:__main__:Getting metadata for https://www.thegrommet.com
 24%|██▍       | 209/859 [03:39<18:36,  1.72s/it]INFO:__main__:Requesting https://thegrommet.com/careers
INFO:__main__:Getting metadata for https://grommet.applytojob.com
 24%|██▍       | 210/859 [03:41<19:07,  1.77s/it]INFO:__main__:Requesting https://loaneco.net/
INFO:__main__:Getting metadata for https://loaneco.net
 25%|██▍       | 211/859 [03:42<17:18,  1.60s/it]INFO:__main__:Requesting https://angel.co/l/28JSu2
INFO:__main__:Requesting http://bit.ly/gghackernews
INFO:__main__:Getting metadata for https://glossgenius.recruitee.com/o/senior-growth-engineer?source=hackernews
 25%|██▍       | 213/859 [03:43<12:55,  1.20s/it]INFO:__main__:Requesting https://www.veezoo.com
INFO:__main__:Getting metadata for https://www.veezoo.com
 25%|██▍       | 214/859 [03:45<15:34,  1.45s/it]INFO:__main__:Requesting https://stitchlabs.bamboohr.com/jobs/view.php?id=28
INFO:__main__:Getting metadata for https://stitchlabs.bamboohr.com/jobs/view.php?id=28
 25%|██▌       | 215/859 [03:45<13:03,  1.22s/it]INFO:__main__:Requesting https://circleup.com
INFO:__main__:Getting metadata for https://circleup.com
ERROR:__main__:Could not get metadata for https://circleup.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 25%|██▌       | 216/859 [03:47<14:10,  1.32s/it]INFO:__main__:Requesting https://medium.com/@ryancaldbeck/announcing-the-launch-of-he...
 25%|██▌       | 217/859 [03:47<10:25,  1.03it/s]INFO:__main__:Requesting https://circleup.com/jobs/
INFO:__main__:Getting metadata for https://circleup.com/jobs/
ERROR:__main__:Could not get metadata for https://circleup.com/jobs/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 25%|██▌       | 218/859 [03:49<12:51,  1.20s/it]INFO:__main__:Requesting https://www.tatari.tv
INFO:__main__:Getting metadata for https://www.tatari.tv
 25%|██▌       | 219/859 [03:50<11:58,  1.12s/it]INFO:__main__:Requesting https://www.tatari.tv/careers
INFO:__main__:Getting metadata for https://www.tatari.tv/careers
 26%|██▌       | 220/859 [03:52<16:15,  1.53s/it]INFO:__main__:Requesting http://learn.realscout.com/about
INFO:__main__:Getting metadata for http://learn.realscout.com/about/
 26%|██▌       | 221/859 [03:52<12:22,  1.16s/it]INFO:__main__:Requesting https://nycbuyergraph.com/
INFO:__main__:Getting metadata for https://nycbuyergraph.com
 26%|██▌       | 222/859 [03:53<11:21,  1.07s/it]INFO:__main__:Requesting https://sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=25632&siteid=5649&Areq=672673BR&CODES=US_INT_INDEED_PD#jobDetails=2811103_5649
INFO:__main__:Getting metadata for https://sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=25632&siteid=5649&Areq=672673BR&CODES=US_INT_INDEED_PD#jobDetails=2811103_5649
ERROR:__main__:Could not get metadata for https://sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=25632&siteid=5649&Areq=672673BR&CODES=US_INT_INDEED_PD#jobDetails=2811103_5649
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 26%|██▌       | 223/859 [03:55<12:37,  1.19s/it]INFO:__main__:Requesting https://tcrn.ch/2G8eniG
ERROR:__main__:Could not reach https://tcrn.ch/2G8eniG
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 247, in resolve_redirects
    **adapter_kwargs
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 26%|██▌       | 224/859 [03:55<10:34,  1.00it/s]INFO:__main__:Requesting http://onspecta.com/careers.html
INFO:__main__:Getting metadata for http://onspecta.com/careers.html
 26%|██▌       | 225/859 [03:56<09:24,  1.12it/s]INFO:__main__:Requesting https://launchdarkly.com/careers/
INFO:__main__:Getting metadata for https://launchdarkly.com/careers/
 26%|██▋       | 226/859 [03:56<08:23,  1.26it/s]INFO:__main__:Requesting https://cooklist.co
INFO:__main__:Getting metadata for https://www.cooklist.co
ERROR:__main__:Could not get metadata for https://www.cooklist.co
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 26%|██▋       | 227/859 [03:57<08:13,  1.28it/s]INFO:__main__:Requesting https://angel.co/l/2eubtM
INFO:__main__:Requesting https://jobs.lever.co/starskyrobotics/
INFO:__main__:Getting metadata for https://jobs.lever.co/starskyrobotics/
 27%|██▋       | 229/859 [03:58<06:50,  1.54it/s]INFO:__main__:Requesting https://www.lumiata.com/careers.html
INFO:__main__:Getting metadata for https://www.lumiata.com/careers.html
 27%|██▋       | 230/859 [03:59<06:40,  1.57it/s]INFO:__main__:Requesting https://www.sanity.io/blog/hiring-sre
INFO:__main__:Getting metadata for https://www.sanity.io/blog/hiring-sre
 27%|██▋       | 231/859 [03:59<06:13,  1.68it/s]INFO:__main__:Requesting https://ecometrica.com/about-us/careers/python-developer/
INFO:__main__:Getting metadata for https://ecometrica.com/about-us/careers/python-developer
ERROR:__main__:Could not get metadata for https://ecometrica.com/about-us/careers/python-developer
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 27%|██▋       | 232/859 [04:01<10:15,  1.02it/s]INFO:__main__:Requesting https://ecometrica.com/about-us/careers/python-developer
INFO:__main__:Getting metadata for https://ecometrica.com/about-us/careers/python-developer
ERROR:__main__:Could not get metadata for https://ecometrica.com/about-us/careers/python-developer
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 27%|██▋       | 233/859 [04:02<11:41,  1.12s/it]INFO:__main__:Requesting https://www.bosch.com/internet-of-things/connected-mobility/
INFO:__main__:Getting metadata for https://www.bosch.com/internet-of-things/connected-mobility/
 27%|██▋       | 234/859 [04:04<12:25,  1.19s/it]INFO:__main__:Requesting http://certsafe.com/
INFO:__main__:Getting metadata for http://www.certsafe.com
 27%|██▋       | 235/859 [04:05<12:18,  1.18s/it]INFO:__main__:Requesting http://certsafe.com/careers/
INFO:__main__:Getting metadata for http://www.certsafe.com/careers/
 27%|██▋       | 236/859 [04:06<11:43,  1.13s/it]INFO:__main__:Requesting https://azure.microsoft.com/en-us/services/kubernetes-service/
INFO:__main__:Getting metadata for https://azure.microsoft.com/en-us/services/kubernetes-service/
 28%|██▊       | 237/859 [04:07<13:06,  1.27s/it]INFO:__main__:Requesting https://industryuseng-ms.icims.com/jobs/590353/senior-software-engineer/job?mode=view
INFO:__main__:Getting metadata for https://industryuseng-ms.icims.com/jobs/590353/senior-software-engineer/job?mode=view
 28%|██▊       | 238/859 [04:08<10:30,  1.02s/it]INFO:__main__:Requesting https://industryuseng-ms.icims.com/jobs/590350/software-engineer/job?mode=view
INFO:__main__:Getting metadata for https://industryuseng-ms.icims.com/jobs/590350/software-engineer/job?mode=view
 28%|██▊       | 239/859 [04:08<08:42,  1.19it/s]INFO:__main__:Requesting https://www.bluecatnetworks.com/careers/
INFO:__main__:Getting metadata for https://www.bluecatnetworks.com/careers/
 28%|██▊       | 240/859 [04:09<07:06,  1.45it/s]INFO:__main__:Requesting https://codelitt-incubator.workable.com/
INFO:__main__:Getting metadata for https://codelitt-incubator.workable.com
ERROR:__main__:Could not get metadata for https://codelitt-incubator.workable.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 28%|██▊       | 241/859 [04:09<07:01,  1.46it/s]INFO:__main__:Requesting https://www.accurx.com/careers
INFO:__main__:Getting metadata for https://www.accurx.com/careers
ERROR:__main__:Could not get metadata for https://www.accurx.com/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 28%|██▊       | 242/859 [04:13<16:29,  1.60s/it]INFO:__main__:Requesting https://techcrunch.com/2019/02/24/accurx/
ERROR:__main__:Could not reach https://techcrunch.com/2019/02/24/accurx/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 28%|██▊       | 243/859 [04:13<11:53,  1.16s/it]INFO:__main__:Requesting https://vsecurity.com/company/employment.html
INFO:__main__:Getting metadata for https://vsecurity.com/company/employment.html
 28%|██▊       | 244/859 [04:14<11:20,  1.11s/it]INFO:__main__:Requesting https://www.visuallabsinc.com/
INFO:__main__:Getting metadata for https://www.visuallabsinc.com
 29%|██▊       | 245/859 [04:17<15:19,  1.50s/it]INFO:__main__:Requesting https://youtu.be/WxHIrdqt9Rg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=WxHIrdqt9Rg&feature=youtu.be
 29%|██▊       | 246/859 [04:17<13:17,  1.30s/it]INFO:__main__:Requesting https://fetchrev.bamboohr.com/jobs/view.php?id=24
INFO:__main__:Getting metadata for https://fetchrev.bamboohr.com/jobs/view.php?id=24
 29%|██▉       | 247/859 [04:18<11:51,  1.16s/it]INFO:__main__:Requesting https://predata.com/
INFO:__main__:Getting metadata for https://predata.com
 29%|██▉       | 248/859 [04:20<12:01,  1.18s/it]INFO:__main__:Requesting https://angel.co/predata/jobs/
INFO:__main__:Requesting https://grnh.se/b048c8491
INFO:__main__:Getting metadata for https://boards.greenhouse.io/peek/jobs/1526308?gh_src=b048c8491
 29%|██▉       | 250/859 [04:22<11:51,  1.17s/it]INFO:__main__:Requesting https://grnh.se/bc186d791
INFO:__main__:Getting metadata for https://boards.greenhouse.io/peek/jobs/1430301?gh_src=bc186d791
 29%|██▉       | 251/859 [04:24<15:02,  1.48s/it]INFO:__main__:Requesting https://grnh.se/5cb706351
INFO:__main__:Getting metadata for https://boards.greenhouse.io/peek/jobs/1452573?gh_src=5cb706351
 29%|██▉       | 252/859 [04:26<15:41,  1.55s/it]INFO:__main__:Requesting https://grnh.se/25c80e8b1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/peek/jobs/1526179?gh_src=25c80e8b1
 29%|██▉       | 253/859 [04:27<14:41,  1.45s/it]INFO:__main__:Requesting https://stackshare.io/peek/peek-stack
INFO:__main__:Getting metadata for https://stackshare.io/peek/peek-stack
 30%|██▉       | 254/859 [04:30<19:58,  1.98s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=nYcBqtOwLcg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=nYcBqtOwLcg
 30%|██▉       | 255/859 [04:31<16:47,  1.67s/it]INFO:__main__:Requesting https://www.polarsteps.com/teleporter
INFO:__main__:Getting metadata for https://www.polarsteps.com/teleporter
 30%|██▉       | 256/859 [04:32<13:06,  1.30s/it]INFO:__main__:Requesting https://careers.polarsteps.com/#vacancies
INFO:__main__:Getting metadata for https://careers.polarsteps.com/#vacancies
 30%|██▉       | 257/859 [04:33<12:59,  1.30s/it]INFO:__main__:Requesting https://braincorporation.applytojob.com/apply/
INFO:__main__:Getting metadata for https://braincorporation.applytojob.com/apply/
 30%|███       | 258/859 [04:34<13:06,  1.31s/it]INFO:__main__:Requesting https://www.linkedin.com/in/rawsonleavitt/
 30%|███       | 259/859 [04:34<09:47,  1.02it/s]INFO:__main__:Requesting http://gambitresearch.com
INFO:__main__:Getting metadata for https://www.gambitresearch.com
 30%|███       | 260/859 [04:39<21:07,  2.12s/it]INFO:__main__:Requesting https://www.gambitresearch.com/quiz/
INFO:__main__:Getting metadata for https://www.gambitresearch.com/quiz/
ERROR:__main__:Could not get metadata for https://www.gambitresearch.com/quiz/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 30%|███       | 261/859 [04:41<21:44,  2.18s/it]INFO:__main__:Requesting https://altusassessments.com/
INFO:__main__:Getting metadata for https://altusassessments.com
 31%|███       | 262/859 [04:42<16:31,  1.66s/it]INFO:__main__:Requesting https://angel.co/firststepcoding/jobs/478698-growth-marketing-manager
INFO:__main__:Requesting https://kiprotect.com
INFO:__main__:Getting metadata for https://kiprotect.com
 31%|███       | 264/859 [04:44<14:27,  1.46s/it]INFO:__main__:Requesting http://developer.paypal.com
INFO:__main__:Getting metadata for https://developer.paypal.com
 31%|███       | 265/859 [04:46<15:51,  1.60s/it]INFO:__main__:Requesting https://sourcegraph.com
INFO:__main__:Getting metadata for https://sourcegraph.com/welcome
ERROR:__main__:Could not get metadata for https://sourcegraph.com/welcome
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 31%|███       | 266/859 [04:46<12:29,  1.26s/it]INFO:__main__:Requesting https://github.com/sourcegraph/careers/
INFO:__main__:Getting metadata for https://github.com/sourcegraph/careers/
 31%|███       | 267/859 [04:47<11:40,  1.18s/it]INFO:__main__:Requesting https://sourcegraph.com/plan
INFO:__main__:Getting metadata for https://about.sourcegraph.com/plan/
 31%|███       | 268/859 [04:48<10:50,  1.10s/it]INFO:__main__:Requesting https://github.com/sourcegraph/sourcegraph
INFO:__main__:Getting metadata for https://github.com/sourcegraph/sourcegraph
 31%|███▏      | 269/859 [04:50<11:38,  1.18s/it]INFO:__main__:Requesting https://docs.sourcegraph.com/dev/roadmap
INFO:__main__:Getting metadata for https://docs.sourcegraph.com/dev/roadmap
 31%|███▏      | 270/859 [04:50<10:36,  1.08s/it]INFO:__main__:Requesting http://belvederetrading.applicantstack.com/x/detail/a2sa4x0b2oek
INFO:__main__:Getting metadata for http://belvederetrading.applicantstack.com/x/detail/a2sa4x0b2oek
 32%|███▏      | 271/859 [04:52<12:33,  1.28s/it]INFO:__main__:Requesting http://www.belvederetrading.com/careers/
INFO:__main__:Getting metadata for http://www.belvederetrading.com/careers/
ERROR:__main__:Could not get metadata for http://www.belvederetrading.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 32%|███▏      | 272/859 [04:53<11:06,  1.14s/it]INFO:__main__:Requesting https://amperity.com/careers/
INFO:__main__:Getting metadata for https://amperity.com/careers/
 32%|███▏      | 273/859 [04:53<09:00,  1.08it/s]INFO:__main__:Requesting https://www.quotapath.com/careers/
INFO:__main__:Getting metadata for https://www.quotapath.com/careers/
ERROR:__main__:Could not get metadata for https://www.quotapath.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 32%|███▏      | 274/859 [04:54<07:43,  1.26it/s]INFO:__main__:Requesting https://matterapp.com
INFO:__main__:Getting metadata for https://matterapp.com
 32%|███▏      | 275/859 [04:55<07:33,  1.29it/s]INFO:__main__:Requesting https://slackatwork.com/job/matter-san-francisco-california-2-full-stack-engineer-react-graphql-typescript/
INFO:__main__:Getting metadata for https://slackatwork.com/job/matter-san-francisco-california-2-full-stack-engineer-react-graphql-typescript/
 32%|███▏      | 276/859 [04:56<08:35,  1.13it/s]INFO:__main__:Requesting https://blueprintpower.com
INFO:__main__:Getting metadata for https://www.blueprintpower.com
 32%|███▏      | 277/859 [04:57<09:44,  1.00s/it]INFO:__main__:Requesting https://www.betterup.co/
INFO:__main__:Getting metadata for https://www.betterup.co
 32%|███▏      | 278/859 [04:57<08:06,  1.19it/s]INFO:__main__:Requesting https://boards.greenhouse.io/betterup/jobs/935618
INFO:__main__:Getting metadata for https://boards.greenhouse.io/betterup/jobs/935618
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/betterup/jobs/935618
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 32%|███▏      | 279/859 [04:58<06:55,  1.39it/s]INFO:__main__:Requesting https://madisonwall.bamboohr.com/jobs/view.php?id=38
INFO:__main__:Getting metadata for https://madisonwall.bamboohr.com/jobs/view.php?id=38
 33%|███▎      | 280/859 [04:59<06:56,  1.39it/s]INFO:__main__:Requesting https://search.firstround.com/
INFO:__main__:Getting metadata for https://search.firstround.com
 33%|███▎      | 281/859 [04:59<05:58,  1.61it/s]INFO:__main__:Requesting https://careers.firstround.com/welcome/firstround
INFO:__main__:Getting metadata for https://careers.firstround.com/welcome/firstround
ERROR:__main__:Could not get metadata for https://careers.firstround.com/welcome/firstround
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 282/859 [05:01<08:54,  1.08it/s]INFO:__main__:Requesting https://medium.com/@firstround/were-hiring-for-our-software-engineering-team-bd844ecd42cf
INFO:__main__:Getting metadata for https://medium.com/@firstround/were-hiring-for-our-software-engineering-team-bd844ecd42cf
 33%|███▎      | 283/859 [05:01<07:36,  1.26it/s]INFO:__main__:Requesting https://venturebeat.com/2018/12/17/datacamp-raises-25-million-for-customizable-online-data-science-courses/
INFO:__main__:Getting metadata for https://venturebeat.com/2018/12/17/datacamp-raises-25-million-for-customizable-online-data-science-courses/
 33%|███▎      | 284/859 [05:03<09:24,  1.02it/s]INFO:__main__:Requesting https://bit.ly/2SUnuae
INFO:__main__:Getting metadata for https://boards.greenhouse.io/datacamp/jobs/1482036
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/datacamp/jobs/1482036
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 33%|███▎      | 285/859 [05:04<11:52,  1.24s/it]INFO:__main__:Requesting https://www.datacamp.com/jobs
INFO:__main__:Getting metadata for https://www.datacamp.com/jobs
ERROR:__main__:Could not get metadata for https://www.datacamp.com/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 33%|███▎      | 286/859 [05:06<13:31,  1.42s/it]INFO:__main__:Requesting https://www.rinse.com/careers/senior-software-engineer/
INFO:__main__:Getting metadata for https://www.rinse.com/careers/senior-software-engineer/
 33%|███▎      | 287/859 [05:07<11:21,  1.19s/it]INFO:__main__:Requesting https://www.rinse.com/careers/software-engineer/
INFO:__main__:Getting metadata for https://www.rinse.com/careers/software-engineer/
 34%|███▎      | 288/859 [05:08<09:42,  1.02s/it]INFO:__main__:Requesting https://www.rinse.com/careers/
INFO:__main__:Getting metadata for https://www.rinse.com/careers/
 34%|███▎      | 289/859 [05:08<08:38,  1.10it/s]INFO:__main__:Requesting https://www.level12.io/careers/
INFO:__main__:Getting metadata for https://www.level12.io/careers/
 34%|███▍      | 290/859 [05:09<07:06,  1.34it/s]INFO:__main__:Requesting https://www.zenysis.com/#careers
INFO:__main__:Getting metadata for https://www.zenysis.com/#careers
 34%|███▍      | 291/859 [05:09<05:42,  1.66it/s]INFO:__main__:Requesting https://goo.gl/UuZ3T3
INFO:__main__:Getting metadata for https://www.kyruus.com/careers?gnk=job&gni=8a78839f661391f5016631ae50016229&gns=WWC
 34%|███▍      | 292/859 [05:09<05:47,  1.63it/s]INFO:__main__:Requesting https://www.kyruus.com/about
INFO:__main__:Getting metadata for https://www.kyruus.com/about
 34%|███▍      | 293/859 [05:10<05:19,  1.77it/s]INFO:__main__:Requesting https://www.kyruus.com/careers
INFO:__main__:Getting metadata for https://www.kyruus.com/careers
 34%|███▍      | 294/859 [05:10<04:34,  2.06it/s]INFO:__main__:Requesting https://redislabs.com/company/careers/
INFO:__main__:Getting metadata for https://redislabs.com/company/careers/
 34%|███▍      | 295/859 [05:11<06:15,  1.50it/s]INFO:__main__:Requesting https://university.redislabs.com
INFO:__main__:Getting metadata for https://university.redislabs.com
 34%|███▍      | 296/859 [05:13<07:55,  1.18it/s]INFO:__main__:Requesting https://redislabs.com/careers/product-manager-security/
INFO:__main__:Getting metadata for https://redislabs.com/careers/product-manager-security/
 35%|███▍      | 297/859 [05:14<08:19,  1.12it/s]INFO:__main__:Requesting https://redislabs.com/careers/team-lead/
INFO:__main__:Getting metadata for https://redislabs.com/careers/team-lead/
 35%|███▍      | 298/859 [05:14<08:24,  1.11it/s]INFO:__main__:Requesting https://getcruise.com/careers
INFO:__main__:Getting metadata for https://getcruise.com/careers
 35%|███▍      | 299/859 [05:15<07:42,  1.21it/s]INFO:__main__:Requesting https://jobs.lever.co/kraken
INFO:__main__:Getting metadata for https://jobs.lever.co/kraken
 35%|███▍      | 300/859 [05:16<07:21,  1.27it/s]INFO:__main__:Requesting https://www.haproxy.com/privacy-policy/
INFO:__main__:Getting metadata for https://www.haproxy.com/privacy-policy/
ERROR:__main__:Could not get metadata for https://www.haproxy.com/privacy-policy/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 35%|███▌      | 301/859 [05:16<06:39,  1.40it/s]INFO:__main__:Requesting http://appliedinformaticsinc.com/
INFO:__main__:Getting metadata for https://appliedinformaticsinc.com
 35%|███▌      | 302/859 [05:18<09:14,  1.01it/s]INFO:__main__:Requesting https://tulip.co/careers
INFO:__main__:Getting metadata for https://tulip.co/careers/
 35%|███▌      | 303/859 [05:18<07:25,  1.25it/s]INFO:__main__:Requesting https://careers.ef.com/job/ohdM8fw8/
INFO:__main__:Getting metadata for https://careers.ef.com/job/ohdM8fw8/
 35%|███▌      | 304/859 [05:20<09:15,  1.00s/it]INFO:__main__:Requesting http://class.ef.com/
INFO:__main__:Getting metadata for http://class.ef.com
 36%|███▌      | 305/859 [05:20<07:54,  1.17it/s]INFO:__main__:Requesting https://occipital.com
INFO:__main__:Getting metadata for https://occipital.com
 36%|███▌      | 306/859 [05:21<07:09,  1.29it/s]INFO:__main__:Requesting https://occipital.com/jobs
INFO:__main__:Getting metadata for https://occipital.com/jobs
 36%|███▌      | 307/859 [05:22<07:19,  1.26it/s]INFO:__main__:Requesting http://www.icontracts.com/policy-management
INFO:__main__:Getting metadata for https://www.icontracts.com/policy-management/
 36%|███▌      | 308/859 [05:23<08:24,  1.09it/s]INFO:__main__:Requesting http://bit.ly/pstat-jobs-2019-github
INFO:__main__:Getting metadata for https://github.com/PolicyStat/jobs
 36%|███▌      | 309/859 [05:24<08:12,  1.12it/s]INFO:__main__:Requesting http://bit.ly/pstat-jobs-react-2019
INFO:__main__:Getting metadata for https://github.com/PolicyStat/jobs/blob/master/front_end_react_engineer.md
 36%|███▌      | 310/859 [05:25<09:46,  1.07s/it]INFO:__main__:Requesting http://bit.ly/pstat-jobs-python-django-2019
INFO:__main__:Getting metadata for https://github.com/PolicyStat/jobs/blob/master/python_django_engineer.md
 36%|███▌      | 311/859 [05:26<10:00,  1.10s/it]INFO:__main__:Requesting http://bit.ly/pstat-jobs-java-grails-2019
INFO:__main__:Getting metadata for https://github.com/PolicyStat/jobs/blob/master/java_grails_engineer.md
 36%|███▋      | 312/859 [05:27<09:41,  1.06s/it]INFO:__main__:Requesting https://steady.health
INFO:__main__:Getting metadata for https://steady.health
 36%|███▋      | 313/859 [05:28<08:39,  1.05it/s]INFO:__main__:Requesting https://medium.com/south-park-commons/the-wearable-that-changed-my-life-1a5b9bdbab22
INFO:__main__:Getting metadata for https://medium.com/south-park-commons/the-wearable-that-changed-my-life-1a5b9bdbab22
 37%|███▋      | 314/859 [05:29<07:39,  1.19it/s]INFO:__main__:Requesting https://www.uncountable.com/careers
INFO:__main__:Getting metadata for https://www.uncountable.com/careers
ERROR:__main__:Could not get metadata for https://www.uncountable.com/careers
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 37%|███▋      | 315/859 [05:29<07:06,  1.28it/s]INFO:__main__:Requesting https://hire.withgoogle.com/public/jobs/handybookcom/view/P_AAAAAADAAADNLu-DW6w0so
INFO:__main__:Getting metadata for https://hire.withgoogle.com/public/jobs/handybookcom/view/P_AAAAAADAAADNLu-DW6w0so
 37%|███▋      | 316/859 [05:30<05:51,  1.54it/s]INFO:__main__:Requesting https://www.geckorobotics.com/
INFO:__main__:Getting metadata for https://www.geckorobotics.com
 37%|███▋      | 317/859 [05:30<05:00,  1.81it/s]INFO:__main__:Requesting https://www.geckorobotics.com/company/careers
INFO:__main__:Getting metadata for https://www.geckorobotics.com/company/careers
 37%|███▋      | 318/859 [05:31<04:48,  1.87it/s]INFO:__main__:Requesting https://www.counterpointconsulting.com/careers
INFO:__main__:Getting metadata for https://www.counterpointconsulting.com/careers
 37%|███▋      | 319/859 [05:31<04:49,  1.86it/s]INFO:__main__:Requesting https://www.counterpointconsulting.com/life-at-counterpoint
INFO:__main__:Getting metadata for https://www.counterpointconsulting.com/life-at-counterpoint
 37%|███▋      | 320/859 [05:32<04:32,  1.98it/s]INFO:__main__:Requesting https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=a6543b20-78f9-4c3b-9272-2ce9ade7de8e&ccId=19000101_000001&type=MP&lang=en_US
INFO:__main__:Getting metadata for https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=a6543b20-78f9-4c3b-9272-2ce9ade7de8e&ccId=19000101_000001&type=MP&lang=en_US
ERROR:__main__:Could not get metadata for https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=a6543b20-78f9-4c3b-9272-2ce9ade7de8e&ccId=19000101_000001&type=MP&lang=en_US
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 37%|███▋      | 321/859 [05:32<05:20,  1.68it/s]INFO:__main__:Requesting https://degreed.com
INFO:__main__:Getting metadata for https://degreed.com
 37%|███▋      | 322/859 [05:33<04:51,  1.84it/s]INFO:__main__:Requesting https://jobs.lever.co/degreed
INFO:__main__:Getting metadata for https://jobs.lever.co/degreed
 38%|███▊      | 323/859 [05:33<05:03,  1.76it/s]INFO:__main__:Requesting https://jobs.apple.com/us/search?job=113644011&openJobId=113644011#&ss=%22SEAR%20-%22&t=0&so=&pN=0
INFO:__main__:Getting metadata for https://jobs.apple.com/en-us/search?job=113644011&openJobId=113644011#&ss=%22SEAR%20-%22&t=0&so=&pN=0
 38%|███▊      | 324/859 [05:35<08:47,  1.01it/s]INFO:__main__:Requesting https://smarkets.com/careers
INFO:__main__:Getting metadata for https://smarkets.com/careers/
ERROR:__main__:Could not get metadata for https://smarkets.com/careers/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 38%|███▊      | 325/859 [05:37<10:13,  1.15s/it]INFO:__main__:Requesting https://atomicobject.com/careers/senior-software-developer-job
INFO:__main__:Getting metadata for https://atomicobject.com/careers/senior-software-developer-job
 38%|███▊      | 326/859 [05:38<09:52,  1.11s/it]INFO:__main__:Requesting https://www.artory.com/
INFO:__main__:Getting metadata for https://www.artory.com
 38%|███▊      | 327/859 [05:38<08:20,  1.06it/s]INFO:__main__:Requesting https://www.artory.com/careers/
INFO:__main__:Getting metadata for https://www.artory.com/careers/
 38%|███▊      | 328/859 [05:39<07:56,  1.12it/s]INFO:__main__:Requesting https://www.codeweavers.com/about/jobs
INFO:__main__:Getting metadata for https://www.codeweavers.com/about/jobs
 38%|███▊      | 329/859 [05:40<08:13,  1.07it/s]INFO:__main__:Requesting https://www.sumologic.com
INFO:__main__:Getting metadata for https://www.sumologic.com
 38%|███▊      | 330/859 [05:40<06:21,  1.39it/s]INFO:__main__:Requesting https://boards.greenhouse.io/sumologic/jobs/1080682
INFO:__main__:Getting metadata for https://boards.greenhouse.io/sumologic/jobs/1080682
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/sumologic/jobs/1080682
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 39%|███▊      | 331/859 [05:41<05:30,  1.60it/s]INFO:__main__:Requesting https://boards.greenhouse.io/sumologic/jobs/1252374
INFO:__main__:Getting metadata for https://boards.greenhouse.io/sumologic/jobs/1252374
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/sumologic/jobs/1252374
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 39%|███▊      | 332/859 [05:41<04:50,  1.82it/s]INFO:__main__:Requesting https://boards.greenhouse.io/sumologic/jobs/1284018
INFO:__main__:Getting metadata for https://boards.greenhouse.io/sumologic/jobs/1284018
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/sumologic/jobs/1284018
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 39%|███▉      | 333/859 [05:42<04:34,  1.91it/s]INFO:__main__:Requesting https://grnh.se/dd40b1ab1
INFO:__main__:Getting metadata for https://learningequality.org/about/jobs/?gh_jid=1441505&gh_src=dd40b1ab1
 39%|███▉      | 334/859 [05:43<05:51,  1.49it/s]INFO:__main__:Requesting https://learningequality.org/ka-lite/map/
ERROR:__main__:Could not reach https://learningequality.org/ka-lite/map/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='learningequality.org', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='learningequality.org', port=443): Read timed out. (read timeout=6)
 39%|███▉      | 335/859 [05:49<20:01,  2.29s/it]INFO:__main__:Requesting https://github.com/learningequality/kolibri
INFO:__main__:Getting metadata for https://github.com/learningequality/kolibri
 39%|███▉      | 336/859 [05:50<17:55,  2.06s/it]INFO:__main__:Requesting https://www.patientsknowbest.com/careers.html
INFO:__main__:Getting metadata for https://www.patientsknowbest.com/careers.html
 39%|███▉      | 337/859 [05:51<14:42,  1.69s/it]INFO:__main__:Requesting https://www.tundra.com
INFO:__main__:Getting metadata for https://www.tundra.com
 39%|███▉      | 338/859 [05:52<12:46,  1.47s/it]INFO:__main__:Requesting https://www.angel.co/tundra
INFO:__main__:Requesting http://mixlr.com/
INFO:__main__:Getting metadata for http://mixlr.com
 40%|███▉      | 340/859 [05:53<09:39,  1.12s/it]INFO:__main__:Requesting https://mixlr.workable.com/jobs/923302
INFO:__main__:Getting metadata for https://mixlr.workable.com/jobs/923302
 40%|███▉      | 341/859 [05:53<08:29,  1.02it/s]INFO:__main__:Requesting https://jobs.netflix.com/jobs/866321
INFO:__main__:Getting metadata for https://jobs.netflix.com/jobs/866321
 40%|███▉      | 342/859 [05:54<08:08,  1.06it/s]INFO:__main__:Requesting https://www.reforge.com
INFO:__main__:Getting metadata for https://www.reforge.com
 40%|███▉      | 343/859 [05:55<07:05,  1.21it/s]INFO:__main__:Requesting https://www.instructure.com/about/careers
INFO:__main__:Getting metadata for https://www.instructure.com/about/careers
 40%|████      | 344/859 [05:56<07:10,  1.20it/s]INFO:__main__:Requesting https://getbyrd.com
INFO:__main__:Getting metadata for https://getbyrd.com
 40%|████      | 345/859 [05:57<09:03,  1.06s/it]INFO:__main__:Requesting https://getbyrd.com/en/jobs/
INFO:__main__:Getting metadata for https://getbyrd.com/en/jobs/
ERROR:__main__:Could not get metadata for https://getbyrd.com/en/jobs/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 40%|████      | 346/859 [05:59<10:00,  1.17s/it]INFO:__main__:Requesting https://jobs.disneycareers.com/search-jobs
INFO:__main__:Getting metadata for https://jobs.disneycareers.com/search-jobs
 40%|████      | 347/859 [06:00<11:38,  1.36s/it]INFO:__main__:Requesting https://jobs.lever.co/plangrid?lever-via=SzsN-_Jgq1
INFO:__main__:Getting metadata for https://jobs.lever.co/plangrid?lever-via=SzsN-_Jgq1
 41%|████      | 348/859 [06:01<10:16,  1.21s/it]INFO:__main__:Requesting https://medium.com/plangrid-technology/working-on-the-plangrid-ios-team-1d1757c76be9
INFO:__main__:Getting metadata for https://medium.com/plangrid-technology/working-on-the-plangrid-ios-team-1d1757c76be9
 41%|████      | 349/859 [06:02<08:32,  1.00s/it]INFO:__main__:Requesting https://grnh.se/6d73e4a71
INFO:__main__:Getting metadata for https://newsela.com/company/jobs/?gh_src=6d73e4a71
 41%|████      | 350/859 [06:03<08:49,  1.04s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=MBqquBtwaNM
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=MBqquBtwaNM
 41%|████      | 351/859 [06:04<08:23,  1.01it/s]INFO:__main__:Requesting https://www.thoughtworks.com
INFO:__main__:Getting metadata for https://www.thoughtworks.com
 41%|████      | 352/859 [06:04<06:21,  1.33it/s]INFO:__main__:Requesting http://www.aha.io
INFO:__main__:Getting metadata for https://www.aha.io
 41%|████      | 353/859 [06:05<07:35,  1.11it/s]INFO:__main__:Requesting https://conjur.org
INFO:__main__:Getting metadata for https://www.conjur.org
 41%|████      | 354/859 [06:07<08:32,  1.02s/it]INFO:__main__:Requesting https://www.conjur.org/careers/engineering.html
INFO:__main__:Getting metadata for https://www.conjur.org/careers/engineering.html
 41%|████▏     | 355/859 [06:08<09:00,  1.07s/it]INFO:__main__:Requesting https://blog.conjur.org
INFO:__main__:Getting metadata for https://blog.conjur.org
 41%|████▏     | 356/859 [06:09<08:57,  1.07s/it]INFO:__main__:Requesting https://netscoutrccorp.peoplefluent.com/
INFO:__main__:Getting metadata for https://netscoutrccorp.peoplefluent.com/res_joblist.html
ERROR:__main__:Could not get metadata for https://netscoutrccorp.peoplefluent.com/res_joblist.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 357/859 [06:10<08:11,  1.02it/s]INFO:__main__:Requesting https://goo.gl/RRPtC2
INFO:__main__:Getting metadata for https://netscoutrccorp.peoplefluent.com/res_viewjob.html?optlink-view=view-9518&ERFormID=res_newjoblist&ERFormCode=any
ERROR:__main__:Could not get metadata for https://netscoutrccorp.peoplefluent.com/res_viewjob.html?optlink-view=view-9518&ERFormID=res_newjoblist&ERFormCode=any
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 358/859 [06:10<07:51,  1.06it/s]INFO:__main__:Requesting https://www.uken.com
INFO:__main__:Getting metadata for https://www.uken.com
ERROR:__main__:Could not get metadata for https://www.uken.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 359/859 [06:12<08:12,  1.01it/s]INFO:__main__:Requesting http://uken.com
INFO:__main__:Getting metadata for https://uken.com:443
ERROR:__main__:Could not get metadata for https://uken.com:443
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 360/859 [06:13<08:18,  1.00it/s]INFO:__main__:Requesting https://www.structionsite.com
INFO:__main__:Getting metadata for https://www.structionsite.com
 42%|████▏     | 361/859 [06:13<07:36,  1.09it/s]INFO:__main__:Requesting https://degica.com
INFO:__main__:Getting metadata for https://degica.com
 42%|████▏     | 362/859 [06:14<06:25,  1.29it/s]INFO:__main__:Requesting https://degica.com/careers.html
INFO:__main__:Getting metadata for https://degica.com/careers.html
ERROR:__main__:Could not get metadata for https://degica.com/careers.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 363/859 [06:14<05:30,  1.50it/s]INFO:__main__:Requesting https://grnh.se/5c2325d71
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580232&gh_src=5c2325d71
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580232&gh_src=5c2325d71
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 364/859 [06:15<07:02,  1.17it/s]INFO:__main__:Requesting https://grnh.se/1f133cdb1
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580229&gh_src=1f133cdb1
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580229&gh_src=1f133cdb1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 365/859 [06:17<08:20,  1.01s/it]INFO:__main__:Requesting https://grnh.se/22c529821
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580227&gh_src=22c529821
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580227&gh_src=22c529821
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 43%|████▎     | 366/859 [06:18<08:41,  1.06s/it]INFO:__main__:Requesting https://grnh.se/3a548cc31
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580213&gh_src=3a548cc31
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580213&gh_src=3a548cc31
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 43%|████▎     | 367/859 [06:19<09:00,  1.10s/it]INFO:__main__:Requesting https://grnh.se/8f4490261
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580224&gh_src=8f4490261
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580224&gh_src=8f4490261
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 43%|████▎     | 368/859 [06:20<09:11,  1.12s/it]INFO:__main__:Requesting https://grnh.se/619bbb561
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580228&gh_src=619bbb561
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580228&gh_src=619bbb561
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 43%|████▎     | 369/859 [06:22<10:23,  1.27s/it]INFO:__main__:Requesting https://grnh.se/9cd139de1
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580225&gh_src=9cd139de1
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580225&gh_src=9cd139de1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 43%|████▎     | 370/859 [06:23<10:30,  1.29s/it]INFO:__main__:Requesting https://grnh.se/230f5df71
INFO:__main__:Getting metadata for https://www.tapad.com/careers/openings/?gh_jid=1580231&gh_src=230f5df71
ERROR:__main__:Could not get metadata for https://www.tapad.com/careers/openings/?gh_jid=1580231&gh_src=230f5df71
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 43%|████▎     | 371/859 [06:25<10:38,  1.31s/it]INFO:__main__:Requesting https://www.simplesurance.com/
INFO:__main__:Getting metadata for https://www.simplesurance.com
 43%|████▎     | 372/859 [06:26<09:40,  1.19s/it]INFO:__main__:Requesting https://blog.ycombinator.com/thoughts-on-insurance/
INFO:__main__:Getting metadata for https://blog.ycombinator.com/thoughts-on-insurance/
 43%|████▎     | 373/859 [06:26<07:56,  1.02it/s]INFO:__main__:Requesting https://www.simplesurance.com/careers/
INFO:__main__:Getting metadata for https://www.simplesurance.com/careers/
 44%|████▎     | 374/859 [06:27<08:30,  1.05s/it]INFO:__main__:Requesting https://www.makelovenotporn.com/
INFO:__main__:Getting metadata for https://www.makelovenotporn.com
ERROR:__main__:Could not get metadata for https://www.makelovenotporn.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 44%|████▎     | 375/859 [06:28<06:59,  1.15it/s]INFO:__main__:Requesting https://blog.ted.com/cindy_gallop_ma/
ERROR:__main__:Could not reach https://blog.ted.com/cindy_gallop_ma/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 44%|████▍     | 376/859 [06:28<05:18,  1.52it/s]INFO:__main__:Requesting https://nowthisnews.com/videos/future/make-love-not-porn-founder-on-starting-a-social-sex-revolution
INFO:__main__:Getting metadata for https://nowthisnews.com/videos/future/make-love-not-porn-founder-on-starting-a-social-sex-revolution
 44%|████▍     | 377/859 [06:28<04:36,  1.75it/s]INFO:__main__:Requesting https://techcrunch.com/2018/01/21/sex-the-final-frontier-cindy-gallop-raises-2m-from-mysterious-investor-for-social-sex-tech/
ERROR:__main__:Could not reach https://techcrunch.com/2018/01/21/sex-the-final-frontier-cindy-gallop-raises-2m-from-mysterious-investor-for-social-sex-tech/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 44%|████▍     | 378/859 [06:28<03:35,  2.23it/s]INFO:__main__:Requesting https://makelovenotporn.tv/jobs
INFO:__main__:Getting metadata for https://makelovenotporn.tv/jobs
ERROR:__main__:Could not get metadata for https://makelovenotporn.tv/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 44%|████▍     | 379/859 [06:29<03:46,  2.12it/s]INFO:__main__:Requesting https://squareup.com/careers/jobs
INFO:__main__:Getting metadata for https://squareup.com/careers/jobs
ERROR:__main__:Could not get metadata for https://squareup.com/careers/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 44%|████▍     | 380/859 [06:31<07:51,  1.02it/s]INFO:__main__:Requesting https://carta.com
INFO:__main__:Getting metadata for https://carta.com
 44%|████▍     | 381/859 [06:31<06:07,  1.30it/s]INFO:__main__:Requesting https://www.investec.co.uk
INFO:__main__:Getting metadata for https://www.investec.com/en_gb.html
 44%|████▍     | 382/859 [06:33<07:12,  1.10it/s]INFO:__main__:Requesting https://www.tanookilabs.com/jobs
INFO:__main__:Getting metadata for https://www.tanookilabs.com/jobs
ERROR:__main__:Could not get metadata for https://www.tanookilabs.com/jobs
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 45%|████▍     | 383/859 [06:33<06:26,  1.23it/s]INFO:__main__:Requesting https://www.conductor.com/careers
INFO:__main__:Getting metadata for https://www.conductor.com/careers/
 45%|████▍     | 384/859 [06:34<05:31,  1.43it/s]INFO:__main__:Requesting https://aclaimant.com/careers-developer
INFO:__main__:Getting metadata for https://aclaimant.com/careers-developer
 45%|████▍     | 385/859 [06:34<05:12,  1.52it/s]INFO:__main__:Requesting https://www.epirussystems.com/careers
INFO:__main__:Getting metadata for https://www.epirussystems.com/careers
 45%|████▍     | 386/859 [06:35<05:23,  1.46it/s]INFO:__main__:Requesting https://evolyst.com
INFO:__main__:Getting metadata for https://evolyst.com
 45%|████▌     | 387/859 [06:37<09:44,  1.24s/it]INFO:__main__:Requesting https://gravitational.com
INFO:__main__:Getting metadata for https://gravitational.com
 45%|████▌     | 388/859 [06:39<09:27,  1.20s/it]INFO:__main__:Requesting https://gravitational.com/about#jobs
INFO:__main__:Getting metadata for https://gravitational.com/about#jobs
 45%|████▌     | 389/859 [06:39<08:21,  1.07s/it]INFO:__main__:Requesting https://github.com/gravitational/careers/blob/master/systems..
 45%|████▌     | 390/859 [06:40<06:23,  1.22it/s]INFO:__main__:Requesting https://www.mailgun.com
INFO:__main__:Getting metadata for https://www.mailgun.com
 46%|████▌     | 391/859 [06:40<04:50,  1.61it/s]INFO:__main__:Requesting https://github.com/vulcand/vulcand
INFO:__main__:Getting metadata for https://github.com/vulcand/vulcand
 46%|████▌     | 392/859 [06:41<05:59,  1.30it/s]INFO:__main__:Requesting https://www.rackspace.com/cloud/servers/onmetal
INFO:__main__:Getting metadata for https://www.rackspace.com/cloud/servers/onmetal
 46%|████▌     | 393/859 [06:42<07:27,  1.04it/s]INFO:__main__:Requesting https://github.com/gravitational/teleport
INFO:__main__:Getting metadata for https://github.com/gravitational/teleport
 46%|████▌     | 394/859 [06:43<07:29,  1.03it/s]INFO:__main__:Requesting https://github.com/gravitational/gravity
INFO:__main__:Getting metadata for https://github.com/gravitational/gravity
 46%|████▌     | 395/859 [06:45<08:50,  1.14s/it]INFO:__main__:Requesting https://www.teleconsole.com/
INFO:__main__:Getting metadata for https://www.teleconsole.com
 46%|████▌     | 396/859 [06:46<08:33,  1.11s/it]INFO:__main__:Requesting https://www.mapudo.com/content/mapudo/jobs-fullstack-developer-core-platform-team/
INFO:__main__:Getting metadata for https://www.mapudo.com/content/mapudo/jobs-fullstack-developer-core-platform-team/
 46%|████▌     | 397/859 [06:47<07:52,  1.02s/it]INFO:__main__:Requesting https://thinkpacifica.com/
INFO:__main__:Getting metadata for https://www.thinkpacifica.com
 46%|████▋     | 398/859 [06:50<13:07,  1.71s/it]INFO:__main__:Requesting https://www.ngpvan.com/careers
INFO:__main__:Getting metadata for https://www.ngpvan.com/careers
 46%|████▋     | 399/859 [06:51<11:14,  1.47s/it]INFO:__main__:Requesting https://synthetic-minds.com/pages/jobs.html
INFO:__main__:Getting metadata for https://synthetic-minds.com/pages/jobs.html
 47%|████▋     | 400/859 [06:51<08:56,  1.17s/it]INFO:__main__:Requesting https://medium.com/@vidiborskiy/software-writes-software-program-synthesis-101-294a9a35177
INFO:__main__:Getting metadata for https://medium.com/@vidiborskiy/software-writes-software-program-synthesis-101-294a9a35177
 47%|████▋     | 401/859 [06:52<07:42,  1.01s/it]INFO:__main__:Requesting https://github.com/Z3Prover/z3
INFO:__main__:Getting metadata for https://github.com/Z3Prover/z3
 47%|████▋     | 402/859 [06:53<08:38,  1.13s/it]INFO:__main__:Requesting https://github.com/ethereum/solidity/blob/develop/libsolidity/ast/AST.cpp
INFO:__main__:Getting metadata for https://github.com/ethereum/solidity/blob/develop/libsolidity/ast/AST.cpp
 47%|████▋     | 403/859 [06:54<08:18,  1.09s/it]INFO:__main__:Requesting https://solidity.readthedocs.io/en/v0.4.21/solidity-by-example.html
INFO:__main__:Getting metadata for https://solidity.readthedocs.io/en/v0.4.21/solidity-by-example.html
 47%|████▋     | 404/859 [06:59<16:21,  2.16s/it]INFO:__main__:Requesting https://www.forbes.com/sites/darrynpollock/2018/10/22/investment-boost-for-synthetic-minds-helps-build-automated-smarter-smart-contracts/#6c1994462a63
INFO:__main__:Getting metadata for https://www.forbes.com/sites/darrynpollock/2018/10/22/investment-boost-for-synthetic-minds-helps-build-automated-smarter-smart-contracts/#6c1994462a63
 47%|████▋     | 405/859 [07:00<13:08,  1.74s/it]INFO:__main__:Requesting https://www.bitexpert.de
INFO:__main__:Getting metadata for https://www.bitexpert.de
ERROR:__main__:Could not get metadata for https://www.bitexpert.de
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 47%|████▋     | 406/859 [07:01<12:33,  1.66s/it]INFO:__main__:Requesting https://www.keyvalues.com/bitexpert
INFO:__main__:Getting metadata for https://www.keyvalues.com/bitexpert
 47%|████▋     | 407/859 [07:03<11:52,  1.58s/it]INFO:__main__:Requesting https://www.bitexpert.de/karriere/softwareentwicklerin/?ref=keyvalues
INFO:__main__:Getting metadata for https://www.bitexpert.de/karriere/softwareentwicklerin/?ref=keyvalues
ERROR:__main__:Could not get metadata for https://www.bitexpert.de/karriere/softwareentwicklerin/?ref=keyvalues
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 47%|████▋     | 408/859 [07:04<11:17,  1.50s/it]INFO:__main__:Requesting https://www.bitexpert.de/karriere/magento-entwicklerin/?ref=keyvalues
INFO:__main__:Getting metadata for https://www.bitexpert.de/karriere/magento-entwicklerin/?ref=keyvalues
ERROR:__main__:Could not get metadata for https://www.bitexpert.de/karriere/magento-entwicklerin/?ref=keyvalues
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 48%|████▊     | 409/859 [07:05<10:51,  1.45s/it]INFO:__main__:Requesting https://www.bitexpert.de/karriere/php-entwicklerin/?ref=keyvalues
INFO:__main__:Getting metadata for https://www.bitexpert.de/karriere/php-entwicklerin/?ref=keyvalues
ERROR:__main__:Could not get metadata for https://www.bitexpert.de/karriere/php-entwicklerin/?ref=keyvalues
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 48%|████▊     | 410/859 [07:07<11:44,  1.57s/it]INFO:__main__:Requesting https://www.prima.it/carriera
INFO:__main__:Getting metadata for https://www.prima.it/carriera
 48%|████▊     | 411/859 [07:12<17:58,  2.41s/it]INFO:__main__:Requesting https://opslock.com/jobs
INFO:__main__:Getting metadata for https://opslock.com/jobs
 48%|████▊     | 412/859 [07:13<16:23,  2.20s/it]INFO:__main__:Requesting https://www.patientcolife.com/jobs/team-lead-software-engineering/
INFO:__main__:Getting metadata for https://www.patientcolife.com/jobs/team-lead-software-engineering/
ERROR:__main__:Could not get metadata for https://www.patientcolife.com/jobs/team-lead-software-engineering/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 48%|████▊     | 413/859 [07:13<11:56,  1.61s/it]INFO:__main__:Requesting https://www.custora.com
INFO:__main__:Getting metadata for https://www.custora.com
 48%|████▊     | 414/859 [07:14<09:29,  1.28s/it]INFO:__main__:Requesting https://www.keyvalues.com/custora
INFO:__main__:Getting metadata for https://www.keyvalues.com/custora
 48%|████▊     | 415/859 [07:15<09:27,  1.28s/it]INFO:__main__:Requesting https://grnh.se/2f70d01c1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/1174709?gh_src=2f70d01c1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/1174709?gh_src=2f70d01c1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 48%|████▊     | 416/859 [07:16<08:51,  1.20s/it]INFO:__main__:Requesting https://grnh.se/cdae713f1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/1390706?gh_src=cdae713f1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/1390706?gh_src=cdae713f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 49%|████▊     | 417/859 [07:17<08:03,  1.09s/it]INFO:__main__:Requesting https://grnh.se/18bf836b1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/1320098?gh_src=18bf836b1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/1320098?gh_src=18bf836b1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 49%|████▊     | 418/859 [07:18<07:22,  1.00s/it]INFO:__main__:Requesting https://grnh.se/02e167501
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/1315503?gh_src=02e167501
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/1315503?gh_src=02e167501
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 49%|████▉     | 419/859 [07:19<06:29,  1.13it/s]INFO:__main__:Requesting https://grnh.se/58b316961
INFO:__main__:Getting metadata for https://boards.greenhouse.io/custora/jobs/54322?gh_src=58b316961
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/custora/jobs/54322?gh_src=58b316961
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 49%|████▉     | 420/859 [07:19<06:19,  1.16it/s]INFO:__main__:Requesting http://grnh.se/3rolbe1
INFO:__main__:Getting metadata for https://www.stashinvest.com/careers?gh_src=3rolbe1
 49%|████▉     | 421/859 [07:20<05:44,  1.27it/s]INFO:__main__:Requesting https://jobs.polymathv.com/bbec85be1
INFO:__main__:Getting metadata for https://polymathv.com/join-us/1083600/Desarrollador+M%C3%B3vil+Android/#bbec85be1
 49%|████▉     | 422/859 [07:21<06:32,  1.11it/s]INFO:__main__:Requesting https://boards.greenhouse.io/theinfatuation
INFO:__main__:Getting metadata for https://boards.greenhouse.io/theinfatuation
 49%|████▉     | 423/859 [07:22<05:47,  1.26it/s]INFO:__main__:Requesting https://www.pmd.com/reviews
INFO:__main__:Getting metadata for https://www.pmd.com/reviews
 49%|████▉     | 424/859 [07:26<13:39,  1.88s/it]INFO:__main__:Requesting https://www.pmd.com/careers
INFO:__main__:Getting metadata for https://www.pmd.com/careers
 49%|████▉     | 425/859 [07:27<12:16,  1.70s/it]INFO:__main__:Requesting https://corrux.io/
 50%|████▉     | 426/859 [07:28<09:11,  1.27s/it]INFO:__main__:Requesting https://corrux.io/career/
 50%|████▉     | 427/859 [07:28<06:57,  1.03it/s]INFO:__main__:Requesting https://www.handelsblatt.com/unternehmen/industrie/start-up-corrux-warum-die-mathematikerin-laura-toennies-als-bagger-fluesterin-gilt/23965996.html
INFO:__main__:Getting metadata for https://www.handelsblatt.com/unternehmen/industrie/start-up-corrux-warum-die-mathematikerin-laura-toennies-als-bagger-fluesterin-gilt/23965996.html?ticket=ST-1924421-by6g1AM4hpR1Bd2fJaZZ-ap2
 50%|████▉     | 428/859 [07:31<11:59,  1.67s/it]INFO:__main__:Requesting https://www.carbonblack.com
INFO:__main__:Getting metadata for https://www.carbonblack.com
 50%|████▉     | 429/859 [07:32<09:23,  1.31s/it]INFO:__main__:Requesting https://www.keyvalues.com/carbon-black
INFO:__main__:Getting metadata for https://www.keyvalues.com/carbon-black
 50%|█████     | 430/859 [07:33<08:48,  1.23s/it]INFO:__main__:Requesting https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb
INFO:__main__:Getting metadata for https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb
ERROR:__main__:Could not get metadata for https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 50%|█████     | 431/859 [07:37<14:26,  2.02s/it]INFO:__main__:Requesting https://www.linkedin.com/jobs/view/python-backend-web-developer-software-developer-iii-non-it-at-bio-rad-laboratories-921319545/
INFO:__main__:Requesting https://www.woflow.com
INFO:__main__:Getting metadata for https://www.woflow.com
 50%|█████     | 433/859 [07:39<12:27,  1.75s/it]INFO:__main__:Requesting https://www.hqo.co
INFO:__main__:Getting metadata for https://www.hqo.co
 51%|█████     | 434/859 [07:39<09:39,  1.36s/it]INFO:__main__:Requesting https://hqo.applytojob.com/apply/0s1ByARDjq/Back-End-Engineer?referrer=20190301164009QPYRPR9O6O5UIE3N
INFO:__main__:Getting metadata for https://hqo.applytojob.com/apply/0s1ByARDjq/Back-End-Engineer?referrer=20190301164009QPYRPR9O6O5UIE3N
 51%|█████     | 435/859 [07:40<09:07,  1.29s/it]INFO:__main__:Requesting https://hqo.applytojob.com/apply/xulftv47ax/Front-End-Engineer?referrer=20190301164037LOMAR2PBCQ81QAPH
INFO:__main__:Getting metadata for https://hqo.applytojob.com/apply/xulftv47ax/Front-End-Engineer?referrer=20190301164037LOMAR2PBCQ81QAPH
 51%|█████     | 436/859 [07:42<10:22,  1.47s/it]INFO:__main__:Requesting https://hqo.applytojob.com/apply/JfW73j99yr/UXUI-Designer?referrer=20190301164129JFPVUQ8HOH1XLXGP
INFO:__main__:Getting metadata for https://hqo.applytojob.com/apply/JfW73j99yr/UXUI-Designer?referrer=20190301164129JFPVUQ8HOH1XLXGP
 51%|█████     | 437/859 [07:44<11:03,  1.57s/it]INFO:__main__:Requesting https://hqo.applytojob.com/apply/cdADITCOdS/Product-Manager?referrer=201903011642173DUESZLFFTQPOXZQ
INFO:__main__:Getting metadata for https://hqo.applytojob.com/apply/cdADITCOdS/Product-Manager?referrer=201903011642173DUESZLFFTQPOXZQ
 51%|█████     | 438/859 [07:45<10:19,  1.47s/it]INFO:__main__:Requesting https://mytrellis.com/
INFO:__main__:Getting metadata for https://mytrellis.com
 51%|█████     | 439/859 [07:46<08:26,  1.21s/it]INFO:__main__:Requesting https://mytrellis.com/available-opportunities/software-developer
INFO:__main__:Getting metadata for https://mytrellis.com/available-opportunities/software-developer
 51%|█████     | 440/859 [07:48<09:31,  1.36s/it]INFO:__main__:Requesting https://careers.smartrecruiters.com/Thinknum/
INFO:__main__:Getting metadata for https://careers.smartrecruiters.com/Thinknum/
 51%|█████▏    | 441/859 [07:49<10:15,  1.47s/it]INFO:__main__:Requesting https://www.thinknum.com
INFO:__main__:Getting metadata for https://www.thinknum.com
 51%|█████▏    | 442/859 [07:50<09:09,  1.32s/it]INFO:__main__:Requesting https://15five.com
INFO:__main__:Getting metadata for https://www.15five.com
 52%|█████▏    | 443/859 [07:52<09:31,  1.37s/it]INFO:__main__:Requesting https://jobs.lever.co/15five/87e81f76-7785-4bef-a005-c8ae3d6796b5?lever-origin=applied&lever-source%5B%5D=HN
INFO:__main__:Getting metadata for https://jobs.lever.co/15five/87e81f76-7785-4bef-a005-c8ae3d6796b5?lever-origin=applied&lever-source%5B%5D=HN
 52%|█████▏    | 444/859 [07:52<07:57,  1.15s/it]INFO:__main__:Requesting https://jobs.lever.co/15five/4fc7917c-3706-450f-9bc0-d7fb080d2e24?lever-source%5B%5D=HN
INFO:__main__:Getting metadata for https://jobs.lever.co/15five/4fc7917c-3706-450f-9bc0-d7fb080d2e24?lever-source%5B%5D=HN
 52%|█████▏    | 445/859 [07:53<06:48,  1.01it/s]INFO:__main__:Requesting https://jobs.lever.co/15five/b6e90d36-36b5-4062-b9cb-d5af4687e2d3?lever-origin=applied&lever-source%5B%5D=HN
INFO:__main__:Getting metadata for https://jobs.lever.co/15five/b6e90d36-36b5-4062-b9cb-d5af4687e2d3?lever-origin=applied&lever-source%5B%5D=HN
 52%|█████▏    | 446/859 [07:54<05:59,  1.15it/s]INFO:__main__:Requesting https://www.15five.com/core-values/
INFO:__main__:Getting metadata for https://www.15five.com/core-values/
 52%|█████▏    | 447/859 [07:54<05:45,  1.19it/s]INFO:__main__:Requesting https://www.bigfishgames.com
INFO:__main__:Getting metadata for https://www.bigfishgames.com
 52%|█████▏    | 448/859 [07:56<06:50,  1.00it/s]INFO:__main__:Requesting https://app.jobvite.com/j?cj=o3yX8fwq&s=HN
INFO:__main__:Getting metadata for http://jobs.jobvite.com/careers/bigfish/job/o3yX8fwq?__jvst=Job+Board&__jvsd=HN
 52%|█████▏    | 449/859 [07:56<06:04,  1.12it/s]INFO:__main__:Requesting https://techcrunch.com/2019/01/25/the-predictive-index-brings-in-50m-to-help-businesses-create-winning-teams/
ERROR:__main__:Could not reach https://techcrunch.com/2019/01/25/the-predictive-index-brings-in-50m-to-help-businesses-create-winning-teams/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 52%|█████▏    | 450/859 [07:57<04:31,  1.51it/s]INFO:__main__:Requesting https://grnh.se/dfc2b9a82
INFO:__main__:Getting metadata for https://boards.greenhouse.io/predictiveindex/jobs/4201099002?gh_src=dfc2b9a82
 53%|█████▎    | 451/859 [07:57<04:33,  1.49it/s]INFO:__main__:Requesting http://www.driveworks.co.uk/jobs/
INFO:__main__:Getting metadata for https://www.driveworks.co.uk/jobs/
 53%|█████▎    | 452/859 [08:01<10:41,  1.58s/it]INFO:__main__:Requesting https://www.depop.com/about/jobs/66BFF78BC7/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/66BFF78BC7/
 53%|█████▎    | 453/859 [08:01<08:07,  1.20s/it]INFO:__main__:Requesting https://www.depop.com/about/jobs/CC5C89E62B/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/CC5C89E62B/
 53%|█████▎    | 454/859 [08:02<06:31,  1.03it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/92DBE64C63/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/92DBE64C63/
 53%|█████▎    | 455/859 [08:02<05:56,  1.13it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/E6A167938B/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/E6A167938B/
 53%|█████▎    | 456/859 [08:03<05:06,  1.32it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/0E6DE2B5C9/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/0E6DE2B5C9/
 53%|█████▎    | 457/859 [08:03<04:40,  1.43it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/450747CCF9/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/450747CCF9/
 53%|█████▎    | 458/859 [08:04<04:13,  1.58it/s]INFO:__main__:Requesting https://www.depop.com/about/jobs/6B70F6DB04/
INFO:__main__:Getting metadata for https://www.depop.com/about/jobs/6B70F6DB04/
 53%|█████▎    | 459/859 [08:04<03:50,  1.74it/s]INFO:__main__:Requesting https://medium.com/darklang/the-design-of-dark-59f5d38e52d2
INFO:__main__:Getting metadata for https://medium.com/darklang/the-design-of-dark-59f5d38e52d2
 54%|█████▎    | 460/859 [08:05<03:49,  1.74it/s]INFO:__main__:Requesting http://darklang.com/careers/infrastructure-engineer
INFO:__main__:Getting metadata for https://darklang.com/careers/infrastructure-engineer/
ERROR:__main__:Could not get metadata for https://darklang.com/careers/infrastructure-engineer/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 54%|█████▎    | 461/859 [08:06<04:36,  1.44it/s]INFO:__main__:Requesting http://darklang.com/careers/software-engineer
INFO:__main__:Getting metadata for https://darklang.com/careers/software-engineer/
ERROR:__main__:Could not get metadata for https://darklang.com/careers/software-engineer/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 54%|█████▍    | 462/859 [08:07<05:01,  1.32it/s]INFO:__main__:Requesting https://darklang.com/careers/frontend-engineer/
INFO:__main__:Getting metadata for https://darklang.com/careers/frontend-engineer/
ERROR:__main__:Could not get metadata for https://darklang.com/careers/frontend-engineer/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 54%|█████▍    | 463/859 [08:07<04:40,  1.41it/s]INFO:__main__:Requesting https://www.levvel.io
INFO:__main__:Getting metadata for https://www.levvel.io
 54%|█████▍    | 464/859 [08:09<05:57,  1.11it/s]INFO:__main__:Requesting https://www.levvel.io/our-ideas/Inc-500-Award-2018
INFO:__main__:Getting metadata for https://www.levvel.io/our-ideas/Inc-500-Award-2018
 54%|█████▍    | 465/859 [08:10<06:01,  1.09it/s]INFO:__main__:Requesting https://www.etecture.de/
INFO:__main__:Getting metadata for https://www.etecture.de
 54%|█████▍    | 466/859 [08:12<09:38,  1.47s/it]INFO:__main__:Requesting https://opench.bamboohr.co.uk/jobs/view.php?id=42
INFO:__main__:Getting metadata for https://opench.bamboohr.co.uk/jobs/view.php?id=42
 54%|█████▍    | 467/859 [08:14<09:54,  1.52s/it]INFO:__main__:Requesting https://opench.bamboohr.co.uk/jobs/view.php?id=111
INFO:__main__:Getting metadata for https://opench.bamboohr.co.uk/jobs/view.php?id=111
 54%|█████▍    | 468/859 [08:16<09:57,  1.53s/it]INFO:__main__:Requesting https://www.continental-corporation.com/en
INFO:__main__:Getting metadata for https://www.continental-corporation.com/en
 55%|█████▍    | 469/859 [08:16<07:33,  1.16s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=Cbw716NsIVQ
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=Cbw716NsIVQ
 55%|█████▍    | 470/859 [08:17<06:59,  1.08s/it]INFO:__main__:Requesting https://www.continental-jobs.com/index.php?ac=jobad&id=999144
INFO:__main__:Getting metadata for https://www.continental-jobs.com/index.php?ac=jobad&id=999144
ERROR:__main__:Could not get metadata for https://www.continental-jobs.com/index.php?ac=jobad&id=999144
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 55%|█████▍    | 471/859 [08:19<08:20,  1.29s/it]INFO:__main__:Requesting https://tray.io
INFO:__main__:Getting metadata for https://tray.io
 55%|█████▍    | 472/859 [08:19<06:16,  1.03it/s]INFO:__main__:Requesting https://tray-io.workable.com/jobs/954594
INFO:__main__:Getting metadata for https://tray-io.workable.com/jobs/954594
 55%|█████▌    | 473/859 [08:19<05:40,  1.13it/s]INFO:__main__:Requesting https://tray-io.workable.com/j/A989E2788E
INFO:__main__:Getting metadata for https://tray-io.workable.com/j/A989E2788E
 55%|█████▌    | 474/859 [08:20<05:26,  1.18it/s]INFO:__main__:Requesting https://tray-io.workable.com/j/50E49D5631
INFO:__main__:Getting metadata for https://tray-io.workable.com/j/50E49D5631
 55%|█████▌    | 475/859 [08:21<05:03,  1.27it/s]INFO:__main__:Requesting https://tray-io.workable.com/j/ECA9DB9833
INFO:__main__:Getting metadata for https://tray-io.workable.com/j/ECA9DB9833
 55%|█████▌    | 476/859 [08:22<04:46,  1.34it/s]INFO:__main__:Requesting https://tray-io.workable.com/j/B966DEFE9F
INFO:__main__:Getting metadata for https://tray-io.workable.com/j/B966DEFE9F
 56%|█████▌    | 477/859 [08:22<04:44,  1.35it/s]INFO:__main__:Requesting https://tray.io/jobs
INFO:__main__:Getting metadata for https://tray.io/jobs
 56%|█████▌    | 478/859 [08:24<05:47,  1.10it/s]INFO:__main__:Requesting https://www.policygenius.com
INFO:__main__:Getting metadata for https://www.policygenius.com
 56%|█████▌    | 479/859 [08:24<04:38,  1.36it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1544126
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1544126
 56%|█████▌    | 480/859 [08:25<05:29,  1.15it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1544131
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1544131
 56%|█████▌    | 481/859 [08:26<04:37,  1.36it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1558455
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1558455
 56%|█████▌    | 482/859 [08:26<03:59,  1.57it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1558446
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1558446
 56%|█████▌    | 483/859 [08:26<03:31,  1.78it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1301195
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1301195
 56%|█████▋    | 484/859 [08:27<03:16,  1.91it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1301194
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1301194
 56%|█████▋    | 485/859 [08:27<03:00,  2.07it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius/jobs/1301193
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius/jobs/1301193
 57%|█████▋    | 486/859 [08:28<02:50,  2.19it/s]INFO:__main__:Requesting https://boards.greenhouse.io/policygenius
INFO:__main__:Getting metadata for https://boards.greenhouse.io/policygenius
 57%|█████▋    | 487/859 [08:28<02:38,  2.35it/s]INFO:__main__:Requesting https://www.igalia.com/
INFO:__main__:Getting metadata for https://www.igalia.com
 57%|█████▋    | 488/859 [08:37<18:41,  3.02s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/chromium-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/chromium-developer
 57%|█████▋    | 489/859 [08:42<21:43,  3.52s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/webkit-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/webkit-developer
 57%|█████▋    | 490/859 [08:46<22:34,  3.67s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/webkit-graphics-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/webkit-graphics-developer
 57%|█████▋    | 491/859 [08:50<22:51,  3.73s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/graphics-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/graphics-developer
 57%|█████▋    | 492/859 [08:53<22:23,  3.66s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/javascript-engine-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/javascript-engine-developer
 57%|█████▋    | 493/859 [08:56<21:48,  3.58s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/compilers-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/compilers-developer
 58%|█████▊    | 494/859 [09:00<21:07,  3.47s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/multimedia-developer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/multimedia-developer
 58%|█████▊    | 495/859 [09:03<20:36,  3.40s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/web-platform-engineer
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/web-platform-engineer
 58%|█████▊    | 496/859 [09:06<20:20,  3.36s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/developer-advocate
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/developer-advocate
 58%|█████▊    | 497/859 [09:10<20:27,  3.39s/it]INFO:__main__:Requesting https://www.igalia.com/nc/about-us/form/senior-systems-administrator-galicia-spain
INFO:__main__:Getting metadata for https://www.igalia.com/nc/about-us/form/senior-systems-administrator-galicia-spain
 58%|█████▊    | 498/859 [09:13<20:35,  3.42s/it]INFO:__main__:Requesting http://www.recursionpharma.com/careers
INFO:__main__:Getting metadata for https://www.recursionpharma.com/careers/
 58%|█████▊    | 499/859 [09:14<15:32,  2.59s/it]INFO:__main__:Requesting http://www.recursionpharma.com/team
INFO:__main__:Getting metadata for https://www.recursionpharma.com/team/
 58%|█████▊    | 500/859 [09:14<12:08,  2.03s/it]INFO:__main__:Requesting https://jobs.scot.nhs.uk/_results.aspx?catID=&regionID=&orgID=&word=medical%20devices%20unit
INFO:__main__:Getting metadata for https://jobs.scot.nhs.uk/_results.aspx?catID=&regionID=&orgID=&word=medical%20devices%20unit
 58%|█████▊    | 501/859 [09:18<14:40,  2.46s/it]INFO:__main__:Requesting https://www.lever.co
INFO:__main__:Getting metadata for https://www.lever.co
 58%|█████▊    | 502/859 [09:18<11:08,  1.87s/it]INFO:__main__:Requesting https://www.keyvalues.com/lever
INFO:__main__:Getting metadata for https://www.keyvalues.com/lever
 59%|█████▊    | 503/859 [09:20<09:54,  1.67s/it]INFO:__main__:Requesting https://jobs.lever.co/lever/5dc41b9b-3166-41ee-b048-71eb53a79bd3?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/5dc41b9b-3166-41ee-b048-71eb53a79bd3?lever-source=KeyValues
 59%|█████▊    | 504/859 [09:20<08:06,  1.37s/it]INFO:__main__:Requesting https://jobs.lever.co/lever/5075f462-d149-4081-ba15-6080cbbbd5fd?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/5075f462-d149-4081-ba15-6080cbbbd5fd?lever-source=KeyValues
 59%|█████▉    | 505/859 [09:21<06:52,  1.17s/it]INFO:__main__:Requesting https://jobs.lever.co/lever/ea11e377-ad86-4173-86d2-2b8b1fc32dd6?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/ea11e377-ad86-4173-86d2-2b8b1fc32dd6?lever-source=KeyValues
 59%|█████▉    | 506/859 [09:22<06:06,  1.04s/it]INFO:__main__:Requesting https://jobs.lever.co/lever/f6eb3fa6-0ba5-4178-b1ae-e4e0448ba175?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/f6eb3fa6-0ba5-4178-b1ae-e4e0448ba175?lever-source=KeyValues
 59%|█████▉    | 507/859 [09:22<05:21,  1.09it/s]INFO:__main__:Requesting https://jobs.lever.co/lever/dd9a8568-623b-404c-b853-d6a46ebeb9ae?lever-source=KeyValues
INFO:__main__:Getting metadata for https://jobs.lever.co/lever/dd9a8568-623b-404c-b853-d6a46ebeb9ae?lever-source=KeyValues
 59%|█████▉    | 508/859 [09:23<04:49,  1.21it/s]INFO:__main__:Requesting https://fulcrum.lever.co/the-lever-tech-stack-1b30e27d2bb0
INFO:__main__:Getting metadata for https://fulcrum.lever.co/the-lever-tech-stack-1b30e27d2bb0?gi=dbbe503fc1d6
 59%|█████▉    | 509/859 [09:24<05:31,  1.06it/s]INFO:__main__:Requesting https://www.noredink.com/jobs
INFO:__main__:Getting metadata for https://www.noredink.com/jobs
 59%|█████▉    | 510/859 [09:25<04:35,  1.27it/s]INFO:__main__:Requesting https://www.noredink.com/about/team
INFO:__main__:Getting metadata for https://www.noredink.com/about/team
 59%|█████▉    | 511/859 [09:27<06:30,  1.12s/it]INFO:__main__:Requesting http://tech.noredink.com/
INFO:__main__:Getting metadata for https://blog.noredink.com/#_=_
 60%|█████▉    | 512/859 [09:27<06:08,  1.06s/it]INFO:__main__:Requesting https://github.com/NoRedInk/
INFO:__main__:Getting metadata for https://github.com/NoRedInk/
 60%|█████▉    | 513/859 [09:29<07:08,  1.24s/it]INFO:__main__:Requesting http://tech.noredink.com/post/136615783598/welcome-evan
INFO:__main__:Getting metadata for https://blog.noredink.com/post/136615783598/welcome-evan#_=_
 60%|█████▉    | 514/859 [09:30<06:17,  1.09s/it]INFO:__main__:Requesting http://tech.noredink.com/post/145260396603/our-engineering-hiring-process
INFO:__main__:Getting metadata for https://blog.noredink.com/post/145260396603/our-engineering-hiring-process#_=_
 60%|█████▉    | 515/859 [09:31<05:45,  1.00s/it]INFO:__main__:Requesting http://tech.noredink.com/post/143787279069/on-boarding-as-a-new-remote-engineer-think-about
INFO:__main__:Getting metadata for https://blog.noredink.com/post/143787279069/on-boarding-as-a-new-remote-engineer#_=_
 60%|██████    | 516/859 [09:31<05:27,  1.05it/s]INFO:__main__:Requesting https://hazelanalytics.com
INFO:__main__:Getting metadata for https://hazelanalytics.com
 60%|██████    | 517/859 [09:32<05:31,  1.03it/s]INFO:__main__:Requesting http://www.espn.com/espn/feature/story/_/id/25316231/health-inspection-reports-find-critical-violations-nfl-nhl-nba-mlb-stadiums-2018-espn-lines
INFO:__main__:Getting metadata for http://www.espn.com/espn/feature/story/_/id/25316231/health-inspection-reports-find-critical-violations-nfl-nhl-nba-mlb-stadiums-2018-espn-lines
 60%|██████    | 518/859 [09:33<05:08,  1.10it/s]INFO:__main__:Requesting https://jobs.lever.co/hazelanalytics/7c4ae7ec-ed3f-45cf-b2e9-0a8146b89840?lever-origin=applied&lever-source%5B%5D=Hacker%20News
INFO:__main__:Getting metadata for https://jobs.lever.co/hazelanalytics/7c4ae7ec-ed3f-45cf-b2e9-0a8146b89840?lever-origin=applied&lever-source%5B%5D=Hacker%20News
 60%|██████    | 519/859 [09:34<04:36,  1.23it/s]INFO:__main__:Requesting https://jobs.lever.co/hazelanalytics/d2df0869-51e3-4e92-9136-78ca3077c2cb?lever-origin=applied&lever-source%5B%5D=Hacker%20News
INFO:__main__:Getting metadata for https://jobs.lever.co/hazelanalytics/d2df0869-51e3-4e92-9136-78ca3077c2cb?lever-origin=applied&lever-source%5B%5D=Hacker%20News
 61%|██████    | 520/859 [09:34<04:16,  1.32it/s]INFO:__main__:Requesting https://jobs.lever.co/hazelanalytics/e959f02d-06e7-4f8b-971b-b7a4af640a0f?lever-origin=applied&lever-source%5B%5D=Hacker%20News
INFO:__main__:Getting metadata for https://jobs.lever.co/hazelanalytics/e959f02d-06e7-4f8b-971b-b7a4af640a0f?lever-origin=applied&lever-source%5B%5D=Hacker%20News
 61%|██████    | 521/859 [09:35<03:59,  1.41it/s]INFO:__main__:Requesting https://www.samsara.com
INFO:__main__:Getting metadata for https://www.samsara.com
 61%|██████    | 522/859 [09:37<06:06,  1.09s/it]INFO:__main__:Requesting https://www.keyvalues.com/samsara
INFO:__main__:Getting metadata for https://www.keyvalues.com/samsara
 61%|██████    | 523/859 [09:38<06:31,  1.16s/it]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1254967?gh_src=d9387f701
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1254967?gh_src=d9387f701
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1254967?gh_src=d9387f701
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 61%|██████    | 524/859 [09:40<06:35,  1.18s/it]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1470418?gh_src=5d66cb4c1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1470418?gh_src=5d66cb4c1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1470418?gh_src=5d66cb4c1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 61%|██████    | 525/859 [09:40<05:20,  1.04it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/870567?gh_src=5a99136f1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/870567?gh_src=5a99136f1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/870567?gh_src=5a99136f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 61%|██████    | 526/859 [09:41<04:33,  1.22it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1385260?gh_src=e5adf49e1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 61%|██████▏   | 527/859 [09:43<06:58,  1.26s/it]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1470416?gh_src=b91f86491
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1470416?gh_src=b91f86491
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1470416?gh_src=b91f86491
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 61%|██████▏   | 528/859 [09:43<05:35,  1.01s/it]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1392257?gh_src=890fd7db1
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1392257?gh_src=890fd7db1
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1392257?gh_src=890fd7db1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 62%|██████▏   | 529/859 [09:44<04:39,  1.18it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/946181
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/946181
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/946181
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 62%|██████▏   | 530/859 [09:44<03:59,  1.37it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/946228?gh_src=0d2920b21
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/946228?gh_src=0d2920b21
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/946228?gh_src=0d2920b21
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 62%|██████▏   | 531/859 [09:45<04:15,  1.28it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1470413?gh_src=782386f71
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1470413?gh_src=782386f71
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1470413?gh_src=782386f71
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 62%|██████▏   | 532/859 [09:46<03:40,  1.48it/s]INFO:__main__:Requesting https://boards.greenhouse.io/samsara/jobs/1271489?gh_src=79bc46e41
INFO:__main__:Getting metadata for https://boards.greenhouse.io/samsara/jobs/1271489?gh_src=79bc46e41
ERROR:__main__:Could not get metadata for https://boards.greenhouse.io/samsara/jobs/1271489?gh_src=79bc46e41
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 62%|██████▏   | 533/859 [09:46<03:20,  1.62it/s]INFO:__main__:Requesting https://jobs.lever.co/quora/4ea5b0e2-b570-439f-a3a1-1f3010422273?lever-origin=applied&lever-source%5B%5D=ycombinator
INFO:__main__:Getting metadata for https://jobs.lever.co/quora/4ea5b0e2-b570-439f-a3a1-1f3010422273?lever-origin=applied&lever-source%5B%5D=ycombinator
 62%|██████▏   | 534/859 [09:47<03:18,  1.63it/s]INFO:__main__:Requesting https://jobs.lever.co/quora/5ae871e6-12a7-40d2-829a-64041e24da42?lever-origin=applied&lever-source%5B%5D=ycombinator
INFO:__main__:Getting metadata for https://jobs.lever.co/quora/5ae871e6-12a7-40d2-829a-64041e24da42?lever-origin=applied&lever-source%5B%5D=ycombinator
 62%|██████▏   | 535/859 [09:47<03:18,  1.63it/s]INFO:__main__:Requesting https://jobs.lever.co/quora/447265db-74b3-4970-bb46-11083af8e4d5?lever-origin=applied&lever-source%5B%5D=ycombinator
INFO:__main__:Getting metadata for https://jobs.lever.co/quora/447265db-74b3-4970-bb46-11083af8e4d5?lever-origin=applied&lever-source%5B%5D=ycombinator
 62%|██████▏   | 536/859 [09:48<03:19,  1.62it/s]INFO:__main__:Requesting https://jobs.lever.co/quora/6be9efa2-49db-4fe1-bf42-fe45e5ae6cb9?lever-origin=applied&lever-source%5B%5D=ycombinator
INFO:__main__:Getting metadata for https://jobs.lever.co/quora/6be9efa2-49db-4fe1-bf42-fe45e5ae6cb9?lever-origin=applied&lever-source%5B%5D=ycombinator
 63%|██████▎   | 537/859 [09:48<03:21,  1.60it/s]INFO:__main__:Requesting https://engineering.quora.com/Dataset-release-and-Kaggle-competition-Question-Sincerity
INFO:__main__:Getting metadata for https://engineering.quora.com/Dataset-release-and-Kaggle-competition-Question-Sincerity
ERROR:__main__:Could not get metadata for https://engineering.quora.com/Dataset-release-and-Kaggle-competition-Question-Sincerity
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 63%|██████▎   | 538/859 [09:50<05:33,  1.04s/it]INFO:__main__:Requesting https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics
INFO:__main__:Getting metadata for https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics
ERROR:__main__:Could not get metadata for https://data.quora.com/A-Robust-Statistical-Test-for-Ratio-Metrics
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 63%|██████▎   | 539/859 [09:53<07:24,  1.39s/it]INFO:__main__:Requesting https://blog.quora.com/Introducing-Spaces
INFO:__main__:Getting metadata for https://blog.quora.com/Introducing-Spaces
ERROR:__main__:Could not get metadata for https://blog.quora.com/Introducing-Spaces
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 63%|██████▎   | 540/859 [09:59<16:01,  3.01s/it]INFO:__main__:Requesting https://nsidc.org/about/jobs/devops-administrator
INFO:__main__:Getting metadata for https://nsidc.org/about/jobs/devops-administrator
 63%|██████▎   | 541/859 [10:00<12:41,  2.40s/it]INFO:__main__:Requesting https://jobs.colorado.edu/jobs/JobDetail/?jobId=15411
INFO:__main__:Getting metadata for https://jobs.colorado.edu/jobs/JobDetail/?jobId=15411
 63%|██████▎   | 542/859 [10:02<11:39,  2.21s/it]INFO:__main__:Requesting https://relayr.io/
INFO:__main__:Getting metadata for https://relayr.io
 63%|██████▎   | 543/859 [10:04<10:42,  2.03s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=39
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=39
 63%|██████▎   | 544/859 [10:06<10:22,  1.98s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=38
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=38
 63%|██████▎   | 545/859 [10:07<09:35,  1.83s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=74
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=74
 64%|██████▎   | 546/859 [10:09<09:01,  1.73s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=37
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=37
 64%|██████▎   | 547/859 [10:10<08:47,  1.69s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=5
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=5
 64%|██████▍   | 548/859 [10:12<08:35,  1.66s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=110
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=110
 64%|██████▍   | 549/859 [10:13<08:25,  1.63s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=71
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=71
 64%|██████▍   | 550/859 [10:15<07:47,  1.51s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=119
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=119
 64%|██████▍   | 551/859 [10:16<07:52,  1.53s/it]INFO:__main__:Requesting https://relayr.bamboohr.co.uk/jobs/view.php?id=118
INFO:__main__:Getting metadata for https://relayr.bamboohr.co.uk/jobs/view.php?id=118
 64%|██████▍   | 552/859 [10:18<07:52,  1.54s/it]INFO:__main__:Requesting https://relayr.io/about/join-us/
INFO:__main__:Getting metadata for https://relayr.io/about/join-us/
 64%|██████▍   | 553/859 [10:19<08:01,  1.57s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/
 64%|██████▍   | 554/859 [10:21<07:23,  1.45s/it]INFO:__main__:Requesting https://www.aquabyte.ai
ERROR:__main__:Could not reach https://www.aquabyte.ai
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 80, in create_connection
    raise err
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 70, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 301, in connect
    conn = self._new_conn()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 164, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0e8c51e8d0>, 'Connection to www.aquabyte.ai timed out. (connect timeout=6)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.aquabyte.ai', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0e8c51e8d0>, 'Connection to www.aquabyte.ai timed out. (connect timeout=6)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 504, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.aquabyte.ai', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0e8c51e8d0>, 'Connection to www.aquabyte.ai timed out. (connect timeout=6)'))
 65%|██████▍   | 555/859 [10:27<14:19,  2.83s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/557f4987-5ed6-4aae-b8c7-b0d3011e59eb
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/557f4987-5ed6-4aae-b8c7-b0d3011e59eb
 65%|██████▍   | 556/859 [10:27<10:55,  2.16s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/738c2aa4-faf3-4783-bda4-d14af2199bf0
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/738c2aa4-faf3-4783-bda4-d14af2199bf0
 65%|██████▍   | 557/859 [10:28<08:32,  1.70s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/59b53335-e773-4003-86a7-a008dd474292
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/59b53335-e773-4003-86a7-a008dd474292
 65%|██████▍   | 558/859 [10:29<07:02,  1.41s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/c4fa7f35-bc53-400a-a830-4fe1bdabfa47
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/c4fa7f35-bc53-400a-a830-4fe1bdabfa47
 65%|██████▌   | 559/859 [10:29<05:48,  1.16s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/b951497b-b4e6-4c94-b35f-83bc8624f312
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/b951497b-b4e6-4c94-b35f-83bc8624f312
 65%|██████▌   | 560/859 [10:30<05:05,  1.02s/it]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/e6683e22-cdcb-4dac-b601-ba37a6da3b8e
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/e6683e22-cdcb-4dac-b601-ba37a6da3b8e
 65%|██████▌   | 561/859 [10:30<04:26,  1.12it/s]INFO:__main__:Requesting https://jobs.lever.co/aquabyte/ce704fb7-3d7a-40b8-93e3-9d21f23cea07
INFO:__main__:Getting metadata for https://jobs.lever.co/aquabyte/ce704fb7-3d7a-40b8-93e3-9d21f23cea07
 65%|██████▌   | 562/859 [10:31<03:58,  1.25it/s]INFO:__main__:Requesting https://www.zoomforth.com
INFO:__main__:Getting metadata for https://www.zoomforth.com
 66%|██████▌   | 563/859 [10:31<03:17,  1.50it/s]INFO:__main__:Requesting https://goo.gl/forms/8WOjyVeQ91lc4U0K3
INFO:__main__:Getting metadata for https://docs.google.com/forms/d/e/1FAIpQLSf3mwlnyNkFejV3hJ5nJpDLyjYMve4bZON5SlItlwUIJUBK5A/viewform?usp=send_form
 66%|██████▌   | 564/859 [10:32<03:16,  1.50it/s]INFO:__main__:Requesting https://www.tanium.com/careers/?gh_src=qprker8f1
INFO:__main__:Getting metadata for https://www.tanium.com/careers/?gh_src=qprker8f1
 66%|██████▌   | 565/859 [10:33<03:16,  1.50it/s]INFO:__main__:Requesting https://www.tanium.com/careers/?p=department&t=Engineering&gh_src=b44d958b1#openings
INFO:__main__:Getting metadata for https://www.tanium.com/careers/?p=department&t=Engineering&gh_src=b44d958b1#openings
 66%|██████▌   | 566/859 [10:33<03:16,  1.49it/s]INFO:__main__:Requesting https://www.tanium.com/careers/?p=department&t=Technical%20Account%20Management&gh_src=r64ytqkl1#openings
INFO:__main__:Getting metadata for https://www.tanium.com/careers/?p=department&t=Technical%20Account%20Management&gh_src=r64ytqkl1#openings
 66%|██████▌   | 567/859 [10:34<02:56,  1.65it/s]INFO:__main__:Requesting https://grnh.se/ec5df4181
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1131458&gh_src=ec5df4181
 66%|██████▌   | 568/859 [10:34<02:53,  1.68it/s]INFO:__main__:Requesting https://grnh.se/hf4v4o8l1
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=497373&gh_src=hf4v4o8l1
 66%|██████▌   | 569/859 [10:35<03:00,  1.61it/s]INFO:__main__:Requesting https://grnh.se/fd4e8ed81
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1416291&gh_src=fd4e8ed81
 66%|██████▋   | 570/859 [10:36<03:15,  1.48it/s]INFO:__main__:Requesting https://grnh.se/5a0b1fd61
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1416292&gh_src=5a0b1fd61
 66%|██████▋   | 571/859 [10:37<03:14,  1.48it/s]INFO:__main__:Requesting https://grnh.se/79ee36481
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1420039&gh_src=79ee36481
 67%|██████▋   | 572/859 [10:37<03:02,  1.57it/s]INFO:__main__:Requesting https://grnh.se/0101307e1
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1148597&gh_src=0101307e1
 67%|██████▋   | 573/859 [10:38<02:52,  1.66it/s]INFO:__main__:Requesting https://grnh.se/c2d947de1
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1148600&gh_src=c2d947de1
 67%|██████▋   | 574/859 [10:38<02:45,  1.72it/s]INFO:__main__:Requesting https://grnh.se/deaf94841
INFO:__main__:Getting metadata for https://www.tanium.com/apply-now/?gh_jid=1141995&gh_src=deaf94841
 67%|██████▋   | 575/859 [10:39<02:40,  1.77it/s]INFO:__main__:Requesting http://fortune.com/most-important-private-companies/tanium-24/
INFO:__main__:Requesting https://www.forbes.com/companies/tanium/#3bbe09173eea
INFO:__main__:Getting metadata for https://www.forbes.com/companies/tanium/#3bbe09173eea
 67%|██████▋   | 577/859 [10:40<02:38,  1.78it/s]INFO:__main__:Requesting https://www.fedscoop.com/air-force-cio-says-role-become-much-prominent-prepares-retire/
INFO:__main__:Getting metadata for https://www.fedscoop.com/air-force-cio-says-role-become-much-prominent-prepares-retire/
 67%|██████▋   | 578/859 [10:41<03:02,  1.54it/s]INFO:__main__:Requesting https://federalnewsnetwork.com/dod-reporters-notebook-jared-serbu/2018/12/air-force-to-release-new-fast-track-cyber-approval-process/
INFO:__main__:Getting metadata for https://federalnewsnetwork.com/dod-reporters-notebook-jared-serbu/2018/12/air-force-to-release-new-fast-track-cyber-approval-process/
 67%|██████▋   | 579/859 [10:41<02:33,  1.83it/s]INFO:__main__:Requesting http://fortune.com/best-medium-workplaces/tanium-55/
 68%|██████▊   | 580/859 [10:42<02:40,  1.73it/s]INFO:__main__:Requesting http://reviews.greatplacetowork.com/tanium
INFO:__main__:Getting metadata for https://www.greatplacetowork.com/certified-company/5003402
 68%|██████▊   | 581/859 [10:43<03:03,  1.51it/s]INFO:__main__:Requesting https://auth0.com/
INFO:__main__:Getting metadata for https://auth0.com
 68%|██████▊   | 582/859 [10:43<02:54,  1.59it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/335316b1-9a71-4488-bd0c-c589c4fac03f
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/335316b1-9a71-4488-bd0c-c589c4fac03f
 68%|██████▊   | 583/859 [10:44<02:51,  1.61it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/f2a6fd71-f536-4aee-8cd1-76d96a04f894
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/f2a6fd71-f536-4aee-8cd1-76d96a04f894
 68%|██████▊   | 584/859 [10:44<02:52,  1.59it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/577e4a81-c5bf-438c-ac86-766a597f30bc
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/577e4a81-c5bf-438c-ac86-766a597f30bc
 68%|██████▊   | 585/859 [10:45<02:49,  1.62it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/ba4c9c85-ad15-4af3-b98d-a81fb6ba46dd
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/ba4c9c85-ad15-4af3-b98d-a81fb6ba46dd
 68%|██████▊   | 586/859 [10:46<02:48,  1.62it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/dd370211-cc49-403e-b001-5eb1c8207f7c
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/dd370211-cc49-403e-b001-5eb1c8207f7c
 68%|██████▊   | 587/859 [10:46<02:45,  1.64it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/f402a708-f59e-4b7c-b144-a1d154e2949b
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/f402a708-f59e-4b7c-b144-a1d154e2949b
 68%|██████▊   | 588/859 [10:47<02:44,  1.65it/s]INFO:__main__:Requesting https://jobs.lever.co/auth0/90483251-ce4e-4129-9682-ce46482508f3
INFO:__main__:Getting metadata for https://jobs.lever.co/auth0/90483251-ce4e-4129-9682-ce46482508f3
 69%|██████▊   | 589/859 [10:47<02:50,  1.58it/s]INFO:__main__:Requesting https://auth0.com/blog/how-we-hire-engineers/
INFO:__main__:Getting metadata for https://auth0.com/blog/how-we-hire-engineers/
 69%|██████▊   | 590/859 [10:51<06:48,  1.52s/it]INFO:__main__:Requesting https://twitter.com/vibronet/status/997608152811044872
INFO:__main__:Getting metadata for https://twitter.com/vibronet/status/997608152811044872
 69%|██████▉   | 591/859 [10:52<05:43,  1.28s/it]INFO:__main__:Requesting https://iterable.com
INFO:__main__:Getting metadata for https://iterable.com
 69%|██████▉   | 592/859 [10:52<04:09,  1.07it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1475142
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1475142
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1475142
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 69%|██████▉   | 593/859 [10:53<04:31,  1.02s/it]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1374138
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1374138
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1374138
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 69%|██████▉   | 594/859 [10:54<04:26,  1.00s/it]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=228990
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=228990
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=228990
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=511439
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=511439
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=511439
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 69%|██████▉   | 596/859 [10:55<03:58,  1.10it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=511410
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=511410
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=511410
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 69%|██████▉   | 597/859 [10:56<04:05,  1.07it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1321405
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1321405
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1321405
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|██████▉   | 598/859 [10:58<04:19,  1.00it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1536262
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1536262
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1536262
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|██████▉   | 599/859 [10:59<04:16,  1.01it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1111156
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1111156
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1111156
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|██████▉   | 600/859 [11:00<04:26,  1.03s/it]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1118621
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1118621
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1118621
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|██████▉   | 601/859 [11:00<03:14,  1.33it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1463678
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1463678
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1463678
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|███████   | 602/859 [11:01<03:29,  1.23it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1565139
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1565139
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1565139
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|███████   | 603/859 [11:01<02:33,  1.67it/s]INFO:__main__:Requesting https://iterable.com/company/job/?gh_jid=1451971
INFO:__main__:Getting metadata for https://iterable.com/company/job/?gh_jid=1451971
ERROR:__main__:Could not get metadata for https://iterable.com/company/job/?gh_jid=1451971
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
INFO:__main__:Requesting https://grnh.se/5363f6b61
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1276367?gh_jid=1276367&gh_src=5363f6b61
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1276367?gh_jid=1276367&gh_src=5363f6b61
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 70%|███████   | 605/859 [11:02<02:39,  1.59it/s]INFO:__main__:Requesting https://grnh.se/c7a1b74f1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1440108?gh_jid=1440108&gh_src=c7a1b74f1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1440108?gh_jid=1440108&gh_src=c7a1b74f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 606/859 [11:03<03:28,  1.22it/s]INFO:__main__:Requesting https://grnh.se/3f67a13d1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1440097?gh_jid=1440097&gh_src=3f67a13d1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1440097?gh_jid=1440097&gh_src=3f67a13d1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 607/859 [11:05<03:49,  1.10it/s]INFO:__main__:Requesting https://grnh.se/c37a43151
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1510047?gh_jid=1510047&gh_src=c37a43151
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1510047?gh_jid=1510047&gh_src=c37a43151
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 608/859 [11:06<04:29,  1.08s/it]INFO:__main__:Requesting https://grnh.se/6c2ba6b11
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173542?gh_jid=1173542&gh_src=6c2ba6b11
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173542?gh_jid=1173542&gh_src=6c2ba6b11
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 609/859 [11:07<04:30,  1.08s/it]INFO:__main__:Requesting https://grnh.se/a4c0a8731
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173581?gh_jid=1173581&gh_src=a4c0a8731
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173581?gh_jid=1173581&gh_src=a4c0a8731
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 610/859 [11:08<04:34,  1.10s/it]INFO:__main__:Requesting https://grnh.se/b8fefccb1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1505260?gh_jid=1505260&gh_src=b8fefccb1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1505260?gh_jid=1505260&gh_src=b8fefccb1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 611/859 [11:09<04:34,  1.11s/it]INFO:__main__:Requesting https://grnh.se/d7514f0c1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173526?gh_jid=1173526&gh_src=d7514f0c1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173526?gh_jid=1173526&gh_src=d7514f0c1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████   | 612/859 [11:11<04:58,  1.21s/it]INFO:__main__:Requesting https://grnh.se/d7ca9c1f1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173588?gh_jid=1173588&gh_src=d7ca9c1f1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173588?gh_jid=1173588&gh_src=d7ca9c1f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████▏  | 613/859 [11:12<04:51,  1.18s/it]INFO:__main__:Requesting https://grnh.se/1d737c291
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173565?gh_jid=1173565&gh_src=1d737c291
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173565?gh_jid=1173565&gh_src=1d737c291
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 71%|███████▏  | 614/859 [11:13<05:08,  1.26s/it]INFO:__main__:Requesting https://grnh.se/db1fe84f1
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173605?gh_jid=1173605&gh_src=db1fe84f1
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173605?gh_jid=1173605&gh_src=db1fe84f1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 72%|███████▏  | 615/859 [11:15<04:54,  1.21s/it]INFO:__main__:Requesting https://grnh.se/df42e0021
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173515?gh_jid=1173515&gh_src=df42e0021
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173515?gh_jid=1173515&gh_src=df42e0021
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 72%|███████▏  | 616/859 [11:16<04:54,  1.21s/it]INFO:__main__:Requesting https://grnh.se/196c74d81
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173551?gh_jid=1173551&gh_src=196c74d81
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173551?gh_jid=1173551&gh_src=196c74d81
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 72%|███████▏  | 617/859 [11:17<04:44,  1.18s/it]INFO:__main__:Requesting https://grnh.se/04c41e691
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173601?gh_jid=1173601&gh_src=04c41e691
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173601?gh_jid=1173601&gh_src=04c41e691
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 72%|███████▏  | 618/859 [11:18<04:42,  1.17s/it]INFO:__main__:Requesting https://grnh.se/5ced83341
INFO:__main__:Getting metadata for https://www.hioscar.com/careers/1173574?gh_jid=1173574&gh_src=5ced83341
ERROR:__main__:Could not get metadata for https://www.hioscar.com/careers/1173574?gh_jid=1173574&gh_src=5ced83341
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 72%|███████▏  | 619/859 [11:19<04:44,  1.19s/it]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/director-of-engineering-editorial-experience-czdJ-Yl7ar6ANxcR_n82lY?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/director-of-engineering-editorial-experience-czdJ-Yl7ar6ANxcR_n82lY?ref=rss&sid=68
 72%|███████▏  | 620/859 [11:20<03:58,  1.00it/s]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/software-engineer-ecommerce-cM-GPUfpar6BIhdUfHqP9G?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/software-engineer-ecommerce-cM-GPUfpar6BIhdUfHqP9G?ref=rss&sid=68
 72%|███████▏  | 621/859 [11:20<03:19,  1.19it/s]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/software-engineer-subscriptions-dzTa3YgcGr6AkBeUHD3cl-?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/software-engineer-subscriptions-dzTa3YgcGr6AkBeUHD3cl-?ref=rss&sid=68
 72%|███████▏  | 622/859 [11:21<02:55,  1.35it/s]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/devops-engineer-d-A7HMI1Sr6kIvdG1ZS6tF?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/devops-engineer-d-A7HMI1Sr6kIvdG1ZS6tF?ref=rss&sid=68
 73%|███████▎  | 623/859 [11:21<02:43,  1.45it/s]INFO:__main__:Requesting https://careers.jobscore.com/careers/businessinsider/jobs/release-engineer-byijqWI1Wr6kIvdG1ZS6tF?ref=rss&sid=68
INFO:__main__:Getting metadata for https://careers.jobscore.com/careers/businessinsider/jobs/release-engineer-byijqWI1Wr6kIvdG1ZS6tF?ref=rss&sid=68
 73%|███████▎  | 624/859 [11:22<02:38,  1.48it/s]INFO:__main__:Requesting https://www.insider-inc.com/careers#careers-open-roles
INFO:__main__:Getting metadata for https://www.insider-inc.com/careers#careers-open-roles
ERROR:__main__:Could not get metadata for https://www.insider-inc.com/careers#careers-open-roles
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 73%|███████▎  | 625/859 [11:23<02:29,  1.56it/s]INFO:__main__:Requesting https://www.keyvalues.com
INFO:__main__:Getting metadata for https://www.keyvalues.com
 73%|███████▎  | 626/859 [11:25<04:45,  1.23s/it]INFO:__main__:Requesting https://www.transparentcareer.com
INFO:__main__:Getting metadata for https://www.transparentcareer.com
 73%|███████▎  | 627/859 [11:26<03:51,  1.00it/s]INFO:__main__:Requesting https://codewithoutrules.com/2019/01/31/does-company-have-worklife-balance/
INFO:__main__:Getting metadata for https://codewithoutrules.com/2019/01/31/does-company-have-worklife-balance/
 73%|███████▎  | 628/859 [11:26<02:55,  1.32it/s]INFO:__main__:Requesting https://levels.fyi
INFO:__main__:Getting metadata for https://www.levels.fyi
 73%|███████▎  | 629/859 [11:26<02:30,  1.53it/s]INFO:__main__:Requesting https://last10k.com
ERROR:__main__:Could not reach https://last10k.com
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 73%|███████▎  | 630/859 [11:26<01:57,  1.95it/s]INFO:__main__:Requesting https://www.kununu.com/
INFO:__main__:Getting metadata for https://www.kununu.com/us
 73%|███████▎  | 631/859 [11:30<05:05,  1.34s/it]INFO:__main__:Requesting http://re2c.org/
INFO:__main__:Getting metadata for http://re2c.org
 74%|███████▎  | 632/859 [11:30<04:05,  1.08s/it]INFO:__main__:Requesting https://github.com/ninja-build/ninja/blob/master/src/lexer.in.cc#L123
INFO:__main__:Getting metadata for https://github.com/ninja-build/ninja/blob/master/src/lexer.in.cc#L123
 74%|███████▎  | 633/859 [11:31<03:59,  1.06s/it]INFO:__main__:Requesting http://www.oilshell.org/blog/2017/12/15.html
INFO:__main__:Getting metadata for http://www.oilshell.org/blog/2017/12/15.html
ERROR:__main__:Could not get metadata for http://www.oilshell.org/blog/2017/12/15.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 74%|███████▍  | 634/859 [11:32<03:19,  1.13it/s]INFO:__main__:Requesting https://megous.com/git/sjson/tree/sjson.c
INFO:__main__:Getting metadata for https://megous.com/git/sjson/tree/sjson.c
ERROR:__main__:Could not get metadata for https://megous.com/git/sjson/tree/sjson.c
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 74%|███████▍  | 635/859 [11:38<09:08,  2.45s/it]INFO:__main__:Requesting https://github.com/cjohansson/emacs-phps-mode/blob/master/phps-mode-lexer.el
INFO:__main__:Getting metadata for https://github.com/cjohansson/emacs-phps-mode/blob/master/phps-mode-lexer.el
 74%|███████▍  | 636/859 [11:39<07:57,  2.14s/it]INFO:__main__:Requesting https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/net/URL.re?at=prefetch&fileviewer=file-view-default#URL.re-106
INFO:__main__:Getting metadata for https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/net/URL.re?at=prefetch&fileviewer=file-view-default#URL.re-106
ERROR:__main__:Could not get metadata for https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/net/URL.re?at=prefetch&fileviewer=file-view-default#URL.re-106
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 74%|███████▍  | 637/859 [11:42<08:53,  2.40s/it]INFO:__main__:Requesting https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/system/Time.re?at=prefetch&fileviewer=file-view-default#Time.re-168
INFO:__main__:Getting metadata for https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/system/Time.re?at=prefetch&fileviewer=file-view-default#Time.re-168
ERROR:__main__:Could not get metadata for https://bitbucket.org/tildeslash/libzdb/src/9402bd5757d1db346b71489439dfc005dd464971/src/system/Time.re?at=prefetch&fileviewer=file-view-default#Time.re-168
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 74%|███████▍  | 638/859 [11:45<09:51,  2.67s/it]INFO:__main__:Requesting https://externals.io/message/102796
INFO:__main__:Getting metadata for https://externals.io/message/102796
 74%|███████▍  | 639/859 [11:49<11:11,  3.05s/it]INFO:__main__:Requesting https://github.com/php/php-src/blob/master/Zend/zend_language_scanner.l
INFO:__main__:Getting metadata for https://github.com/php/php-src/blob/master/Zend/zend_language_scanner.l
 75%|███████▍  | 640/859 [11:51<09:27,  2.59s/it]INFO:__main__:Requesting http://sourceware.org/git/gitweb.cgi?p=systemtap.git;a=blob;f=README.stapregex
INFO:__main__:Getting metadata for http://sourceware.org/git/gitweb.cgi?p=systemtap.git;a=blob;f=README.stapregex
ERROR:__main__:Could not get metadata for http://sourceware.org/git/gitweb.cgi?p=systemtap.git;a=blob;f=README.stapregex
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 75%|███████▍  | 641/859 [11:52<08:01,  2.21s/it]INFO:__main__:Requesting https://github.com/fbb-git/flexcpp
INFO:__main__:Getting metadata for https://github.com/fbb-git/flexcpp
 75%|███████▍  | 642/859 [11:53<06:24,  1.77s/it]INFO:__main__:Requesting https://github.com/fbb-git/bisoncpp
INFO:__main__:Getting metadata for https://github.com/fbb-git/bisoncpp
 75%|███████▍  | 643/859 [11:54<05:19,  1.48s/it]INFO:__main__:Requesting http://www.colm.net/open-source/ragel/
INFO:__main__:Getting metadata for http://www.colm.net/open-source/ragel/
 75%|███████▍  | 644/859 [11:54<04:07,  1.15s/it]INFO:__main__:Requesting http://abovethecrowd.com/2019/02/27/money-out-of-nowhere-how-internet-marketplaces-unlock-economic-wealth/
INFO:__main__:Getting metadata for http://abovethecrowd.com/2019/02/27/money-out-of-nowhere-how-internet-marketplaces-unlock-economic-wealth/
 75%|███████▌  | 645/859 [11:54<03:03,  1.17it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Comparative_advantage#Criticism
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Comparative_advantage#Criticism
 75%|███████▌  | 646/859 [11:56<04:06,  1.16s/it]INFO:__main__:Requesting https://creatorsneverdie.com/blog/item?q=the-cost-of-developing-native-hyrbid-progressive-web-apps
INFO:__main__:Getting metadata for https://creatorsneverdie.com/blog/item?q=the-cost-of-developing-native-hyrbid-progressive-web-apps
ERROR:__main__:Could not get metadata for https://creatorsneverdie.com/blog/item?q=the-cost-of-developing-native-hyrbid-progressive-web-apps
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 75%|███████▌  | 647/859 [11:57<03:28,  1.02it/s]INFO:__main__:Requesting https://www.sqlite.org/json1.html
INFO:__main__:Getting metadata for https://www.sqlite.org/json1.html
 75%|███████▌  | 648/859 [11:57<03:12,  1.10it/s]INFO:__main__:Requesting https://docs.sqlalchemy.org/en/latest/dialects/sqlite.html#pysqlite-serializable
INFO:__main__:Getting metadata for https://docs.sqlalchemy.org/en/latest/dialects/sqlite.html#pysqlite-serializable
 76%|███████▌  | 649/859 [12:00<04:32,  1.30s/it]INFO:__main__:Requesting https://github.com/rgov/sqlite_protobuf
INFO:__main__:Getting metadata for https://github.com/rgov/sqlite_protobuf
 76%|███████▌  | 650/859 [12:00<03:55,  1.13s/it]INFO:__main__:Requesting https://burrows.svbtle.com/build-sqlite-json1-extension-as-shared-library-on-os-x
INFO:__main__:Getting metadata for https://burrows.svbtle.com/build-sqlite-json1-extension-as-shared-library-on-os-x
 76%|███████▌  | 651/859 [12:01<03:08,  1.10it/s]INFO:__main__:Requesting https://redisql.com/
INFO:__main__:Getting metadata for https://redisql.com
 76%|███████▌  | 652/859 [12:01<02:43,  1.27it/s]INFO:__main__:Requesting http://redbeardlab.tech/rediSQL/blog/JaaS/
INFO:__main__:Getting metadata for http://redbeardlab.tech/rediSQL/blog/JaaS/
 76%|███████▌  | 653/859 [12:02<02:21,  1.46it/s]INFO:__main__:Requesting http://redbeardlab.tech/rediSQL/blog/golang/using-redisql-with-golang/
INFO:__main__:Getting metadata for http://redbeardlab.tech/rediSQL/blog/golang/using-redisql-with-golang/
 76%|███████▌  | 654/859 [12:02<02:01,  1.69it/s]INFO:__main__:Requesting https://blog.budgetwithbuckets.com/2018/08/27/sqlite-changelog.html
INFO:__main__:Getting metadata for https://blog.budgetwithbuckets.com/2018/08/27/sqlite-changelog.html
 76%|███████▋  | 655/859 [12:03<01:56,  1.74it/s]INFO:__main__:Requesting https://www.sqlite.org/expridx.html
INFO:__main__:Getting metadata for https://www.sqlite.org/expridx.html
 76%|███████▋  | 656/859 [12:03<01:49,  1.85it/s]INFO:__main__:Requesting https://www.postgresql.org/docs/9.1/arrays.html
INFO:__main__:Getting metadata for https://www.postgresql.org/docs/9.1/arrays.html
 76%|███████▋  | 657/859 [12:06<04:01,  1.20s/it]INFO:__main__:Requesting https://github.com/coast-framework/lighthouse/blob/master/README.md#pull-queries
INFO:__main__:Getting metadata for https://github.com/coast-framework/lighthouse/blob/master/README.md#pull-queries
 77%|███████▋  | 658/859 [12:07<03:34,  1.07s/it]INFO:__main__:Requesting https://modern-sql.com/blog/2017-06/whats-new-in-sql-2016
INFO:__main__:Getting metadata for https://modern-sql.com/blog/2017-06/whats-new-in-sql-2016
 77%|███████▋  | 659/859 [12:08<03:50,  1.15s/it]INFO:__main__:Requesting https://commitfest.postgresql.org/17/1471/
INFO:__main__:Getting metadata for https://commitfest.postgresql.org/17/1471/
ERROR:__main__:Could not get metadata for https://commitfest.postgresql.org/17/1471/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 77%|███████▋  | 660/859 [12:09<04:08,  1.25s/it]INFO:__main__:Requesting https://commitfest.postgresql.org/17/1472/
INFO:__main__:Getting metadata for https://commitfest.postgresql.org/17/1472/
ERROR:__main__:Could not get metadata for https://commitfest.postgresql.org/17/1472/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 77%|███████▋  | 661/859 [12:11<04:14,  1.28s/it]INFO:__main__:Requesting https://commitfest.postgresql.org/17/1473/
INFO:__main__:Getting metadata for https://commitfest.postgresql.org/17/1473/
ERROR:__main__:Could not get metadata for https://commitfest.postgresql.org/17/1473/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 77%|███████▋  | 662/859 [12:12<04:21,  1.33s/it]INFO:__main__:Requesting https://obartunov.livejournal.com/200076.html
INFO:__main__:Getting metadata for https://obartunov.livejournal.com/200076.html
 77%|███████▋  | 663/859 [12:15<05:32,  1.69s/it]INFO:__main__:Requesting https://www.postgresql.org/message-id/CAF4Au4w2x-5LTnN_bxky-mq4=WOqsGsxSpENCzHRAzSnEd8+WQ@mail.gmail.com
INFO:__main__:Getting metadata for https://www.postgresql.org/message-id/CAF4Au4w2x-5LTnN_bxky-mq4=WOqsGsxSpENCzHRAzSnEd8+WQ@mail.gmail.com
 77%|███████▋  | 664/859 [12:18<06:45,  2.08s/it]INFO:__main__:Requesting https://www.postgresql.org/message-id/00531c7e-f501-b852-9b67-1d1278d035a0%40pgmasters.net
INFO:__main__:Getting metadata for https://www.postgresql.org/message-id/00531c7e-f501-b852-9b67-1d1278d035a0%40pgmasters.net
 77%|███████▋  | 665/859 [12:20<07:20,  2.27s/it]INFO:__main__:Requesting https://www.postgresql.org/message-id/a3be6a7a-77d3-0e88-4f9d-4f725d11d7cd%40postgrespro.ru
INFO:__main__:Getting metadata for https://www.postgresql.org/message-id/a3be6a7a-77d3-0e88-4f9d-4f725d11d7cd%40postgrespro.ru
 78%|███████▊  | 666/859 [12:24<08:16,  2.57s/it]INFO:__main__:Requesting https://www.postgresql.org/message-id/c2f32c9f-9a69-202b-a8aa-d93c769a579e%40postgrespro.ru
INFO:__main__:Getting metadata for https://www.postgresql.org/message-id/c2f32c9f-9a69-202b-a8aa-d93c769a579e%40postgrespro.ru
 78%|███████▊  | 667/859 [12:27<08:48,  2.75s/it]INFO:__main__:Requesting https://standards.iso.org/ittf/PubliclyAvailableStandards/
INFO:__main__:Getting metadata for https://standards.iso.org/ittf/PubliclyAvailableStandards/
 78%|███████▊  | 668/859 [12:35<14:15,  4.48s/it]INFO:__main__:Requesting https://www.sqlite.org/onefile.html
INFO:__main__:Getting metadata for https://www.sqlite.org/onefile.html
ERROR:__main__:Could not get metadata for https://www.sqlite.org/onefile.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 78%|███████▊  | 669/859 [12:36<10:21,  3.27s/it]INFO:__main__:Requesting https://github.com/requery/sqlite-android
INFO:__main__:Getting metadata for https://github.com/requery/sqlite-android
 78%|███████▊  | 670/859 [12:37<08:26,  2.68s/it]INFO:__main__:Requesting https://research.swtch.com/tlog
INFO:__main__:Getting metadata for https://research.swtch.com/tlog
 78%|███████▊  | 671/859 [12:38<06:26,  2.06s/it]INFO:__main__:Requesting https://github.com/mafintosh/hypercore
INFO:__main__:Getting metadata for https://github.com/mafintosh/hypercore
 78%|███████▊  | 672/859 [12:39<05:21,  1.72s/it]INFO:__main__:Requesting https://www.datprotocol.com/
INFO:__main__:Getting metadata for https://www.datprotocol.com
 78%|███████▊  | 673/859 [12:40<04:34,  1.47s/it]INFO:__main__:Requesting https://datprotocol.github.io/how-dat-works/
INFO:__main__:Getting metadata for https://datprotocol.github.io/how-dat-works/
 78%|███████▊  | 674/859 [12:40<03:58,  1.29s/it]INFO:__main__:Requesting https://github.com/datrs/hypercore
INFO:__main__:Getting metadata for https://github.com/datrs/hypercore
 79%|███████▊  | 675/859 [12:41<03:29,  1.14s/it]INFO:__main__:Requesting https://www.wsj.com/articles/pg-e-records-10-5-billion-charge-related-to-camp-fire-11551363969
INFO:__main__:Getting metadata for https://www.wsj.com/articles/pg-e-records-10-5-billion-charge-related-to-camp-fire-11551363969
 79%|███████▊  | 676/859 [12:42<03:29,  1.15s/it]INFO:__main__:Requesting https://arstechnica.com/information-technology/2019/02/pge-its-likely-our-equipment-was-ignition-point-for-deadly-camp-fire/
INFO:__main__:Getting metadata for https://arstechnica.com/information-technology/2019/02/pge-its-likely-our-equipment-was-ignition-point-for-deadly-camp-fire/
 79%|███████▉  | 677/859 [12:43<02:43,  1.11it/s]INFO:__main__:Requesting https://www.wsj.com/articles/pg-e-delayed-safety-work-on-power-line-that-is-prime-suspect-in-california-wildfire-11551292977?mod=hp_lead_pos5&mod=article_inline
INFO:__main__:Getting metadata for https://www.wsj.com/articles/pg-e-delayed-safety-work-on-power-line-that-is-prime-suspect-in-california-wildfire-11551292977?mod=hp_lead_pos5&mod=article_inline
 79%|███████▉  | 678/859 [12:43<02:22,  1.27it/s]INFO:__main__:Requesting https://blog.littlevgl.com/2019-02-20/micropython-bindings
INFO:__main__:Getting metadata for https://blog.littlevgl.com/2019-02-20/micropython-bindings
 79%|███████▉  | 679/859 [12:44<01:56,  1.54it/s]INFO:__main__:Requesting https://github.com/littlevgl/lvgl/graphs/code-frequency
INFO:__main__:Getting metadata for https://github.com/littlevgl/lvgl/graphs/code-frequency
 79%|███████▉  | 680/859 [12:44<01:59,  1.50it/s]INFO:__main__:Requesting http://www.bbc.com/travel/story/20190228-athens-bizarre-underground-phenomenon
INFO:__main__:Getting metadata for http://www.bbc.com/travel/story/20190228-athens-bizarre-underground-phenomenon
 79%|███████▉  | 681/859 [12:45<01:58,  1.51it/s]INFO:__main__:Requesting https://techcrunch.com/2019/02/28/facebook-research-teens/
ERROR:__main__:Could not reach https://techcrunch.com/2019/02/28/facebook-research-teens/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 79%|███████▉  | 682/859 [12:45<01:28,  2.00it/s]INFO:__main__:Requesting https://github.com/Microsoft/nni
INFO:__main__:Getting metadata for https://github.com/Microsoft/nni
 80%|███████▉  | 683/859 [12:47<02:28,  1.18it/s]INFO:__main__:Requesting https://arxiv.org/abs/1902.07638
INFO:__main__:Getting metadata for https://arxiv.org/abs/1902.07638
 80%|███████▉  | 684/859 [12:48<02:43,  1.07it/s]INFO:__main__:Requesting https://nni.readthedocs.io/en/latest/gbdt_example.html
INFO:__main__:Getting metadata for https://nni.readthedocs.io/en/latest/gbdt_example.html
 80%|███████▉  | 685/859 [12:49<02:49,  1.03it/s]INFO:__main__:Requesting https://github.com/polyaxon/polyaxon#hyperparameters-tuning
INFO:__main__:Getting metadata for https://github.com/polyaxon/polyaxon#hyperparameters-tuning
 80%|███████▉  | 686/859 [12:50<02:57,  1.03s/it]INFO:__main__:Requesting https://nni.readthedocs.io/en/latest/sklearn_examples.html
INFO:__main__:Getting metadata for https://nni.readthedocs.io/en/latest/sklearn_examples.html
 80%|███████▉  | 687/859 [12:51<02:54,  1.01s/it]INFO:__main__:Requesting https://github.com/EpistasisLab/tpot
INFO:__main__:Getting metadata for https://github.com/EpistasisLab/tpot
 80%|████████  | 688/859 [12:52<02:58,  1.05s/it]INFO:__main__:Requesting https://github.com/automl/auto-sklearn
INFO:__main__:Getting metadata for https://github.com/automl/auto-sklearn
 80%|████████  | 689/859 [12:53<02:49,  1.00it/s]INFO:__main__:Requesting https://www.technologyreview.com/lists/technologies/2019/
INFO:__main__:Getting metadata for https://www.technologyreview.com/lists/technologies/2019/
 80%|████████  | 690/859 [12:55<03:36,  1.28s/it]INFO:__main__:Requesting https://www.wsj.com/articles/know-it-all-robot-shuts-down-dubious-family-texts-11551370040
INFO:__main__:Getting metadata for https://www.wsj.com/articles/know-it-all-robot-shuts-down-dubious-family-texts-11551370040
 80%|████████  | 691/859 [12:56<03:00,  1.07s/it]INFO:__main__:Requesting https://outline.com/https://www.wsj.com/articles/know-it-all-robot-shuts-down-dubious-family-texts-11551370040
INFO:__main__:Getting metadata for https://outline.com/https://www.wsj.com/articles/know-it-all-robot-shuts-down-dubious-family-texts-11551370040
 81%|████████  | 692/859 [12:57<03:04,  1.10s/it]INFO:__main__:Requesting https://i.kym-cdn.com/photos/images/newsfeed/001/191/035/135.png
INFO:__main__:Getting metadata for https://i.kym-cdn.com/photos/images/newsfeed/001/191/035/135.png
ERROR:__main__:Could not get metadata for https://i.kym-cdn.com/photos/images/newsfeed/001/191/035/135.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 81%|████████  | 693/859 [13:01<05:37,  2.03s/it]INFO:__main__:Requesting https://www.riskology.co/idea-guy/
ERROR:__main__:Could not reach https://www.riskology.co/idea-guy/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.riskology.co', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.riskology.co', port=443): Read timed out. (read timeout=6)
 81%|████████  | 694/859 [13:07<09:00,  3.27s/it]INFO:__main__:Requesting https://en.m.wikipedia.org/wiki/Project_Habakkuk
INFO:__main__:Getting metadata for https://en.m.wikipedia.org/wiki/Project_Habakkuk
 81%|████████  | 695/859 [13:08<07:14,  2.65s/it]INFO:__main__:Requesting https://www.ecowatch.com/epa-fracking-water-contamination-2144968213.html
INFO:__main__:Getting metadata for https://www.ecowatch.com/epa-fracking-water-contamination-2144968213.html
 81%|████████  | 696/859 [13:11<06:56,  2.56s/it]INFO:__main__:Requesting https://articulu.com
INFO:__main__:Getting metadata for https://articulu.com
 81%|████████  | 697/859 [13:12<05:27,  2.02s/it]INFO:__main__:Requesting https://www.narro.co
INFO:__main__:Getting metadata for https://www.narro.co
 81%|████████▏ | 698/859 [13:12<04:13,  1.58s/it]INFO:__main__:Requesting https://webcache.googleusercontent.com/search?q=cache:https://www.riskology.co/idea-guy/
INFO:__main__:Getting metadata for https://webcache.googleusercontent.com/search?q=cache:https://www.riskology.co/idea-guy/
 81%|████████▏ | 699/859 [13:13<03:48,  1.43s/it]INFO:__main__:Requesting https://www.dictionary.com/browse/monday-morning-quarterback
INFO:__main__:Getting metadata for https://www.dictionary.com/browse/monday-morning-quarterback
ERROR:__main__:Could not get metadata for https://www.dictionary.com/browse/monday-morning-quarterback
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 81%|████████▏ | 700/859 [13:13<02:47,  1.06s/it]INFO:__main__:Requesting https://spectrum.ieee.org/consumer-electronics/gadgets/the-story-behind-the-blackberry-case
INFO:__main__:Getting metadata for https://spectrum.ieee.org/consumer-electronics/gadgets/the-story-behind-the-blackberry-case
 82%|████████▏ | 701/859 [13:16<04:14,  1.61s/it]INFO:__main__:Requesting https://www.theregister.co.uk/2007/01/06/broadcom_csr_bluetooth_lawsuit/
INFO:__main__:Getting metadata for https://www.theregister.co.uk/2007/01/06/broadcom_csr_bluetooth_lawsuit/
 82%|████████▏ | 702/859 [13:17<03:22,  1.29s/it]INFO:__main__:Requesting https://medium.com/@donhopkins/pie-menu-timeline-21bec9b21620
INFO:__main__:Getting metadata for https://medium.com/@donhopkins/pie-menu-timeline-21bec9b21620
 82%|████████▏ | 703/859 [13:18<03:24,  1.31s/it]INFO:__main__:Requesting https://sivers.org/multiply
INFO:__main__:Getting metadata for https://sivers.org/multiply
 82%|████████▏ | 704/859 [13:18<02:40,  1.03s/it]INFO:__main__:Requesting https://web.archive.org/web/20190301181528/https://www.riskology.co/idea-guy/
INFO:__main__:Getting metadata for https://web.archive.org/web/20190301181528/https://www.riskology.co/idea-guy/
 82%|████████▏ | 705/859 [13:19<02:31,  1.02it/s]INFO:__main__:Requesting https://m.youtube.com/watch?v=DkGMY63FF3Q
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=DkGMY63FF3Q&app=desktop
 82%|████████▏ | 706/859 [13:21<02:37,  1.03s/it]INFO:__main__:Requesting https://beta.trimread.com/articles/207
INFO:__main__:Getting metadata for https://beta.trimread.com/articles/207
ERROR:__main__:Could not get metadata for https://beta.trimread.com/articles/207
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 82%|████████▏ | 707/859 [13:21<02:11,  1.16it/s]INFO:__main__:Requesting https://web.archive.org/web/20171016173743/https://www.riskology.co/idea-guy/
ERROR:__main__:Could not reach https://web.archive.org/web/20171016173743/https://www.riskology.co/idea-guy/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 80, in create_connection
    raise err
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 70, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 301, in connect
    conn = self._new_conn()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 164, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0e7c7da978>, 'Connection to web.archive.org timed out. (connect timeout=6)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='web.archive.org', port=443): Max retries exceeded with url: /web/20171016173743/https://www.riskology.co/idea-guy/ (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0e7c7da978>, 'Connection to web.archive.org timed out. (connect timeout=6)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 504, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='web.archive.org', port=443): Max retries exceeded with url: /web/20171016173743/https://www.riskology.co/idea-guy/ (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0e7c7da978>, 'Connection to web.archive.org timed out. (connect timeout=6)'))
 82%|████████▏ | 708/859 [13:27<06:03,  2.41s/it]INFO:__main__:Requesting https://www.reuters.com/article/us-usa-economy-spenidng/u-s-personal-income-posts-first-drop-in-over-three-years-idUSKCN1QI4P7
INFO:__main__:Getting metadata for https://www.reuters.com/article/us-usa-economy-spenidng/u-s-personal-income-posts-first-drop-in-over-three-years-idUSKCN1QI4P7
 83%|████████▎ | 709/859 [13:27<04:25,  1.77s/it]INFO:__main__:Requesting https://fred.stlouisfed.org/series/WCURCIR
INFO:__main__:Getting metadata for https://fred.stlouisfed.org/series/WCURCIR
ERROR:__main__:Could not get metadata for https://fred.stlouisfed.org/series/WCURCIR
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 83%|████████▎ | 710/859 [13:28<03:19,  1.34s/it]INFO:__main__:Requesting https://www.thebalance.com/who-owns-the-u-s-national-debt-3306124
INFO:__main__:Getting metadata for https://www.thebalance.com/who-owns-the-u-s-national-debt-3306124
 83%|████████▎ | 711/859 [13:28<02:38,  1.07s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Made_in_China_2025
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Made_in_China_2025
 83%|████████▎ | 712/859 [13:29<02:44,  1.12s/it]INFO:__main__:Requesting https://www.statista.com/statistics/631244/voter-turnout-of-the-exit-polls-of-the-2016-elections-by-income/
INFO:__main__:Getting metadata for https://www.statista.com/statistics/631244/voter-turnout-of-the-exit-polls-of-the-2016-elections-by-income/
 83%|████████▎ | 713/859 [13:30<02:22,  1.03it/s]INFO:__main__:Requesting https://www.washingtonpost.com/news/monkey-cage/wp/2017/06/05/its-time-to-bust-the-myth-most-trump-voters-were-not-working-class/?noredirect=on&utm_term=.8bab332bf87c
ERROR:__main__:Could not reach https://www.washingtonpost.com/news/monkey-cage/wp/2017/06/05/its-time-to-bust-the-myth-most-trump-voters-were-not-working-class/?noredirect=on&utm_term=.8bab332bf87c
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)
 83%|████████▎ | 714/859 [13:36<06:02,  2.50s/it]INFO:__main__:Requesting http://www.people-press.org/2018/08/09/an-examination-of-the-2016-electorate-based-on-validated-voters/
INFO:__main__:Getting metadata for http://www.people-press.org/2018/08/09/an-examination-of-the-2016-electorate-based-on-validated-voters/
 83%|████████▎ | 715/859 [13:36<04:21,  1.82s/it]INFO:__main__:Requesting https://www1.salary.com/Jeffrey-P-Bezos-Salary-Bonus-Stock-Options-for-Amazon-Com-Inc.html
INFO:__main__:Getting metadata for https://www1.salary.com/Jeffrey-P-Bezos-Salary-Bonus-Stock-Options-for-Amazon-Com-Inc.html
 83%|████████▎ | 716/859 [13:37<03:42,  1.55s/it]INFO:__main__:Requesting http://www.esa.int/Our_Activities/Space_Science/Mars_Express/First_evidence_of_planet-wide_groundwater_system_on_Mars
INFO:__main__:Getting metadata for http://www.esa.int/Our_Activities/Space_Science/Mars_Express/First_evidence_of_planet-wide_groundwater_system_on_Mars
 83%|████████▎ | 717/859 [13:37<02:39,  1.12s/it]INFO:__main__:Requesting https://www.brainpickings.org/2017/10/17/richard-feynman-arline-letter/
INFO:__main__:Getting metadata for https://www.brainpickings.org/2017/10/17/richard-feynman-arline-letter/
 84%|████████▎ | 718/859 [13:38<02:18,  1.02it/s]INFO:__main__:Requesting https://www.researchgate.net/figure/Crude-death-rates-for-tuberculosis-in-the-United-States-1900-2014-Note-that-with-the_fig1_307084755
 84%|████████▎ | 719/859 [13:38<01:46,  1.32it/s]INFO:__main__:Requesting https://philosophicaldisquisitions.blogspot.com/2014/09/steven-pinkers-guide-to-classic-style.html
INFO:__main__:Getting metadata for https://philosophicaldisquisitions.blogspot.com/2014/09/steven-pinkers-guide-to-classic-style.html
 84%|████████▍ | 720/859 [13:39<01:38,  1.42it/s]INFO:__main__:Requesting http://web.cs.ucla.edu/~palsberg/shivers.html
INFO:__main__:Getting metadata for http://web.cs.ucla.edu/~palsberg/shivers.html
 84%|████████▍ | 721/859 [13:39<01:27,  1.57it/s]INFO:__main__:Requesting https://www.universityofcalifornia.edu/press-room/uc-terminates-subscriptions-worlds-largest-scientific-publisher-push-open-access-publicly
INFO:__main__:Getting metadata for https://www.universityofcalifornia.edu/press-room/uc-terminates-subscriptions-worlds-largest-scientific-publisher-push-open-access-publicly
 84%|████████▍ | 722/859 [13:39<01:11,  1.93it/s]INFO:__main__:Requesting https://www.theguardian.com/science/2012/apr/24/harvard-university-journal-publishers-prices
INFO:__main__:Getting metadata for https://www.theguardian.com/science/2012/apr/24/harvard-university-journal-publishers-prices
 84%|████████▍ | 723/859 [13:40<01:05,  2.09it/s]INFO:__main__:Requesting https://www.projekt-deal.de/vertragskundigungen-elsevier-2018/
INFO:__main__:Getting metadata for https://www.projekt-deal.de/vertragskundigungen-elsevier-2018/
 84%|████████▍ | 724/859 [13:46<05:13,  2.32s/it]INFO:__main__:Requesting https://www.projekt-deal.de/
INFO:__main__:Getting metadata for https://www.projekt-deal.de
 84%|████████▍ | 725/859 [13:53<08:05,  3.62s/it]INFO:__main__:Requesting https://controller.berkeley.edu/home/uc-berkeley-financial-reports
INFO:__main__:Getting metadata for https://controller.berkeley.edu/home/uc-berkeley-financial-reports
 85%|████████▍ | 726/859 [13:54<06:28,  2.92s/it]INFO:__main__:Requesting https://www.quora.com/What-is-the-cost-for-a-university-subscription-to-the-entire-Elsevier-database-with-unlimited-views-and-downloads-for-an-academic-year
INFO:__main__:Getting metadata for https://www.quora.com/What-is-the-cost-for-a-university-subscription-to-the-entire-Elsevier-database-with-unlimited-views-and-downloads-for-an-academic-year
 85%|████████▍ | 727/859 [13:57<06:09,  2.80s/it]INFO:__main__:Requesting https://pages.github.berkeley.edu/OPA/our-berkeley/enroll-history.html
INFO:__main__:Getting metadata for https://pages.github.berkeley.edu/OPA/our-berkeley/enroll-history.html
ERROR:__main__:Could not get metadata for https://pages.github.berkeley.edu/OPA/our-berkeley/enroll-history.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 85%|████████▍ | 728/859 [13:58<05:01,  2.30s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=pgUA1tluVmE
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=pgUA1tluVmE
 85%|████████▍ | 729/859 [13:59<04:02,  1.87s/it]INFO:__main__:Requesting https://sci-hub.tw/donate
INFO:__main__:Getting metadata for https://sci-hub.tw/donate
 85%|████████▍ | 730/859 [14:06<07:38,  3.56s/it]INFO:__main__:Requesting https://chorasimilarity.wordpress.com/2019/02/28/google-translate-helps-the-scholarly-poor/
ERROR:__main__:Could not reach https://chorasimilarity.wordpress.com/2019/02/28/google-translate-helps-the-scholarly-poor/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 85%|████████▌ | 731/859 [14:07<05:23,  2.53s/it]INFO:__main__:Requesting https://eighty-twenty.org/2018/06/13/mendeley-encrypted-db
INFO:__main__:Getting metadata for https://eighty-twenty.org/2018/06/13/mendeley-encrypted-db
ERROR:__main__:Could not get metadata for https://eighty-twenty.org/2018/06/13/mendeley-encrypted-db
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 85%|████████▌ | 732/859 [14:08<04:31,  2.14s/it]INFO:__main__:Requesting https://trends.collegeboard.org/college-pricing/figures-tables/average-net-price-over-time-full-time-students-private-nonprofit-four-year-institutions
INFO:__main__:Getting metadata for https://trends.collegeboard.org/college-pricing/figures-tables/average-net-price-over-time-full-time-students-private-nonprofit-four-year-institutions
 85%|████████▌ | 733/859 [14:09<03:42,  1.76s/it]INFO:__main__:Requesting https://trends.collegeboard.org/college-pricing/figures-tables/average-net-price-over-time-full-time-students-public-four-year-institution
INFO:__main__:Getting metadata for https://trends.collegeboard.org/college-pricing/figures-tables/average-net-price-over-time-full-time-students-public-four-year-institution
 85%|████████▌ | 734/859 [14:10<03:13,  1.55s/it]INFO:__main__:Requesting https://www.reddit.com/r/AskAnAmerican/comments/7qesj9/why_is_college_in_the_us_so_expensive/
INFO:__main__:Getting metadata for https://www.reddit.com/r/AskAnAmerican/comments/7qesj9/why_is_college_in_the_us_so_expensive/
 86%|████████▌ | 735/859 [14:11<02:54,  1.41s/it]INFO:__main__:Requesting https://www.topuniversities.com/student-info/student-finance/how-much-does-it-cost-study-us
INFO:__main__:Getting metadata for https://www.topuniversities.com/student-info/student-finance/how-much-does-it-cost-study-us
 86%|████████▌ | 736/859 [14:11<02:23,  1.16s/it]INFO:__main__:Requesting https://trends.collegeboard.org/college-pricing
INFO:__main__:Getting metadata for https://trends.collegeboard.org/college-pricing
 86%|████████▌ | 737/859 [14:12<02:12,  1.09s/it]INFO:__main__:Requesting https://nces.ed.gov/programs/digest/d17/tables/dt17_334.30.asp
INFO:__main__:Getting metadata for https://nces.ed.gov/programs/digest/d17/tables/dt17_334.30.asp
 86%|████████▌ | 738/859 [14:17<04:25,  2.19s/it]INFO:__main__:Requesting https://nces.ed.gov/programs/digest/d17/tables/dt17_334.10.asp
INFO:__main__:Getting metadata for https://nces.ed.gov/programs/digest/d17/tables/dt17_334.10.asp
 86%|████████▌ | 739/859 [14:20<04:52,  2.44s/it]INFO:__main__:Requesting https://ucla.app.box.com/v/acct-pdf-AFR-16-17
INFO:__main__:Getting metadata for https://ucla.app.box.com/v/acct-pdf-AFR-16-17
ERROR:__main__:Could not get metadata for https://ucla.app.box.com/v/acct-pdf-AFR-16-17
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 86%|████████▌ | 740/859 [14:28<08:01,  4.05s/it]INFO:__main__:Requesting https://www.latimes.com/local/education/la-me-uc-spending-20151011-story.html
INFO:__main__:Getting metadata for https://www.latimes.com/local/education/la-me-uc-spending-20151011-story.html
ERROR:__main__:Could not get metadata for https://www.latimes.com/local/education/la-me-uc-spending-20151011-story.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 86%|████████▋ | 741/859 [14:29<06:19,  3.22s/it]INFO:__main__:Requesting https://twitter.com/dgmacarthur/status/1028489457803161600?s=09
INFO:__main__:Getting metadata for https://twitter.com/dgmacarthur/status/1028489457803161600?s=09
 86%|████████▋ | 742/859 [14:31<05:12,  2.67s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Elsevier
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Elsevier
 86%|████████▋ | 743/859 [14:33<04:51,  2.51s/it]INFO:__main__:Requesting https://getpolarized.io/2019/01/23/mendeleys-encrypted-repository-is-fundamentally-anti-science.html
INFO:__main__:Getting metadata for https://getpolarized.io/2019/01/23/mendeleys-encrypted-repository-is-fundamentally-anti-science.html
 87%|████████▋ | 744/859 [14:33<03:34,  1.87s/it]INFO:__main__:Requesting https://www.zotero.org/support/kb/mendeley_import
INFO:__main__:Getting metadata for https://www.zotero.org/support/kb/mendeley_import
 87%|████████▋ | 745/859 [14:34<03:07,  1.65s/it]INFO:__main__:Requesting https://github.com/retorquere/zotero-better-bibtex
INFO:__main__:Getting metadata for https://github.com/retorquere/zotero-better-bibtex
 87%|████████▋ | 746/859 [14:36<02:55,  1.56s/it]INFO:__main__:Requesting https://blog.mendeley.com/2019/01/31/the-importance-of-interoperability/
ERROR:__main__:Could not reach https://blog.mendeley.com/2019/01/31/the-importance-of-interoperability/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 87%|████████▋ | 747/859 [14:36<02:07,  1.14s/it]INFO:__main__:Requesting https://www.josemoura.com
INFO:__main__:Getting metadata for https://www.josemoura.com
 87%|████████▋ | 748/859 [14:37<02:10,  1.17s/it]INFO:__main__:Requesting https://youtu.be/Sdm698P2AkA?t=88
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=Sdm698P2AkA&feature=youtu.be&t=88
 87%|████████▋ | 749/859 [14:38<01:56,  1.06s/it]INFO:__main__:Requesting https://osc.universityofcalifornia.edu/open-access-at-uc/publisher-negotiations/uc-and-elsevier/
INFO:__main__:Getting metadata for https://osc.universityofcalifornia.edu/open-access-at-uc/publisher-negotiations/uc-and-elsevier/
 87%|████████▋ | 750/859 [14:38<01:32,  1.18it/s]INFO:__main__:Requesting https://web.archive.org/web/20190209202821/https://osc.universityofcalifornia.edu/open-access-at-uc/publisher-negotiations/uc-and-elsevier/
INFO:__main__:Getting metadata for https://web.archive.org/web/20190209202821/https://osc.universityofcalifornia.edu/open-access-at-uc/publisher-negotiations/uc-and-elsevier/
 87%|████████▋ | 751/859 [14:39<01:45,  1.02it/s]INFO:__main__:Requesting https://www.crui.it/archivio-notizie/i-ricercatori-italiani-potranno-beneficiare-dell%E2%80%99accesso-continuo-al-database-sciencedirect-di-elsevie.html
INFO:__main__:Getting metadata for https://www.crui.it/archivio-notizie/i-ricercatori-italiani-potranno-beneficiare-dell%E2%80%99accesso-continuo-al-database-sciencedirect-di-elsevie.html
 88%|████████▊ | 752/859 [14:43<03:14,  1.82s/it]INFO:__main__:Requesting https://plaudit.pub/extension/
INFO:__main__:Getting metadata for https://plaudit.pub/extension/
 88%|████████▊ | 753/859 [14:45<03:26,  1.95s/it]INFO:__main__:Requesting https://escholarship.org
INFO:__main__:Getting metadata for https://escholarship.org
ERROR:__main__:Could not get metadata for https://escholarship.org
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 88%|████████▊ | 754/859 [14:46<02:42,  1.54s/it]INFO:__main__:Requesting http://rivervalleytechnologies.com/#clients
INFO:__main__:Getting metadata for http://rivervalleytechnologies.com/#clients
 88%|████████▊ | 755/859 [14:48<02:47,  1.61s/it]INFO:__main__:Requesting https://openscience.com/green-oa-vs-gold-oa-which-one-to-choose/
INFO:__main__:Getting metadata for https://openscience.com/green-oa-vs-gold-oa-which-one-to-choose/
 88%|████████▊ | 756/859 [14:49<02:36,  1.52s/it]INFO:__main__:Requesting https://www.nature.com/articles/d41586-018-07659-5
INFO:__main__:Getting metadata for https://www.nature.com/articles/d41586-018-07659-5
 88%|████████▊ | 757/859 [14:51<02:59,  1.76s/it]INFO:__main__:Requesting https://www.nature.com/articles/d41586-019-00492-4
INFO:__main__:Getting metadata for https://www.nature.com/articles/d41586-019-00492-4
 88%|████████▊ | 758/859 [14:54<03:22,  2.00s/it]INFO:__main__:Requesting https://www.library.ucdavis.edu/uc-elsevier/
INFO:__main__:Getting metadata for https://www.library.ucdavis.edu/uc-elsevier/
 88%|████████▊ | 759/859 [14:56<03:12,  1.93s/it]INFO:__main__:Requesting http://libgen.io/scimag/index.php?s=archaeology
INFO:__main__:Getting metadata for http://libgen.io/scimag/index.php?s=archaeology
 88%|████████▊ | 760/859 [14:59<03:37,  2.20s/it]INFO:__main__:Requesting https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5832410/
INFO:__main__:Getting metadata for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5832410/
 89%|████████▊ | 761/859 [15:01<03:36,  2.21s/it]INFO:__main__:Requesting https://osc.universityofcalifornia.edu/open-access-at-uc/publisher-negotiations/alternative-access-to-articles/
INFO:__main__:Getting metadata for https://osc.universityofcalifornia.edu/open-access-at-uc/publisher-negotiations/alternative-access-to-articles/
 89%|████████▊ | 762/859 [15:01<02:35,  1.60s/it]INFO:__main__:Requesting https://openaccessmanifesto.wordpress.com/guerilla-open-access-manifesto/
ERROR:__main__:Could not reach https://openaccessmanifesto.wordpress.com/guerilla-open-access-manifesto/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 89%|████████▉ | 763/859 [15:01<01:51,  1.16s/it]INFO:__main__:Requesting https://unpaywall.org/products/extension
INFO:__main__:Getting metadata for https://unpaywall.org/products/extension
ERROR:__main__:Could not get metadata for https://unpaywall.org/products/extension
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 89%|████████▉ | 764/859 [15:02<01:41,  1.07s/it]INFO:__main__:Requesting https://github.com/nfahlgren/scihub_bookmark
INFO:__main__:Getting metadata for https://github.com/nfahlgren/scihub_bookmark
 89%|████████▉ | 765/859 [15:03<01:37,  1.04s/it]INFO:__main__:Requesting https://medium.com/@gagarine/use-sci-hub-with-zotero-as-a-fall-back-pdf-resolver-cf139eb2cea7
INFO:__main__:Getting metadata for https://medium.com/@gagarine/use-sci-hub-with-zotero-as-a-fall-back-pdf-resolver-cf139eb2cea7
 89%|████████▉ | 766/859 [15:04<01:28,  1.05it/s]INFO:__main__:Requesting https://twitter.com/sci_hub/status/731467465973174273
INFO:__main__:Getting metadata for https://twitter.com/sci_hub/status/731467465973174273
 89%|████████▉ | 767/859 [15:05<01:34,  1.03s/it]INFO:__main__:Requesting https://greasyfork.org/en/scripts/36188-sci-hub-automatic-link/code
INFO:__main__:Getting metadata for https://greasyfork.org/en/scripts/36188-sci-hub-automatic-link/code
ERROR:__main__:Could not get metadata for https://greasyfork.org/en/scripts/36188-sci-hub-automatic-link/code
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 203, in web_preview
    gp = GenericPreview(url, timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 73, in __init__
    self.description = self._get_description()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 97, in _get_description
    if(meta_description and meta_description['content'] !=""):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 89%|████████▉ | 768/859 [15:06<01:36,  1.06s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=vSPUc70z_Cc
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=vSPUc70z_Cc
 90%|████████▉ | 769/859 [15:07<01:29,  1.00it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=bzNowvBmR3g
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=bzNowvBmR3g
 90%|████████▉ | 770/859 [15:08<01:24,  1.05it/s]INFO:__main__:Requesting http://thecostofknowledge.com
INFO:__main__:Getting metadata for http://thecostofknowledge.com
 90%|████████▉ | 771/859 [15:08<01:15,  1.16it/s]INFO:__main__:Requesting https://theconversation.com/why-i-disagree-with-nobel-laureates-when-it-comes-to-career-advice-for-scientists-80079
INFO:__main__:Getting metadata for https://theconversation.com/why-i-disagree-with-nobel-laureates-when-it-comes-to-career-advice-for-scientists-80079
 90%|████████▉ | 772/859 [15:09<01:10,  1.23it/s]INFO:__main__:Requesting https://www.chronicle.com/article/In-Talks-With-Elsevier-UCLA/245311
 90%|████████▉ | 773/859 [15:09<00:53,  1.60it/s]INFO:__main__:Requesting https://www.ucpress.edu/openaccess
INFO:__main__:Getting metadata for https://www.ucpress.edu/openaccess
 90%|█████████ | 774/859 [15:12<01:54,  1.35s/it]INFO:__main__:Requesting https://www.arl.org/focus-areas/scholarly-communication/toward-an-open-monograph-ecosystem
INFO:__main__:Getting metadata for https://www.arl.org/focus-areas/scholarly-communication/toward-an-open-monograph-ecosystem
 90%|█████████ | 775/859 [15:14<01:57,  1.40s/it]INFO:__main__:Requesting http://uc-oa.info
INFO:__main__:Getting metadata for https://osc.universityofcalifornia.edu/open-access-at-uc/open-access-policy/
 90%|█████████ | 776/859 [15:14<01:35,  1.15s/it]INFO:__main__:Requesting http://www.lib.berkeley.edu/using-the-libraries/interlibrary-loan
INFO:__main__:Getting metadata for http://www.lib.berkeley.edu/using-the-libraries/interlibrary-loan
 90%|█████████ | 777/859 [15:15<01:28,  1.08s/it]INFO:__main__:Requesting https://twitter.com/DannyBate4/status/1092132558937169922
INFO:__main__:Getting metadata for https://twitter.com/DannyBate4/status/1092132558937169922
 91%|█████████ | 778/859 [15:17<01:34,  1.17s/it]INFO:__main__:Requesting https://avc.com/2011/09/minimum-viable-personality/
INFO:__main__:Getting metadata for https://avc.com/2011/09/minimum-viable-personality/
 91%|█████████ | 779/859 [15:20<02:22,  1.78s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=KHbzSif78qQ
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=KHbzSif78qQ
 91%|█████████ | 780/859 [15:21<02:00,  1.52s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=rE3j_RHkqJc
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=rE3j_RHkqJc
 91%|█████████ | 781/859 [15:22<01:44,  1.34s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=06yy88tLWlg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=06yy88tLWlg
 91%|█████████ | 782/859 [15:23<01:32,  1.20s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=TNYbcqyyj68
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=TNYbcqyyj68
 91%|█████████ | 783/859 [15:24<01:27,  1.15s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=u4ZoJKF_VuA
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=u4ZoJKF_VuA
 91%|█████████▏| 784/859 [15:25<01:20,  1.08s/it]INFO:__main__:Requesting https://www.businessinsider.com/10-biggest-advertising-spenders-in-the-us-2015-7
INFO:__main__:Getting metadata for https://www.businessinsider.com/10-biggest-advertising-spenders-in-the-us-2015-7
 91%|█████████▏| 785/859 [15:25<01:02,  1.19it/s]INFO:__main__:Requesting https://www.adsoftheworld.com/collection/2018_super_bowl_commercials
INFO:__main__:Getting metadata for https://www.adsoftheworld.com/collection/2018_super_bowl_commercials
ERROR:__main__:Could not get metadata for https://www.adsoftheworld.com/collection/2018_super_bowl_commercials
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 92%|█████████▏| 786/859 [15:31<02:49,  2.32s/it]INFO:__main__:Requesting https://github.com/triska/lisprolog
INFO:__main__:Getting metadata for https://github.com/triska/lisprolog
 92%|█████████▏| 787/859 [15:32<02:18,  1.92s/it]INFO:__main__:Requesting https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-0-preface7.html
INFO:__main__:Getting metadata for https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-0-preface7.html
ERROR:__main__:Could not get metadata for https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-0-preface7.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 92%|█████████▏| 788/859 [15:32<01:47,  1.52s/it]INFO:__main__:Requesting https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-4.html#jvms-4.10
INFO:__main__:Getting metadata for https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-4.html#jvms-4.10
ERROR:__main__:Could not get metadata for https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-4.html#jvms-4.10
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 92%|█████████▏| 789/859 [15:38<03:06,  2.67s/it]INFO:__main__:Requesting https://kylecordes.com/2010/the-prolog-story
INFO:__main__:Getting metadata for https://kylecordes.com/2010/the-prolog-story
 92%|█████████▏| 790/859 [15:38<02:27,  2.14s/it]INFO:__main__:Requesting http://eclipseclp.org/
INFO:__main__:Getting metadata for http://eclipseclp.org
 92%|█████████▏| 791/859 [15:40<02:08,  1.89s/it]INFO:__main__:Requesting https://sicstus.sics.se/
INFO:__main__:Getting metadata for https://sicstus.sics.se
 92%|█████████▏| 792/859 [15:42<02:21,  2.12s/it]INFO:__main__:Requesting https://www.cs.nmsu.edu/ALP/2011/03/natural-language-processing-with-prolog-in-the-ibm-watson-system/
INFO:__main__:Getting metadata for https://www.cs.nmsu.edu/ALP/2011/03/natural-language-processing-with-prolog-in-the-ibm-watson-system/
 92%|█████████▏| 793/859 [15:45<02:34,  2.34s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=RpsZ1Ka2HPQ
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=RpsZ1Ka2HPQ
 92%|█████████▏| 794/859 [15:46<02:01,  1.87s/it]INFO:__main__:Requesting http://www.swi-prolog.org/pldoc/man?section=simplex
INFO:__main__:Getting metadata for http://www.swi-prolog.org/pldoc/man?section=simplex
 93%|█████████▎| 795/859 [15:47<01:45,  1.64s/it]INFO:__main__:Requesting http://eclipseclp.org/features.html
INFO:__main__:Getting metadata for http://eclipseclp.org/features.html
 93%|█████████▎| 796/859 [15:48<01:34,  1.50s/it]INFO:__main__:Requesting https://vanemden.wordpress.com/2010/08/21/who-killed-prolog/
ERROR:__main__:Could not reach https://vanemden.wordpress.com/2010/08/21/who-killed-prolog/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 93%|█████████▎| 797/859 [15:48<01:07,  1.09s/it]INFO:__main__:Requesting https://xmonader.github.io/prolog/2018/12/21/solving-murder-prolog.html
INFO:__main__:Getting metadata for https://xmonader.github.io/prolog/2018/12/21/solving-murder-prolog.html
 93%|█████████▎| 798/859 [15:49<00:52,  1.17it/s]INFO:__main__:Requesting https://github.com/TeamSPoon/wam_common_lisp
INFO:__main__:Getting metadata for https://github.com/TeamSPoon/wam_common_lisp
 93%|█████████▎| 799/859 [15:50<00:53,  1.12it/s]INFO:__main__:Requesting http://www.swi-prolog.org/pldoc/man?section=fileext
INFO:__main__:Getting metadata for http://www.swi-prolog.org/pldoc/man?section=fileext
ERROR:__main__:Could not get metadata for http://www.swi-prolog.org/pldoc/man?section=fileext
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 93%|█████████▎| 800/859 [15:50<00:46,  1.28it/s]INFO:__main__:Requesting https://github.com/norvig/paip-lisp
INFO:__main__:Getting metadata for https://github.com/norvig/paip-lisp
 93%|█████████▎| 801/859 [15:51<00:46,  1.25it/s]INFO:__main__:Requesting https://www.givecampus.com/careers#engineering
INFO:__main__:Getting metadata for https://www.givecampus.com/careers#engineering
 93%|█████████▎| 802/859 [15:52<00:39,  1.44it/s]INFO:__main__:Requesting https://blog.lukaszolejnik.com/target-confirming-an-offensive-cyber-operation-2/
INFO:__main__:Getting metadata for https://blog.lukaszolejnik.com/target-confirming-an-offensive-cyber-operation-2/
 93%|█████████▎| 803/859 [15:53<00:45,  1.23it/s]INFO:__main__:Requesting https://www.nytimes.com/2018/06/17/us/politics/cyber-command-trump.html?module=inline
INFO:__main__:Getting metadata for https://www.nytimes.com/2018/06/17/us/politics/cyber-command-trump.html?module=inline
 94%|█████████▎| 804/859 [15:53<00:35,  1.57it/s]INFO:__main__:Requesting https://www.internetsociety.org/internet/history-internet/brief-history-internet/
INFO:__main__:Getting metadata for https://www.internetsociety.org/internet/history-internet/brief-history-internet/
ERROR:__main__:Could not get metadata for https://www.internetsociety.org/internet/history-internet/brief-history-internet/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 94%|█████████▎| 805/859 [15:55<00:57,  1.07s/it]INFO:__main__:Requesting http://
ERROR:__main__:Could not reach http://
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 519, in request
    prep = self.prepare_request(req)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 462, in prepare_request
    hooks=merge_hooks(request.hooks, self.hooks),
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 313, in prepare
    self.prepare_url(url, params)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 390, in prepare_url
    raise InvalidURL("Invalid URL %r: No host supplied" % url)
requests.exceptions.InvalidURL: Invalid URL 'http://': No host supplied
INFO:__main__:Requesting https://www.nytimes.com/2018/10/23/us/politics/russian-hacking-usa-cyber-command.html
INFO:__main__:Getting metadata for https://www.nytimes.com/2018/10/23/us/politics/russian-hacking-usa-cyber-command.html
 94%|█████████▍| 807/859 [15:55<00:40,  1.28it/s]INFO:__main__:Requesting https://www.washingtonpost.com/world/national-security/us-cyber-command-operation-disrupted-internet-access-of-russian-troll-factory-on-day-of-2018-midterms/2019/02/26/1827fc9e-36d6-11e9-af5b-b51b7ff322e9_story.html/?noredirect=on&utm_term=.0daec82fe881
ERROR:__main__:Could not reach https://www.washingtonpost.com/world/national-security/us-cyber-command-operation-disrupted-internet-access-of-russian-troll-factory-on-day-of-2018-midterms/2019/02/26/1827fc9e-36d6-11e9-af5b-b51b7ff322e9_story.html/?noredirect=on&utm_term=.0daec82fe881
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)
 94%|█████████▍| 808/859 [16:01<02:00,  2.37s/it]INFO:__main__:Requesting https://riafan.ru/1155441-kiberataka-ssha-na-fan-podrobnosti-neudachnoi-operacii-us-cyber-command
INFO:__main__:Getting metadata for https://riafan.ru/1155441-kiberataka-ssha-na-fan-podrobnosti-neudachnoi-operacii-us-cyber-command
 94%|█████████▍| 809/859 [16:04<02:02,  2.46s/it]INFO:__main__:Requesting https://www.rbc.ru/technology_and_media/08/02/2019/5c5c51069a7947bef4503927
INFO:__main__:Getting metadata for https://www.rbc.ru/technology_and_media/08/02/2019/5c5c51069a7947bef4503927
 94%|█████████▍| 810/859 [16:06<01:52,  2.29s/it]INFO:__main__:Requesting http://tass.com/world/1046641
INFO:__main__:Getting metadata for http://tass.com/world/1046641
 94%|█████████▍| 811/859 [16:08<01:42,  2.13s/it]INFO:__main__:Requesting https://github.com/pugwonk/gif2xlsx/blob/master/README.md
INFO:__main__:Getting metadata for https://github.com/pugwonk/gif2xlsx/blob/master/README.md
 95%|█████████▍| 812/859 [16:08<01:21,  1.74s/it]INFO:__main__:Requesting http://justpic.info/images4/1100/usage_king.png
INFO:__main__:Getting metadata for http://justpic.info/images4/1100/usage_king.png
ERROR:__main__:Could not get metadata for http://justpic.info/images4/1100/usage_king.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 95%|█████████▍| 813/859 [16:11<01:35,  2.09s/it]INFO:__main__:Requesting http://www.pouet.net/prod.php?which=53021
INFO:__main__:Getting metadata for http://www.pouet.net/prod.php?which=53021
ERROR:__main__:Could not get metadata for http://www.pouet.net/prod.php?which=53021
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 95%|█████████▍| 814/859 [16:12<01:18,  1.74s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=UBX2QQHlQ_I
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=UBX2QQHlQ_I
 95%|█████████▍| 815/859 [16:13<01:06,  1.51s/it]INFO:__main__:Requesting https://www.newyorker.com/magazine/2016/12/19/how-to-be-a-stoic
INFO:__main__:Getting metadata for https://www.newyorker.com/magazine/2016/12/19/how-to-be-a-stoic
 95%|█████████▍| 816/859 [16:14<00:52,  1.23s/it]INFO:__main__:Requesting https://speeches.byu.edu/talks/bruce-c-hafen_love-is-not-blind-thoughts-college-students-faith-ambiguity/
INFO:__main__:Getting metadata for https://speeches.byu.edu/talks/bruce-c-hafen_love-is-not-blind-thoughts-college-students-faith-ambiguity/
 95%|█████████▌| 817/859 [16:15<00:52,  1.25s/it]INFO:__main__:Requesting https://standardebooks.org/ebooks/marcus-aurelius/meditations/george-long
INFO:__main__:Getting metadata for https://standardebooks.org/ebooks/marcus-aurelius/meditations/george-long
ERROR:__main__:Could not get metadata for https://standardebooks.org/ebooks/marcus-aurelius/meditations/george-long
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 95%|█████████▌| 818/859 [16:15<00:40,  1.01it/s]INFO:__main__:Requesting https://standardebooks.org/ebooks/epictetus/the-enchiridion/elizabeth-carter
INFO:__main__:Getting metadata for https://standardebooks.org/ebooks/epictetus/the-enchiridion/elizabeth-carter
ERROR:__main__:Could not get metadata for https://standardebooks.org/ebooks/epictetus/the-enchiridion/elizabeth-carter
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 95%|█████████▌| 819/859 [16:16<00:31,  1.25it/s]INFO:__main__:Requesting https://standardebooks.org/ebooks/seneca/dialogues/aubrey-stewart
INFO:__main__:Getting metadata for https://standardebooks.org/ebooks/seneca/dialogues/aubrey-stewart
ERROR:__main__:Could not get metadata for https://standardebooks.org/ebooks/seneca/dialogues/aubrey-stewart
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 95%|█████████▌| 820/859 [16:16<00:25,  1.51it/s]INFO:__main__:Requesting https://codeandtechno.com/posts/stoicism-for-developers/
INFO:__main__:Getting metadata for https://codeandtechno.com/posts/stoicism-for-developers/
 96%|█████████▌| 821/859 [16:16<00:19,  1.91it/s]INFO:__main__:Requesting https://www.amazon.com/Guide-Good-Life-Ancient-Stoic/dp/1522632735
INFO:__main__:Getting metadata for https://www.amazon.com/Guide-Good-Life-Ancient-Stoic/dp/1522632735
 96%|█████████▌| 822/859 [16:25<01:50,  2.99s/it]INFO:__main__:Requesting https://www.reddit.com/r/Stoicism/comments/9umsg0/starting_with_things_of_little_value_a_bit_of/
INFO:__main__:Getting metadata for https://www.reddit.com/r/Stoicism/comments/9umsg0/starting_with_things_of_little_value_a_bit_of/
 96%|█████████▌| 823/859 [16:26<01:25,  2.37s/it]INFO:__main__:Requesting https://www.amazon.com/Guide-Good-Life-Ancient-Stoic/dp/0195374614
INFO:__main__:Getting metadata for https://www.amazon.com/Guide-Good-Life-Ancient-Stoic/dp/0195374614
 96%|█████████▌| 824/859 [16:35<02:34,  4.41s/it]INFO:__main__:Requesting https://www.amazon.com/No-Mud-Lotus-Transforming-Suffering/dp/1937006859
INFO:__main__:Getting metadata for https://www.amazon.com/No-Mud-Lotus-Transforming-Suffering/dp/1937006859
 96%|█████████▌| 825/859 [16:44<03:12,  5.67s/it]INFO:__main__:Requesting https://www.amazon.co.uk/Daily-Stoic-Meditations-Perseverance-translations/dp/1781257655/
INFO:__main__:Getting metadata for https://www.amazon.co.uk/Daily-Stoic-Meditations-Perseverance-translations/dp/1781257655/
 96%|█████████▌| 826/859 [16:48<02:50,  5.17s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Meditations
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Meditations
 96%|█████████▋| 827/859 [16:49<02:07,  4.00s/it]INFO:__main__:Requesting https://why-openbsd.rocks/fact/
INFO:__main__:Getting metadata for https://why-openbsd.rocks/fact/
ERROR:__main__:Could not get metadata for https://why-openbsd.rocks/fact/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 96%|█████████▋| 828/859 [16:50<01:37,  3.14s/it]INFO:__main__:Requesting https://why-openbsd.rocks/fact/file/
INFO:__main__:Getting metadata for https://why-openbsd.rocks/fact/file/
ERROR:__main__:Could not get metadata for https://why-openbsd.rocks/fact/file/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 97%|█████████▋| 829/859 [16:51<01:15,  2.51s/it]INFO:__main__:Requesting https://why-openbsd.rocks/fact/pledge/
INFO:__main__:Getting metadata for https://why-openbsd.rocks/fact/pledge/
ERROR:__main__:Could not get metadata for https://why-openbsd.rocks/fact/pledge/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 97%|█████████▋| 830/859 [16:52<00:59,  2.06s/it]INFO:__main__:Requesting https://github.com/Blitznote/signify
INFO:__main__:Getting metadata for https://github.com/Blitznote/signify
 97%|█████████▋| 831/859 [16:53<00:50,  1.79s/it]INFO:__main__:Requesting https://www.openbsd.org/innovations.html
INFO:__main__:Getting metadata for https://www.openbsd.org/innovations.html
ERROR:__main__:Could not get metadata for https://www.openbsd.org/innovations.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 97%|█████████▋| 832/859 [16:56<00:52,  1.95s/it]INFO:__main__:Requesting https://www.openbsd.org/64.html
INFO:__main__:Getting metadata for https://www.openbsd.org/64.html
 97%|█████████▋| 833/859 [17:00<01:08,  2.62s/it]INFO:__main__:Requesting https://rgz.ee/openbsd/cwm.html
INFO:__main__:Getting metadata for https://rgz.ee/openbsd/cwm.html
 97%|█████████▋| 834/859 [17:03<01:09,  2.79s/it]INFO:__main__:Requesting http://cdn.openbsd.org/pub/OpenBSD/6.4/packages/amd64/
INFO:__main__:Getting metadata for http://cdn.openbsd.org/pub/OpenBSD/6.4/packages/amd64/
 97%|█████████▋| 835/859 [17:18<02:33,  6.39s/it]INFO:__main__:Requesting https://man.openbsd.org/?query=ethernet&apropos=1&sec=4
INFO:__main__:Getting metadata for https://man.openbsd.org/?query=ethernet&apropos=1&sec=4
ERROR:__main__:Could not get metadata for https://man.openbsd.org/?query=ethernet&apropos=1&sec=4
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 97%|█████████▋| 836/859 [17:20<01:54,  4.98s/it]INFO:__main__:Requesting https://man.openbsd.org/?query=wireless&apropos=1
INFO:__main__:Getting metadata for https://man.openbsd.org/?query=wireless&apropos=1
ERROR:__main__:Could not get metadata for https://man.openbsd.org/?query=wireless&apropos=1
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 97%|█████████▋| 837/859 [17:21<01:25,  3.87s/it]INFO:__main__:Requesting https://man.openbsd.org/?query=video+driver&apropos=1&sec=4&arch=default&manpath=OpenBSD-current
INFO:__main__:Getting metadata for https://man.openbsd.org/?query=video+driver&apropos=1&sec=4&arch=default&manpath=OpenBSD-current
ERROR:__main__:Could not get metadata for https://man.openbsd.org/?query=video+driver&apropos=1&sec=4&arch=default&manpath=OpenBSD-current
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 98%|█████████▊| 838/859 [17:22<01:05,  3.13s/it]INFO:__main__:Requesting https://www.openbsd.org/octeon.html
INFO:__main__:Getting metadata for https://www.openbsd.org/octeon.html
 98%|█████████▊| 839/859 [17:24<00:53,  2.67s/it]INFO:__main__:Requesting https://codeghar.com/blog/openbsd-network-gateway-on-edgerouter-lite.html
INFO:__main__:Getting metadata for https://codeghar.com/blog/openbsd-network-gateway-on-edgerouter-lite.html
 98%|█████████▊| 840/859 [17:24<00:39,  2.07s/it]INFO:__main__:Requesting https://www.amazon.com/dp/B013CCTM2E/ref=cm_sw_em_r_mt_dp_U_UewECb3Q86NVG
INFO:__main__:Getting metadata for https://www.amazon.com/dp/B013CCTM2E/ref=cm_sw_em_r_mt_dp_U_UewECb3Q86NVG
 98%|█████████▊| 841/859 [17:35<01:23,  4.62s/it]INFO:__main__:Requesting https://www.amazon.com/dp/B01N0LMWGQ/ref=cm_sw_em_r_mt_dp_U_wgwECbSVDAYK5
INFO:__main__:Getting metadata for https://www.amazon.com/dp/B01N0LMWGQ/ref=cm_sw_em_r_mt_dp_U_wgwECbSVDAYK5
 98%|█████████▊| 842/859 [17:43<01:34,  5.57s/it]INFO:__main__:Requesting https://protectli.com/4-port/
INFO:__main__:Getting metadata for https://protectli.com/4-port/
 98%|█████████▊| 843/859 [17:47<01:23,  5.21s/it]INFO:__main__:Requesting https://tech.mangot.com/blog/2018/11/08/showing-a-gigabit-openbsd-firewall-some-monitoring-love/
INFO:__main__:Getting metadata for https://tech.mangot.com/blog/2018/11/08/showing-a-gigabit-openbsd-firewall-some-monitoring-love/
 98%|█████████▊| 844/859 [17:48<00:58,  3.93s/it]INFO:__main__:Requesting http://man.openbsd.org/pf.conf.5
INFO:__main__:Getting metadata for http://man.openbsd.org/pf.conf.5
 98%|█████████▊| 845/859 [17:50<00:45,  3.26s/it]INFO:__main__:Requesting https://rgz.ee/openbsd/why.html
INFO:__main__:Getting metadata for https://rgz.ee/openbsd/why.html
 98%|█████████▊| 846/859 [17:54<00:44,  3.39s/it]INFO:__main__:Requesting https://rgz.ee/openbsd/
INFO:__main__:Getting metadata for https://rgz.ee/openbsd/
 99%|█████████▊| 847/859 [17:56<00:38,  3.23s/it]INFO:__main__:Requesting https://www.openbsd.org/errata64.html
INFO:__main__:Getting metadata for https://www.openbsd.org/errata64.html
 99%|█████████▊| 848/859 [17:58<00:30,  2.73s/it]INFO:__main__:Requesting https://why-openbsd.rocks/fact/meltdown-spectre/
INFO:__main__:Getting metadata for https://why-openbsd.rocks/fact/meltdown-spectre/
ERROR:__main__:Could not get metadata for https://why-openbsd.rocks/fact/meltdown-spectre/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 99%|█████████▉| 849/859 [17:59<00:22,  2.22s/it]INFO:__main__:Requesting https://rgz.ee/openbsd/install.html
INFO:__main__:Getting metadata for https://rgz.ee/openbsd/install.html
 99%|█████████▉| 850/859 [18:02<00:22,  2.49s/it]INFO:__main__:Requesting https://nixos.wiki/wiki/Keyboard_Layout_Customization
INFO:__main__:Getting metadata for https://nixos.wiki/wiki/Keyboard_Layout_Customization
 99%|█████████▉| 851/859 [18:05<00:19,  2.49s/it]INFO:__main__:Requesting https://seymour-locksmiths.co.uk/bitcoin-locksmith/
INFO:__main__:Getting metadata for https://seymour-locksmiths.co.uk/bitcoin-locksmith/
 99%|█████████▉| 852/859 [18:06<00:15,  2.16s/it]INFO:__main__:Requesting https://www.money.co.uk/money-transfers.htm
INFO:__main__:Getting metadata for https://www.money.co.uk/money-transfers.htm
ERROR:__main__:Could not get metadata for https://www.money.co.uk/money-transfers.htm
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 99%|█████████▉| 853/859 [18:07<00:11,  1.86s/it]INFO:__main__:Requesting https://www.npr.org/sections/money/2018/01/10/576879734/episode-489-the-invisible-plumbing-of-our-economy
INFO:__main__:Getting metadata for https://www.npr.org/sections/money/2018/01/10/576879734/episode-489-the-invisible-plumbing-of-our-economy
 99%|█████████▉| 854/859 [18:08<00:07,  1.41s/it]INFO:__main__:Requesting http://gs.statcounter.com/os-market-share/desktop/worldwide/#monthly-201003-201807
INFO:__main__:Getting metadata for http://gs.statcounter.com/os-market-share/desktop/worldwide/#monthly-201003-201807
100%|█████████▉| 855/859 [18:09<00:05,  1.30s/it]INFO:__main__:Requesting https://www.blockchain.com/charts/n-transactions?timespan=all
INFO:__main__:Getting metadata for https://www.blockchain.com/charts/n-transactions?timespan=all
100%|█████████▉| 856/859 [18:09<00:03,  1.02s/it]INFO:__main__:Requesting https://medium.com/gitcoin/burner-wallet-at-ethdenver-was-faa3851ea833
INFO:__main__:Getting metadata for https://medium.com/gitcoin/burner-wallet-at-ethdenver-was-faa3851ea833
100%|█████████▉| 857/859 [18:10<00:01,  1.11it/s]INFO:__main__:Requesting https://paywithmoon.com/
INFO:__main__:Getting metadata for https://paywithmoon.com
100%|█████████▉| 858/859 [18:10<00:00,  1.18it/s]INFO:__main__:Requesting https://blockchain.info/
INFO:__main__:Getting metadata for https://www.blockchain.com/explorer
100%|██████████| 859/859 [18:11<00:00,  1.25it/s]
