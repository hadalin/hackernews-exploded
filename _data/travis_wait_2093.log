INFO:__main__:Get urls from stories
  0%|          | 0/30 [00:00<?, ?it/s]  3%|▎         | 1/30 [00:00<00:16,  1.72it/s]  7%|▋         | 2/30 [00:01<00:17,  1.57it/s] 10%|█         | 3/30 [00:01<00:13,  1.96it/s] 13%|█▎        | 4/30 [00:04<00:34,  1.33s/it] 20%|██        | 6/30 [00:05<00:23,  1.01it/s] 27%|██▋       | 8/30 [00:05<00:16,  1.35it/s] 30%|███       | 9/30 [00:05<00:13,  1.57it/s] 37%|███▋      | 11/30 [00:06<00:09,  2.08it/s] 40%|████      | 12/30 [00:06<00:07,  2.53it/s] 43%|████▎     | 13/30 [00:06<00:05,  2.94it/s] 50%|█████     | 15/30 [00:06<00:03,  3.91it/s] 57%|█████▋    | 17/30 [00:08<00:05,  2.41it/s] 67%|██████▋   | 20/30 [00:08<00:03,  3.05it/s] 70%|███████   | 21/30 [00:08<00:02,  3.32it/s] 73%|███████▎  | 22/30 [00:09<00:02,  3.90it/s] 77%|███████▋  | 23/30 [00:09<00:02,  2.95it/s] 80%|████████  | 24/30 [00:09<00:01,  3.03it/s] 87%|████████▋ | 26/30 [00:10<00:01,  3.61it/s] 90%|█████████ | 27/30 [00:10<00:01,  2.55it/s] 93%|█████████▎| 28/30 [00:12<00:01,  1.28it/s]100%|██████████| 30/30 [00:14<00:00,  1.17it/s]
  0%|          | 0/219 [00:00<?, ?it/s]INFO:__main__:Requesting http://immersivemath.com/ila/index.html
INFO:__main__:Getting metadata for http://immersivemath.com/ila/index.html
  0%|          | 1/219 [00:02<10:02,  2.76s/it]INFO:__main__:Requesting http://joshua.smcvt.edu/linearalgebra/
INFO:__main__:Getting metadata for http://joshua.smcvt.edu/linearalgebra/
ERROR:__main__:Could not get metadata for http://joshua.smcvt.edu/linearalgebra/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  1%|          | 2/219 [00:03<07:29,  2.07s/it]INFO:__main__:Requesting https://openstax.org/
INFO:__main__:Getting metadata for https://openstax.org
  1%|▏         | 3/219 [00:04<06:45,  1.88s/it]INFO:__main__:Requesting https://open.umn.edu/opentextbooks/
INFO:__main__:Getting metadata for https://open.umn.edu/opentextbooks/
  2%|▏         | 4/219 [00:06<06:35,  1.84s/it]INFO:__main__:Requesting http://tutorial.math.lamar.edu/Extras/AlgebraTrigReview/AlgebraTrigIntro.aspx
INFO:__main__:Getting metadata for http://tutorial.math.lamar.edu/Extras/AlgebraTrigReview/AlgebraTrigIntro.aspx
  2%|▏         | 5/219 [00:08<06:25,  1.80s/it]INFO:__main__:Requesting https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw
INFO:__main__:Getting metadata for https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw
  3%|▎         | 6/219 [00:11<08:08,  2.29s/it]INFO:__main__:Requesting http://abstract.ups.edu/aata/
INFO:__main__:Getting metadata for http://abstract.ups.edu/aata/
  3%|▎         | 7/219 [00:13<07:28,  2.11s/it]INFO:__main__:Requesting http://linear.pugetsound.edu/html/fcla.html
INFO:__main__:Getting metadata for http://linear.pugetsound.edu/html/fcla.html
  4%|▎         | 8/219 [00:14<06:24,  1.82s/it]INFO:__main__:Requesting https://physicstoday.scitation.org/doi/full/10.1063/1.1768652
INFO:__main__:Getting metadata for https://physicstoday.scitation.org/action/captchaChallenge?redirectUrl=https%3A%2F%2Fphysicstoday.scitation.org%2Fdoi%2Ffull%2F10.1063%2F1.1768652
  4%|▍         | 9/219 [00:17<07:42,  2.20s/it]INFO:__main__:Requesting http://www.math.harvard.edu/~elkies/M55a.17/index.html
INFO:__main__:Getting metadata for http://www.math.harvard.edu/~elkies/M55a.17/index.html
ERROR:__main__:Could not get metadata for http://www.math.harvard.edu/~elkies/M55a.17/index.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  5%|▍         | 10/219 [00:18<06:33,  1.88s/it]INFO:__main__:Requesting http://setosa.io/ev/eigenvectors-and-eigenvalues/
INFO:__main__:Getting metadata for http://setosa.io/ev/eigenvectors-and-eigenvalues/
ERROR:__main__:Could not get metadata for http://setosa.io/ev/eigenvectors-and-eigenvalues/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  5%|▌         | 11/219 [00:18<04:54,  1.41s/it]INFO:__main__:Requesting https://www.amazon.com/Visual-Group-Theory-Problem-Book/dp/088385757X
INFO:__main__:Getting metadata for https://www.amazon.com/Visual-Group-Theory-Problem-Book/dp/088385757X
  5%|▌         | 12/219 [00:20<05:29,  1.59s/it]INFO:__main__:Requesting https://www.lowtechmagazine.com/2019/02/heat-your-house-with-a-water-brake-windmill.html
INFO:__main__:Getting metadata for https://www.lowtechmagazine.com/2019/02/heat-your-house-with-a-water-brake-windmill.html
  6%|▌         | 13/219 [00:21<04:24,  1.29s/it]INFO:__main__:Requesting https://dothemath.ucsd.edu/2012/06/heat-pumps-work-miracles/
INFO:__main__:Getting metadata for https://dothemath.ucsd.edu/2012/06/heat-pumps-work-miracles/
  6%|▋         | 14/219 [00:24<06:22,  1.87s/it]INFO:__main__:Requesting https://www.energy.gov/eere/solar/articles/solar-radiation-basics
  7%|▋         | 15/219 [00:24<04:39,  1.37s/it]INFO:__main__:Requesting https://www.nrel.gov/gis/images/map_pv_us_january_dec2008.jpg
INFO:__main__:Getting metadata for https://www.nrel.gov/gis/images/map_pv_us_january_dec2008.jpg
ERROR:__main__:Could not get metadata for https://www.nrel.gov/gis/images/map_pv_us_january_dec2008.jpg
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  7%|▋         | 16/219 [00:30<09:16,  2.74s/it]INFO:__main__:Requesting https://www.nrel.gov/gis/images/map_pv_us_july_dec2008.jpg
INFO:__main__:Getting metadata for https://www.nrel.gov/gis/images/map_pv_us_july_dec2008.jpg
ERROR:__main__:Could not get metadata for https://www.nrel.gov/gis/images/map_pv_us_july_dec2008.jpg
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  8%|▊         | 17/219 [00:36<12:03,  3.58s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Mechanical_equivalent_of_heat
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Mechanical_equivalent_of_heat
  8%|▊         | 18/219 [00:37<09:14,  2.76s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=GjcOobt9Ef8
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=GjcOobt9Ef8
  9%|▊         | 19/219 [00:38<07:22,  2.21s/it]INFO:__main__:Requesting https://jacquesmattheij.com/how-to-build-a-windmill/
INFO:__main__:Getting metadata for https://jacquesmattheij.com/how-to-build-a-windmill/
  9%|▉         | 20/219 [00:41<08:07,  2.45s/it]INFO:__main__:Requesting https://web.archive.org/web/20160813143636/http://www.jacquesmattheij.com/how-to-build-a-windmill
INFO:__main__:Getting metadata for https://web.archive.org/web/20160813143636/http://www.jacquesmattheij.com/how-to-build-a-windmill
 10%|▉         | 21/219 [00:43<07:36,  2.30s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Electromigration
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Electromigration
 10%|█         | 22/219 [00:44<06:34,  2.00s/it]INFO:__main__:Requesting https://www.lowtechmagazine.com/2013/03/the-mechanical-transmission-of-power-3-wire-ropes.html
INFO:__main__:Getting metadata for https://www.lowtechmagazine.com/2013/03/the-mechanical-transmission-of-power-3-wire-ropes.html
 11%|█         | 23/219 [00:45<05:10,  1.58s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/District_heating
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/District_heating
 11%|█         | 24/219 [00:47<05:30,  1.69s/it]INFO:__main__:Requesting https://solar.lowtechmagazine.com/2019/02/heat-your-house-with-a-water-brake-windmill.html
INFO:__main__:Getting metadata for https://solar.lowtechmagazine.com/2019/02/heat-your-house-with-a-water-brake-windmill.html
 11%|█▏        | 25/219 [00:48<05:26,  1.68s/it]INFO:__main__:Requesting https://solar.lowtechmagazine.com/about/
INFO:__main__:Getting metadata for https://solar.lowtechmagazine.com/about/
 12%|█▏        | 26/219 [00:50<05:38,  1.76s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Vortex_tube
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Vortex_tube
 12%|█▏        | 27/219 [00:51<04:54,  1.53s/it]INFO:__main__:Requesting https://colab.research.google.com/github/JuliaTPU/XLA.jl/blob/master/examples/3_LSTM_DistributedTraining.ipynb
INFO:__main__:Getting metadata for https://colab.research.google.com/github/JuliaTPU/XLA.jl/blob/master/examples/3_LSTM_DistributedTraining.ipynb
ERROR:__main__:Could not get metadata for https://colab.research.google.com/github/JuliaTPU/XLA.jl/blob/master/examples/3_LSTM_DistributedTraining.ipynb
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 13%|█▎        | 28/219 [00:51<03:39,  1.15s/it]INFO:__main__:Requesting https://github.com/staticfloat
INFO:__main__:Getting metadata for https://github.com/staticfloat
 13%|█▎        | 29/219 [00:54<04:58,  1.57s/it]INFO:__main__:Requesting http://karpathy.github.io/2015/05/21/rnn-effectiveness/
INFO:__main__:Getting metadata for http://karpathy.github.io/2015/05/21/rnn-effectiveness/
 14%|█▎        | 30/219 [00:54<03:58,  1.26s/it]INFO:__main__:Requesting https://arxiv.org/abs/1810.09868
INFO:__main__:Getting metadata for https://arxiv.org/abs/1810.09868
 14%|█▍        | 31/219 [00:56<03:53,  1.24s/it]INFO:__main__:Requesting https://github.com/JuliaGPU/CUDAnative.jl
INFO:__main__:Getting metadata for https://github.com/JuliaGPU/CUDAnative.jl
 15%|█▍        | 32/219 [00:57<03:38,  1.17s/it]INFO:__main__:Requesting https://medium.com/@mapmeld/esperanto-nlp-part-3-correcting-grammar-6d34f93bded1
INFO:__main__:Getting metadata for https://medium.com/@mapmeld/esperanto-nlp-part-3-correcting-grammar-6d34f93bded1
 15%|█▌        | 33/219 [00:57<03:00,  1.03it/s]INFO:__main__:Requesting https://redalemeden.com/blog/2019/we-need-chrome-no-more
INFO:__main__:Getting metadata for https://redalemeden.com/blog/2019/we-need-chrome-no-more/
 16%|█▌        | 34/219 [00:58<02:56,  1.05it/s]INFO:__main__:Requesting https://news.softpedia.com/news/Lead-Firebug-Developer-Joins-Google-Chrome-Team-212278.shtml
INFO:__main__:Getting metadata for https://news.softpedia.com/news/Lead-Firebug-Developer-Joins-Google-Chrome-Team-212278.shtml
 16%|█▌        | 35/219 [07:32<6:04:42, 118.92s/it]INFO:__main__:Requesting https://9to5google.com/2018/12/03/microsoft-chrome-based-browser/
INFO:__main__:Getting metadata for https://9to5google.com/2018/12/03/microsoft-chrome-based-browser/
 16%|█▋        | 36/219 [07:33<4:14:28, 83.44s/it] INFO:__main__:Requesting https://bugzilla.mozilla.org/show_bug.cgi?id=885508#c49
 17%|█▋        | 37/219 [07:33<2:57:31, 58.53s/it]INFO:__main__:Requesting https://www.google.com/googlebooks/chrome/
INFO:__main__:Getting metadata for https://www.google.com/googlebooks/chrome/
 17%|█▋        | 38/219 [07:33<2:03:43, 41.01s/it]INFO:__main__:Requesting https://imgur.com/gallery/WWZxj
INFO:__main__:Getting metadata for https://imgur.com/gallery/WWZxj
 18%|█▊        | 39/219 [07:34<1:26:55, 28.97s/it]INFO:__main__:Requesting https://googleblog.blogspot.com/2008/09/fresh-take-on-browser.html
INFO:__main__:Getting metadata for https://googleblog.blogspot.com/2008/09/fresh-take-on-browser.html
 18%|█▊        | 40/219 [07:35<1:00:46, 20.37s/it]INFO:__main__:Requesting https://getpolarized.io/
INFO:__main__:Getting metadata for https://getpolarized.io
 19%|█▊        | 41/219 [07:35<42:37, 14.37s/it]  INFO:__main__:Requesting https://developers.google.com/web/updates/2019/01/devtools
INFO:__main__:Getting metadata for https://developers.google.com/web/updates/2019/01/devtools
 19%|█▉        | 42/219 [07:36<30:21, 10.29s/it]INFO:__main__:Requesting https://developers.google.com/web/updates/2018/05/devtools
INFO:__main__:Getting metadata for https://developers.google.com/web/updates/2018/05/devtools
 20%|█▉        | 43/219 [07:37<21:47,  7.43s/it]INFO:__main__:Requesting https://developer.mozilla.org/en-US/docs/Tools/Page_Inspector/How_to/Examine_grid_layouts
INFO:__main__:Getting metadata for https://developer.mozilla.org/en-US/docs/Tools/Page_Inspector/How_to/Examine_grid_layouts
 20%|██        | 44/219 [07:37<15:34,  5.34s/it]INFO:__main__:Requesting https://www.xkcd.com/1053/
INFO:__main__:Getting metadata for https://www.xkcd.com/1053/
 21%|██        | 45/219 [07:38<11:17,  3.89s/it]INFO:__main__:Requesting http://gs.statcounter.com/browser-market-share#monthly-200901-201902
INFO:__main__:Getting metadata for http://gs.statcounter.com/browser-market-share#monthly-200901-201902
 21%|██        | 46/219 [07:38<08:27,  2.93s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Internet_Explorer#/media/File:Internet-explorer-usage-data.svg
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Internet_Explorer#/media/File:Internet-explorer-usage-data.svg
 21%|██▏       | 47/219 [07:42<08:54,  3.11s/it]INFO:__main__:Requesting https://www.cnet.com/news/google-firefox-search-deal-gives-mozilla-more-money-to-push-privacy/
INFO:__main__:Getting metadata for https://www.cnet.com/news/google-firefox-search-deal-gives-mozilla-more-money-to-push-privacy/
 22%|██▏       | 48/219 [07:43<07:10,  2.52s/it]INFO:__main__:Requesting https://github.com/chromium/chromium
INFO:__main__:Getting metadata for https://github.com/chromium/chromium
 22%|██▏       | 49/219 [07:44<06:01,  2.13s/it]INFO:__main__:Requesting https://github.com/mozilla/gecko-dev
INFO:__main__:Getting metadata for https://github.com/mozilla/gecko-dev
 23%|██▎       | 50/219 [07:45<05:04,  1.80s/it]INFO:__main__:Requesting https://developer.microsoft.com/en-us/windows/pwa
INFO:__main__:Getting metadata for https://developer.microsoft.com/en-us/windows/pwa
 23%|██▎       | 51/219 [07:47<05:23,  1.93s/it]INFO:__main__:Requesting https://github.com/nodejs/node-chakracore
INFO:__main__:Getting metadata for https://github.com/nodejs/node-chakracore
 24%|██▎       | 52/219 [07:48<04:36,  1.65s/it]INFO:__main__:Requesting https://github.com/Microsoft/ChakraCore/issues/5865
INFO:__main__:Getting metadata for https://github.com/Microsoft/ChakraCore/issues/5865
 24%|██▍       | 53/219 [07:52<06:02,  2.19s/it]INFO:__main__:Requesting https://pianop.ly/
INFO:__main__:Getting metadata for https://pianop.ly
ERROR:__main__:Could not get metadata for https://pianop.ly
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 25%|██▍       | 54/219 [07:53<05:24,  1.97s/it]INFO:__main__:Requesting https://www.adsoftheworld.com/media/film/google_chrome_speed_tests
INFO:__main__:Getting metadata for https://www.adsoftheworld.com/media/film/google_chrome_speed_tests
ERROR:__main__:Could not get metadata for https://www.adsoftheworld.com/media/film/google_chrome_speed_tests
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 25%|██▌       | 55/219 [07:57<06:29,  2.37s/it]INFO:__main__:Requesting https://arstechnica.com/information-technology/2013/04/google-going-its-own-way-forking-webkit-rendering-engine/
INFO:__main__:Getting metadata for https://arstechnica.com/information-technology/2013/04/google-going-its-own-way-forking-webkit-rendering-engine/
 26%|██▌       | 56/219 [07:57<04:44,  1.75s/it]INFO:__main__:Requesting https://blog.chromium.org/2013/04/blink-rendering-engine-for-chromium.html
INFO:__main__:Getting metadata for https://blog.chromium.org/2013/04/blink-rendering-engine-for-chromium.html
 26%|██▌       | 57/219 [07:57<03:31,  1.30s/it]INFO:__main__:Requesting https://www.qutebrowser.org
INFO:__main__:Getting metadata for https://www.qutebrowser.org
 26%|██▋       | 58/219 [08:00<04:49,  1.80s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Chromium_(web_browser)#2008
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Chromium_(web_browser)#2008
 27%|██▋       | 59/219 [08:02<05:12,  1.95s/it]INFO:__main__:Requesting https://support.mozilla.org/en-US/kb/containers
INFO:__main__:Getting metadata for https://support.mozilla.org/en-US/kb/containers
 27%|██▋       | 60/219 [08:05<05:33,  2.10s/it]INFO:__main__:Requesting https://addons.mozilla.org/en-US/firefox/addon/chrome-store-foxified/
INFO:__main__:Getting metadata for https://addons.mozilla.org/en-US/firefox/addon/chrome-store-foxified/
 28%|██▊       | 61/219 [08:06<04:57,  1.89s/it]INFO:__main__:Requesting https://support.brave.com/hc/en-us/articles/360017909112-How-can-I-add-extensions-to-Brave-
INFO:__main__:Getting metadata for https://support.brave.com/hc/en-us/articles/360017909112-How-can-I-add-extensions-to-Brave-
 28%|██▊       | 62/219 [08:07<03:53,  1.49s/it]INFO:__main__:Requesting https://aleksandarmilicevic.github.io/hola/
INFO:__main__:Getting metadata for https://aleksandarmilicevic.github.io/hola/
 29%|██▉       | 63/219 [08:08<03:17,  1.26s/it]INFO:__main__:Requesting http://gpu.rocks
INFO:__main__:Getting metadata for http://gpu.rocks
ERROR:__main__:Could not get metadata for http://gpu.rocks
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 29%|██▉       | 64/219 [08:08<02:31,  1.02it/s]INFO:__main__:Requesting https://github.com/gpujs/gpu.js/blob/develop/src/backend/web-gl2/fragment-shader.js#L40
INFO:__main__:Getting metadata for https://github.com/gpujs/gpu.js/blob/develop/src/backend/web-gl2/fragment-shader.js#L40
 30%|██▉       | 65/219 [08:09<02:29,  1.03it/s]INFO:__main__:Requesting http://raytracer.crypt.sg/
INFO:__main__:Getting metadata for http://raytracer.crypt.sg
ERROR:__main__:Could not get metadata for http://raytracer.crypt.sg
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 30%|███       | 66/219 [08:09<02:11,  1.16it/s]INFO:__main__:Requesting https://turdnagel.com/cells/
INFO:__main__:Getting metadata for https://turdnagel.com/cells/
ERROR:__main__:Could not get metadata for https://turdnagel.com/cells/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 31%|███       | 67/219 [08:10<02:03,  1.23it/s]INFO:__main__:Requesting https://www.zdnet.com/article/new-browser-attack-lets-hackers-run-bad-code-even-after-users-leave-a-web-page/
INFO:__main__:Getting metadata for https://www.zdnet.com/article/new-browser-attack-lets-hackers-run-bad-code-even-after-users-leave-a-web-page/
 31%|███       | 68/219 [08:11<01:53,  1.33it/s]INFO:__main__:Requesting https://js.tensorflow.org/
INFO:__main__:Getting metadata for https://js.tensorflow.org
 32%|███▏      | 69/219 [08:11<01:25,  1.76it/s]INFO:__main__:Requesting https://breakingdefense.com/2019/02/pentagon-to-retire-uss-truman-early-shrinking-carrier-fleet-to-10/
INFO:__main__:Getting metadata for https://breakingdefense.com/2019/02/pentagon-to-retire-uss-truman-early-shrinking-carrier-fleet-to-10/
ERROR:__main__:Could not get metadata for https://breakingdefense.com/2019/02/pentagon-to-retire-uss-truman-early-shrinking-carrier-fleet-to-10/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 32%|███▏      | 70/219 [08:11<01:17,  1.92it/s]INFO:__main__:Requesting https://www.gremlin.com/blog/introducing-gremlin-free/
INFO:__main__:Getting metadata for https://www.gremlin.com/blog/introducing-gremlin-free/
 32%|███▏      | 71/219 [08:12<01:41,  1.45it/s]INFO:__main__:Requesting https://www.gremlin.com/docs/infrastructure-layer/installation/
INFO:__main__:Getting metadata for https://www.gremlin.com/docs/infrastructure-layer/installation/
 33%|███▎      | 72/219 [08:13<02:00,  1.22it/s]INFO:__main__:Requesting https://www.rust-lang.org/production/users
INFO:__main__:Getting metadata for https://www.rust-lang.org/production/users
 33%|███▎      | 73/219 [08:14<01:47,  1.36it/s]INFO:__main__:Requesting https://www.gremlin.com/docs/application-layer/overview/
INFO:__main__:Getting metadata for https://www.gremlin.com/docs/application-layer/overview/
 34%|███▍      | 74/219 [08:15<02:07,  1.13it/s]INFO:__main__:Requesting https://www.gremlin.com/slack
INFO:__main__:Getting metadata for https://slofile.com/slack/chaosengineering
 34%|███▍      | 75/219 [08:16<02:01,  1.18it/s]INFO:__main__:Requesting https://www.gremlin.com/chaos-monkey/chaos-monkey-alternatives/
INFO:__main__:Getting metadata for https://www.gremlin.com/chaos-monkey/chaos-monkey-alternatives/
 35%|███▍      | 76/219 [08:17<02:19,  1.02it/s]INFO:__main__:Requesting https://github.com/Netflix/SimianArmy
INFO:__main__:Getting metadata for https://github.com/Netflix/SimianArmy
 35%|███▌      | 77/219 [08:18<02:26,  1.03s/it]INFO:__main__:Requesting http://www.apache.org/foundation/marks/faq/
INFO:__main__:Getting metadata for http://www.apache.org/foundation/marks/faq/
 36%|███▌      | 78/219 [08:20<02:44,  1.16s/it]INFO:__main__:Requesting https://www.cbsnews.com/pictures/worlds-15-ugliest-cars/7/
INFO:__main__:Getting metadata for https://www.cbsnews.com/pictures/worlds-15-ugliest-cars/7/
 36%|███▌      | 79/219 [08:20<02:09,  1.08it/s]INFO:__main__:Requesting https://trademarks.justia.com/871/94/gremlin-87194877.html
INFO:__main__:Getting metadata for https://trademarks.justia.com/871/94/gremlin-87194877.html
 37%|███▋      | 80/219 [08:21<01:42,  1.36it/s]INFO:__main__:Requesting https://www.rafflecopter.com/
INFO:__main__:Getting metadata for https://www.rafflecopter.com
 37%|███▋      | 81/219 [08:21<01:22,  1.67it/s]INFO:__main__:Requesting https://www.microsoft.com/security/blog/2013/06/13/exploitable-crash-analyzer-version-1-6/
INFO:__main__:Getting metadata for https://www.microsoft.com/security/blog/2013/06/13/exploitable-crash-analyzer-version-1-6/
 37%|███▋      | 82/219 [08:22<01:53,  1.21it/s]INFO:__main__:Requesting https://github.com/jfoote/exploitable
INFO:__main__:Getting metadata for https://github.com/jfoote/exploitable
 38%|███▊      | 83/219 [08:23<02:08,  1.06it/s]INFO:__main__:Requesting https://github.com/sslab-gatech/perf-fuzz/
INFO:__main__:Getting metadata for https://github.com/sslab-gatech/perf-fuzz/
 38%|███▊      | 84/219 [08:24<02:08,  1.05it/s]INFO:__main__:Requesting https://labelbox.com/buy-vs-build
INFO:__main__:Getting metadata for https://labelbox.com/buy-vs-build
 39%|███▉      | 85/219 [08:25<02:06,  1.06it/s]INFO:__main__:Requesting https://hypothesis.readthedocs.io/en/latest/
INFO:__main__:Getting metadata for https://hypothesis.readthedocs.io/en/latest/
 39%|███▉      | 86/219 [08:27<02:44,  1.24s/it]INFO:__main__:Requesting https://github.com/trailofbits/deepstate
INFO:__main__:Getting metadata for https://github.com/trailofbits/deepstate
 40%|███▉      | 87/219 [08:29<02:44,  1.25s/it]INFO:__main__:Requesting https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition
INFO:__main__:Getting metadata for https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition
 40%|████      | 88/219 [08:30<02:35,  1.19s/it]INFO:__main__:Requesting https://jobs.lever.co/pachyderm/
INFO:__main__:Getting metadata for https://jobs.lever.co/pachyderm/
 41%|████      | 89/219 [08:30<02:17,  1.05s/it]INFO:__main__:Requesting https://cacm.acm.org/magazines/2019/3/234913-lost-in-math/fulltext
INFO:__main__:Getting metadata for https://cacm.acm.org/magazines/2019/3/234913-lost-in-math/fulltext
 41%|████      | 90/219 [08:35<04:53,  2.27s/it]INFO:__main__:Requesting http://www.cs.utexas.edu/users/EWD/transcriptions/EWD12xx/EWD1243a.html
INFO:__main__:Getting metadata for http://www.cs.utexas.edu/users/EWD/transcriptions/EWD12xx/EWD1243a.html
 42%|████▏     | 91/219 [08:36<03:36,  1.69s/it]INFO:__main__:Requesting http://learnyouahaskell.com/
INFO:__main__:Getting metadata for http://learnyouahaskell.com
ERROR:__main__:Could not get metadata for http://learnyouahaskell.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 42%|████▏     | 92/219 [08:37<03:02,  1.44s/it]INFO:__main__:Requesting https://github.com/data61/fp-course
INFO:__main__:Getting metadata for https://github.com/data61/fp-course
 42%|████▏     | 93/219 [08:37<02:40,  1.28s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=FGtsqEwANWY&feature=youtu.be&list=PLgKuh-lKre12S9FgcsgxlaoEkgNZuqeNc
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=FGtsqEwANWY&feature=youtu.be&list=PLgKuh-lKre12S9FgcsgxlaoEkgNZuqeNc
 43%|████▎     | 94/219 [08:38<02:25,  1.16s/it]INFO:__main__:Requesting http://backreaction.blogspot.com/2019/02/a-philosopher-of-science-reviews-lost.html
INFO:__main__:Getting metadata for http://backreaction.blogspot.com/2019/02/a-philosopher-of-science-reviews-lost.html
 43%|████▎     | 95/219 [08:39<02:03,  1.00it/s]INFO:__main__:Requesting https://github.com/antontarasenko/hacker-news-groups
INFO:__main__:Getting metadata for https://github.com/antontarasenko/hacker-news-groups
 44%|████▍     | 96/219 [08:40<02:00,  1.02it/s]INFO:__main__:Requesting https://hackernoon.com/stop-using-io-domain-names-for-production-traffic-b6aa17eeac20
INFO:__main__:Getting metadata for https://hackernoon.com/stop-using-io-domain-names-for-production-traffic-b6aa17eeac20?gi=a4e7c83a4746
 44%|████▍     | 97/219 [08:42<02:35,  1.27s/it]INFO:__main__:Requesting https://spectrum.chat/canada
INFO:__main__:Getting metadata for https://spectrum.chat/canada
 45%|████▍     | 98/219 [08:44<02:59,  1.48s/it]INFO:__main__:Requesting https://www.secbsd.org/
INFO:__main__:Getting metadata for https://www.secbsd.org
ERROR:__main__:Could not get metadata for https://www.secbsd.org
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 45%|████▌     | 99/219 [08:47<03:53,  1.95s/it]INFO:__main__:Requesting https://webcache.googleusercontent.com/search?q=cache:E2OiV-7ZhGIJ:https://secbsd.org/dark-intelligence-team.html
INFO:__main__:Getting metadata for https://webcache.googleusercontent.com/search?q=cache:E2OiV-7ZhGIJ:https://secbsd.org/dark-intelligence-team.html
 46%|████▌     | 100/219 [08:50<04:15,  2.15s/it]INFO:__main__:Requesting https://www.allacronyms.com/TCB
INFO:__main__:Getting metadata for https://www.allacronyms.com/TCB
 46%|████▌     | 101/219 [08:50<03:11,  1.62s/it]INFO:__main__:Requesting https://longform.org/posts/the-mastermind
INFO:__main__:Getting metadata for https://longform.org/posts/the-mastermind
 47%|████▋     | 102/219 [08:50<02:26,  1.25s/it]INFO:__main__:Requesting https://www.gimletmedia.com/reply-all/the-founder#episode-player
INFO:__main__:Getting metadata for https://www.gimletmedia.com/reply-all/the-founder#episode-player
ERROR:__main__:Could not get metadata for https://www.gimletmedia.com/reply-all/the-founder#episode-player
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 47%|████▋     | 103/219 [08:51<02:11,  1.13s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=MTeonvkHKDk
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=MTeonvkHKDk
 47%|████▋     | 104/219 [08:52<02:00,  1.05s/it]INFO:__main__:Requesting https://www.vulture.com/amp/2019/02/michael-mann-and-elaine-shannon-talk-on-hunting-leroux.html
INFO:__main__:Getting metadata for https://www.vulture.com/amp/2019/02/michael-mann-and-elaine-shannon-talk-on-hunting-leroux.html
 48%|████▊     | 105/219 [08:52<01:32,  1.24it/s]INFO:__main__:Requesting https://www.newyorker.com/magazine/2019/03/04/how-much-a-dementia-patient-needs-to-know
INFO:__main__:Getting metadata for https://www.newyorker.com/magazine/2019/03/04/how-much-a-dementia-patient-needs-to-know
 48%|████▊     | 106/219 [08:53<01:15,  1.50it/s]INFO:__main__:Requesting https://gizmodo.com/inside-an-amazing-village-designed-just-for-people-with-1526062373
INFO:__main__:Getting metadata for https://gizmodo.com/inside-an-amazing-village-designed-just-for-people-with-1526062373
 49%|████▉     | 107/219 [08:53<01:02,  1.80it/s]INFO:__main__:Requesting https://www.newyorker.com/magazine/2018/10/08/the-comforting-fictions-of-dementia-care
INFO:__main__:Getting metadata for https://www.newyorker.com/magazine/2018/10/08/the-comforting-fictions-of-dementia-care
 49%|████▉     | 108/219 [08:53<00:52,  2.10it/s]INFO:__main__:Requesting https://bicycledutch.wordpress.com/2019/02/27/the-1979-delft-cycle-plan/
ERROR:__main__:Could not reach https://bicycledutch.wordpress.com/2019/02/27/the-1979-delft-cycle-plan/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 50%|████▉     | 109/219 [08:53<00:41,  2.67it/s]INFO:__main__:Requesting https://k3s.io
INFO:__main__:Getting metadata for https://k3s.io
 50%|█████     | 110/219 [08:54<00:49,  2.20it/s]INFO:__main__:Requesting https://fosdem.org/2019/schedule/event/hw_gitlab_ci_arduino/
INFO:__main__:Getting metadata for https://fosdem.org/2019/schedule/event/hw_gitlab_ci_arduino/
ERROR:__main__:Could not get metadata for https://fosdem.org/2019/schedule/event/hw_gitlab_ci_arduino/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 51%|█████     | 111/219 [08:55<01:11,  1.50it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Erlang_(programming_language)
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Erlang_(programming_language)
 51%|█████     | 112/219 [08:56<01:32,  1.16it/s]INFO:__main__:Requesting http://erlang.org/pipermail/erlang-questions/2008-October/039261.html
INFO:__main__:Getting metadata for http://erlang.org/pipermail/erlang-questions/2008-October/039261.html
 52%|█████▏    | 113/219 [08:59<02:33,  1.45s/it]INFO:__main__:Requesting https://github.com/rancher/k3s/blob/master/README.md#what-is-this
INFO:__main__:Getting metadata for https://github.com/rancher/k3s/blob/master/README.md#what-is-this
 52%|█████▏    | 114/219 [09:00<02:12,  1.26s/it]INFO:__main__:Requesting https://github.com/rancher/k3s/blob/master/README.md#server-ha
INFO:__main__:Getting metadata for https://github.com/rancher/k3s/blob/master/README.md#server-ha
 53%|█████▎    | 115/219 [09:01<01:55,  1.11s/it]INFO:__main__:Requesting https://github.com/rancher/k3s/search?q=ingress&type=Commits
INFO:__main__:Getting metadata for https://github.com/rancher/k3s/search?q=ingress&type=Commits
 53%|█████▎    | 116/219 [09:02<01:44,  1.02s/it]INFO:__main__:Requesting https://twitter.com/kelseyhightower/status/935252923721793536
INFO:__main__:Getting metadata for https://twitter.com/kelseyhightower/status/935252923721793536
 53%|█████▎    | 117/219 [09:02<01:38,  1.03it/s]INFO:__main__:Requesting https://youtu.be/mMpZpa7uUSk
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=mMpZpa7uUSk&feature=youtu.be
 54%|█████▍    | 118/219 [09:03<01:37,  1.04it/s]INFO:__main__:Requesting https://landscape.cncf.io/category=certified-kubernetes-distribution,certified-kubernetes-hosted,certified-kubernetes-installer&format=card-mode&grouping=category&selected=k3s
INFO:__main__:Getting metadata for https://landscape.cncf.io/category=certified-kubernetes-distribution,certified-kubernetes-hosted,certified-kubernetes-installer&format=card-mode&grouping=category&selected=k3s
ERROR:__main__:Could not get metadata for https://landscape.cncf.io/category=certified-kubernetes-distribution,certified-kubernetes-hosted,certified-kubernetes-installer&format=card-mode&grouping=category&selected=k3s
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 54%|█████▍    | 119/219 [09:04<01:24,  1.19it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=5-5t672vFi4
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=5-5t672vFi4
 55%|█████▍    | 120/219 [09:05<01:24,  1.18it/s]INFO:__main__:Requesting https://medium.com/@cfatechblog/bare-metal-k8s-clustering-at-chick-fil-a-scale-7b0607bd3541
INFO:__main__:Getting metadata for https://medium.com/@cfatechblog/bare-metal-k8s-clustering-at-chick-fil-a-scale-7b0607bd3541
 55%|█████▌    | 121/219 [09:05<01:10,  1.39it/s]INFO:__main__:Requesting https://thenewstack.io/rancher-takes-kubernetes-management-to-china/
INFO:__main__:Getting metadata for https://thenewstack.io/rancher-takes-kubernetes-management-to-china/
 56%|█████▌    | 122/219 [09:06<01:00,  1.61it/s]INFO:__main__:Requesting https://www.sqlite.org/famous.html
INFO:__main__:Getting metadata for https://www.sqlite.org/famous.html
ERROR:__main__:Could not get metadata for https://www.sqlite.org/famous.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 56%|█████▌    | 123/219 [09:07<01:09,  1.38it/s]INFO:__main__:Requesting https://godoc.org/github.com/etcd-io/etcd/embed
INFO:__main__:Getting metadata for https://godoc.org/github.com/etcd-io/etcd/embed
 57%|█████▋    | 124/219 [09:07<00:55,  1.72it/s]INFO:__main__:Requesting https://github.com/lxc/lxd/blob/master/doc/database.md
INFO:__main__:Getting metadata for https://github.com/lxc/lxd/blob/master/doc/database.md
 57%|█████▋    | 125/219 [09:08<00:58,  1.62it/s]INFO:__main__:Requesting https://github.com/CanonicalLtd/dqlite
INFO:__main__:Getting metadata for https://github.com/CanonicalLtd/dqlite
 58%|█████▊    | 126/219 [09:09<01:09,  1.34it/s]INFO:__main__:Requesting https://blog.hasura.io/draft-vs-gitkube-vs-helm-vs-ksonnet-vs-metaparticle-vs-skaffold-f5aa9561f948/
INFO:__main__:Getting metadata for https://blog.hasura.io/draft-vs-gitkube-vs-helm-vs-ksonnet-vs-metaparticle-vs-skaffold-f5aa9561f948/
 58%|█████▊    | 127/219 [09:10<01:33,  1.02s/it]INFO:__main__:Requesting https://kubernetes.io/blog/2018/05/01/developing-on-kubernetes/
INFO:__main__:Getting metadata for https://kubernetes.io/blog/2018/05/01/developing-on-kubernetes/
 58%|█████▊    | 128/219 [09:12<02:01,  1.34s/it]INFO:__main__:Requesting http://www.pidramble.com
INFO:__main__:Getting metadata for http://www.pidramble.com
 59%|█████▉    | 129/219 [09:13<01:34,  1.05s/it]INFO:__main__:Requesting https://electronics.stackexchange.com/questions/32200/why-is-spi-flash-memory-so-limited-in-max-size-and-cost-way-more-per-mb-than
INFO:__main__:Getting metadata for https://electronics.stackexchange.com/questions/32200/why-is-spi-flash-memory-so-limited-in-max-size-and-cost-way-more-per-mb-than
 59%|█████▉    | 130/219 [09:13<01:14,  1.19it/s]INFO:__main__:Requesting https://github.com/rancher/k3s#flannel
INFO:__main__:Getting metadata for https://github.com/rancher/k3s#flannel
 60%|█████▉    | 131/219 [09:14<01:14,  1.18it/s]INFO:__main__:Requesting https://bugs.chromium.org/p/chromium/issues/detail?id=878034
INFO:__main__:Getting metadata for https://bugs.chromium.org/p/chromium/issues/detail?id=878034
ERROR:__main__:Could not get metadata for https://bugs.chromium.org/p/chromium/issues/detail?id=878034
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 60%|██████    | 132/219 [09:16<01:46,  1.22s/it]INFO:__main__:Requesting https://medium.com/@kvaps/run-kubernetes-in-lxc-container-f04aa94b6c9c
INFO:__main__:Getting metadata for https://medium.com/@kvaps/run-kubernetes-in-lxc-container-f04aa94b6c9c
 61%|██████    | 133/219 [09:17<01:25,  1.00it/s]INFO:__main__:Requesting https://lwn.net/SubscriberLink/780710/ece0f8b930151422/
INFO:__main__:Getting metadata for https://lwn.net/SubscriberLink/780710/ece0f8b930151422/
 61%|██████    | 134/219 [09:18<01:40,  1.18s/it]INFO:__main__:Requesting https://techcrunch.com/2019/02/27/dow-jones-watchlist-leak/
ERROR:__main__:Could not reach https://techcrunch.com/2019/02/27/dow-jones-watchlist-leak/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 62%|██████▏   | 135/219 [09:18<01:12,  1.16it/s]INFO:__main__:Requesting http://lexindicium.com/2018/03/19/data-mining-and-gdpr-compliance/
INFO:__main__:Getting metadata for http://lexindicium.com/2018/03/19/data-mining-and-gdpr-compliance/
 62%|██████▏   | 136/219 [09:20<01:25,  1.03s/it]INFO:__main__:Requesting https://ec.europa.eu/info/law/law-topic/data-protection/reform/rights-citizens/my-rights/what-are-my-rights_en
INFO:__main__:Getting metadata for https://ec.europa.eu/info/law/law-topic/data-protection/reform/rights-citizens/my-rights/what-are-my-rights_en
ERROR:__main__:Could not get metadata for https://ec.europa.eu/info/law/law-topic/data-protection/reform/rights-citizens/my-rights/what-are-my-rights_en
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 63%|██████▎   | 137/219 [09:21<01:30,  1.10s/it]INFO:__main__:Requesting https://www.eetimes.com/document.asp?doc_id=1334373
ERROR:__main__:Could not reach https://www.eetimes.com/document.asp?doc_id=1334373
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.eetimes.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.eetimes.com', port=443): Read timed out. (read timeout=6)
 63%|██████▎   | 138/219 [09:27<03:32,  2.62s/it]INFO:__main__:Requesting https://training.ti.com/tis-bulk-acoustic-wave-clocking-technology-0
INFO:__main__:Getting metadata for https://training.ti.com/tis-bulk-acoustic-wave-clocking-technology-0
ERROR:__main__:Could not get metadata for https://training.ti.com/tis-bulk-acoustic-wave-clocking-technology-0
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 63%|██████▎   | 139/219 [09:28<02:39,  1.99s/it]INFO:__main__:Requesting https://www.nature.com/articles/d41586-019-00577-0
INFO:__main__:Getting metadata for https://www.nature.com/articles/d41586-019-00577-0
 64%|██████▍   | 140/219 [09:30<02:43,  2.07s/it]INFO:__main__:Requesting https://physicsfm-frontiers.blogspot.com
INFO:__main__:Getting metadata for https://physicsfm-frontiers.blogspot.com
ERROR:__main__:Could not get metadata for https://physicsfm-frontiers.blogspot.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 64%|██████▍   | 141/219 [09:30<01:59,  1.53s/it]INFO:__main__:Requesting https://www.preposterousuniverse.com/podcast/
INFO:__main__:Getting metadata for https://www.preposterousuniverse.com/podcast/
 65%|██████▍   | 142/219 [09:31<01:36,  1.25s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Semi-empirical_mass_formula
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Semi-empirical_mass_formula
 65%|██████▌   | 143/219 [09:33<01:48,  1.42s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Neutron
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Neutron
 66%|██████▌   | 144/219 [09:35<02:06,  1.69s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Neutron#Description
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Neutron#Description
 66%|██████▌   | 145/219 [09:37<02:19,  1.88s/it]INFO:__main__:Requesting https://commons.wikimedia.org/wiki/File:Beta_Negative_Decay.svg
INFO:__main__:Getting metadata for https://commons.wikimedia.org/wiki/File:Beta_Negative_Decay.svg
 67%|██████▋   | 146/219 [09:38<01:56,  1.60s/it]INFO:__main__:Requesting https://pubs.rsc.org/en/content/articlehtml/2013/cp/c3cp51500a
INFO:__main__:Getting metadata for https://pubs.rsc.org/en/content/articlehtml/2013/cp/c3cp51500a
ERROR:__main__:Could not get metadata for https://pubs.rsc.org/en/content/articlehtml/2013/cp/c3cp51500a
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 34, in __init__
    res = requests.get(url, timeout=timeout, headers=headers)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 131, in __init__
    super(SocialPreviewBase, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 36, in __init__
    raise URLUnreachable("The URL does not exist.")
webpreview.excepts.URLUnreachable: The URL does not exist.
 67%|██████▋   | 147/219 [09:40<02:03,  1.72s/it]INFO:__main__:Requesting https://www.confluent.io/blog/noise-mapping-ksql-raspberry-pi-software-defined-radio
INFO:__main__:Getting metadata for https://www.confluent.io/blog/noise-mapping-ksql-raspberry-pi-software-defined-radio
 68%|██████▊   | 148/219 [09:40<01:27,  1.24s/it]INFO:__main__:Requesting https://webtrak.emsbk.com/lax4
INFO:__main__:Getting metadata for https://webtrak.emsbk.com/lax4
 68%|██████▊   | 149/219 [09:42<01:32,  1.33s/it]INFO:__main__:Requesting https://www.nytimes.com/2019/02/26/dining/homemade-yogurt-starter-south-asia.html
INFO:__main__:Getting metadata for https://www.nytimes.com/2019/02/26/dining/homemade-yogurt-starter-south-asia.html
 68%|██████▊   | 150/219 [09:42<01:09,  1.00s/it]INFO:__main__:Requesting https://www.bobsredmill.com/sourdough-starter.html
INFO:__main__:Getting metadata for https://www.bobsredmill.com/sourdough-starter.html
 69%|██████▉   | 151/219 [09:45<01:49,  1.61s/it]INFO:__main__:Requesting https://cooking.nytimes.com/recipes/11376-no-knead-bread
INFO:__main__:Getting metadata for https://cooking.nytimes.com/recipes/11376-no-knead-bread
 69%|██████▉   | 152/219 [09:45<01:19,  1.19s/it]INFO:__main__:Requesting https://www.womenshealthmag.com/nl/voeding/feiten-fabels/a23733982/yoghurt-verschillende-soorten-gezondst/
INFO:__main__:Getting metadata for https://www.womenshealthmag.com/nl/voeding/feiten-fabels/a23733982/yoghurt-verschillende-soorten-gezondst/
 70%|██████▉   | 153/219 [09:46<01:09,  1.06s/it]INFO:__main__:Requesting https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4166373/
INFO:__main__:Getting metadata for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4166373/
 70%|███████   | 154/219 [09:47<01:15,  1.17s/it]INFO:__main__:Requesting https://github.com/cablespaghetti/kubeadm-aws
INFO:__main__:Getting metadata for https://github.com/cablespaghetti/kubeadm-aws
 71%|███████   | 155/219 [09:48<01:09,  1.08s/it]INFO:__main__:Requesting https://github.com/hobby-kube/guide
INFO:__main__:Getting metadata for https://github.com/hobby-kube/guide
 71%|███████   | 156/219 [09:49<01:06,  1.06s/it]INFO:__main__:Requesting https://www.ovh.co.uk/kubernetes/
INFO:__main__:Getting metadata for https://www.ovh.co.uk/kubernetes/
 72%|███████▏  | 157/219 [09:51<01:10,  1.14s/it]INFO:__main__:Requesting https://www.hetzner.com/rechtliches/agb
INFO:__main__:Getting metadata for https://www.hetzner.com/rechtliches/agb
 72%|███████▏  | 158/219 [09:55<02:08,  2.10s/it]INFO:__main__:Requesting https://github.com/GoogleContainerTools/kubehost
INFO:__main__:Getting metadata for https://github.com/GoogleContainerTools/kubehost
 73%|███████▎  | 159/219 [09:56<01:46,  1.77s/it]INFO:__main__:Requesting https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-configuring.html
INFO:__main__:Getting metadata for https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-configuring.html
 73%|███████▎  | 160/219 [09:57<01:30,  1.54s/it]INFO:__main__:Requesting https://www.radishlogic.com/kubernetes/running-minikube-in-aws-ec2-ubuntu/
INFO:__main__:Getting metadata for https://www.radishlogic.com/kubernetes/running-minikube-in-aws-ec2-ubuntu/
 74%|███████▎  | 161/219 [10:00<01:45,  1.82s/it]INFO:__main__:Requesting https://aws.amazon.com/fargate/pricing/
INFO:__main__:Getting metadata for https://aws.amazon.com/fargate/pricing/
ERROR:__main__:Could not get metadata for https://aws.amazon.com/fargate/pricing/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 74%|███████▍  | 162/219 [10:00<01:21,  1.42s/it]INFO:__main__:Requesting https://github.com/projectriff/riff/issues/1093
INFO:__main__:Getting metadata for https://github.com/projectriff/riff/issues/1093
 74%|███████▍  | 163/219 [10:02<01:24,  1.50s/it]INFO:__main__:Requesting https://github.com/knative/docs/tree/master/serving/samples/helloworld-ruby
INFO:__main__:Getting metadata for https://github.com/knative/docs/tree/master/serving/samples/helloworld-ruby
 75%|███████▍  | 164/219 [10:03<01:11,  1.29s/it]INFO:__main__:Requesting https://github.com/kubernetes/kops
INFO:__main__:Getting metadata for https://github.com/kubernetes/kops
 75%|███████▌  | 165/219 [10:03<01:04,  1.20s/it]INFO:__main__:Requesting https://www.vox.com/future-perfect/2019/2/26/18241904/lake-erie-legal-rights-personhood-nature-environment-toledo-ohio
INFO:__main__:Getting metadata for https://www.vox.com/future-perfect/2019/2/26/18241904/lake-erie-legal-rights-personhood-nature-environment-toledo-ohio
 76%|███████▌  | 166/219 [10:04<00:47,  1.11it/s]INFO:__main__:Requesting http://www.p01.org/defender_of_the_favicon/
INFO:__main__:Getting metadata for http://www.p01.org/defender_of_the_favicon/
 76%|███████▋  | 167/219 [10:05<00:56,  1.08s/it]INFO:__main__:Requesting https://github.com/jbochi/gifstreaming
INFO:__main__:Getting metadata for https://github.com/jbochi/gifstreaming
 77%|███████▋  | 168/219 [10:06<00:53,  1.04s/it]INFO:__main__:Requesting https://defseg.io/snavicon
INFO:__main__:Getting metadata for https://defseg.io/snavicon/
ERROR:__main__:Could not get metadata for https://defseg.io/snavicon/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 77%|███████▋  | 169/219 [10:07<00:43,  1.16it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Haiku_Vector_Icon_Format
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Haiku_Vector_Icon_Format
 78%|███████▊  | 170/219 [10:08<00:44,  1.09it/s]INFO:__main__:Requesting https://worldwideweb.cern.ch/
INFO:__main__:Getting metadata for https://worldwideweb.cern.ch
 78%|███████▊  | 171/219 [10:09<00:52,  1.10s/it]INFO:__main__:Requesting https://worldwideweb.cern.ch/images/wow.jpg
INFO:__main__:Getting metadata for https://worldwideweb.cern.ch/images/wow.jpg
ERROR:__main__:Could not get metadata for https://worldwideweb.cern.ch/images/wow.jpg
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 79%|███████▊  | 172/219 [10:15<02:01,  2.58s/it]INFO:__main__:Requesting https://adactio.com
INFO:__main__:Getting metadata for https://adactio.com
 79%|███████▉  | 173/219 [10:16<01:29,  1.94s/it]INFO:__main__:Requesting https://worldwideweb.cern.ch/colophon/
INFO:__main__:Getting metadata for https://worldwideweb.cern.ch/colophon/
 79%|███████▉  | 174/219 [10:18<01:30,  2.01s/it]INFO:__main__:Requesting https://imgur.com/a/KWl3iUp
INFO:__main__:Getting metadata for https://imgur.com/a/KWl3iUp
ERROR:__main__:Could not get metadata for https://imgur.com/a/KWl3iUp
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 80%|███████▉  | 175/219 [10:19<01:12,  1.66s/it]INFO:__main__:Requesting https://github.com/djrrb/CERN-www-fonts/blob/master/README.md
 80%|████████  | 176/219 [10:19<00:52,  1.23s/it]INFO:__main__:Requesting http://"
ERROR:__main__:Could not reach http://"
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 57, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 745, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 964, in send
    self.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 181, in connect
    conn = self._new_conn()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f065aaa9cc0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='%22', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f065aaa9cc0>: Failed to establish a new connection: [Errno -2] Name or service not known',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='%22', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f065aaa9cc0>: Failed to establish a new connection: [Errno -2] Name or service not known',))
INFO:__main__:Requesting https://www.zdnet.com/article/windows-10-new-study-shows-home-edition-users-are-baffled-by-updates/
INFO:__main__:Getting metadata for https://www.zdnet.com/article/windows-10-new-study-shows-home-edition-users-are-baffled-by-updates/
 81%|████████▏ | 178/219 [10:19<00:38,  1.07it/s]INFO:__main__:Requesting https://www.windowslatest.com/2017/07/23/calculator-windows-10-updated-currency-converter/
INFO:__main__:Getting metadata for https://www.windowslatest.com/2017/07/23/calculator-windows-10-updated-currency-converter/
 82%|████████▏ | 179/219 [10:20<00:31,  1.29it/s]INFO:__main__:Requesting https://linux-audit.com/livepatch-linux-kernel-updates-without-rebooting/
INFO:__main__:Getting metadata for https://linux-audit.com/livepatch-linux-kernel-updates-without-rebooting/
 82%|████████▏ | 180/219 [10:21<00:34,  1.13it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Focus_stealing
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Focus_stealing
 83%|████████▎ | 181/219 [10:22<00:32,  1.19it/s]INFO:__main__:Requesting https://support.microsoft.com/en-us/help/3159635/windows-10-update-assistant
INFO:__main__:Getting metadata for https://support.microsoft.com/en-us/help/3159635/windows-10-update-assistant
 83%|████████▎ | 182/219 [10:23<00:36,  1.03it/s]INFO:__main__:Requesting https://www.voidtools.com/
INFO:__main__:Getting metadata for https://www.voidtools.com
 84%|████████▎ | 183/219 [10:24<00:33,  1.07it/s]INFO:__main__:Requesting https://www.launchy.net/
INFO:__main__:Getting metadata for https://www.launchy.net
 84%|████████▍ | 184/219 [10:25<00:31,  1.11it/s]INFO:__main__:Requesting http://keypirinha.com/
INFO:__main__:Getting metadata for http://keypirinha.com
 84%|████████▍ | 185/219 [10:25<00:29,  1.17it/s]INFO:__main__:Requesting https://getaether.net
INFO:__main__:Getting metadata for https://getaether.net
ERROR:__main__:Could not get metadata for https://getaether.net
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 85%|████████▍ | 186/219 [10:26<00:29,  1.11it/s]INFO:__main__:Requesting https://github.com/ValveSoftware/Proton/
INFO:__main__:Getting metadata for https://github.com/ValveSoftware/Proton/
 85%|████████▌ | 187/219 [10:27<00:29,  1.09it/s]INFO:__main__:Requesting https://forums.docker.com/t/running-docker-and-virtualbox-on-the-same-machine/23578/7
INFO:__main__:Getting metadata for https://forums.docker.com/t/running-docker-and-virtualbox-on-the-same-machine/23578/7
 86%|████████▌ | 188/219 [10:28<00:25,  1.19it/s]INFO:__main__:Requesting https://forums.docker.com/t/running-docker-and-virtualbox-on..
 86%|████████▋ | 189/219 [10:28<00:20,  1.46it/s]INFO:__main__:Requesting https://mouse-jiggler.en.uptodown.com/windows
INFO:__main__:Getting metadata for https://mouse-jiggler.en.uptodown.com/windows
 87%|████████▋ | 190/219 [10:29<00:19,  1.47it/s]INFO:__main__:Requesting https://www.udse.de/en/windows-10-reboot-blocker
INFO:__main__:Getting metadata for https://www.udse.de/en/windows-10-reboot-blocker
 87%|████████▋ | 191/219 [10:34<00:53,  1.91s/it]INFO:__main__:Requesting https://www.windowscentral.com/how-prevent-windows-10-rebooting-after-installing-updates
INFO:__main__:Getting metadata for https://www.windowscentral.com/how-prevent-windows-10-rebooting-after-installing-updates
 88%|████████▊ | 192/219 [10:34<00:37,  1.40s/it]INFO:__main__:Requesting https://answers.microsoft.com/en-us/windows/forum/windows_10-update/windows-10-1809-update-deleted-all-files-from/ff608374-2686-4a08-a4c2-caa4caa6d4e1?auth=1
INFO:__main__:Getting metadata for https://answers.microsoft.com/en-us/windows/forum/windows_10-update/windows-10-1809-update-deleted-all-files-from/ff608374-2686-4a08-a4c2-caa4caa6d4e1?auth=1
 88%|████████▊ | 193/219 [10:35<00:33,  1.30s/it]INFO:__main__:Requesting https://arstechnica.com/information-technology/2013/12/exponential-algorithm-making-windows-xp-miserable-could-be-fixed/
INFO:__main__:Getting metadata for https://arstechnica.com/information-technology/2013/12/exponential-algorithm-making-windows-xp-miserable-could-be-fixed/
 89%|████████▊ | 194/219 [10:35<00:24,  1.02it/s]INFO:__main__:Requesting https://support.microsoft.com/en-us/help/4028458/windows-metered-connections-in-windows-10
INFO:__main__:Getting metadata for https://support.microsoft.com/en-us/help/4028458/windows-metered-connections-in-windows-10
 89%|████████▉ | 195/219 [10:37<00:27,  1.14s/it]INFO:__main__:Requesting https://www.confluent.io/blog/journey-to-event-driven-part-3-affinity-between-events-streams-serverless
INFO:__main__:Getting metadata for https://www.confluent.io/blog/journey-to-event-driven-part-3-affinity-between-events-streams-serverless
 89%|████████▉ | 196/219 [10:37<00:19,  1.21it/s]INFO:__main__:Requesting https://redislabs.com/blog/redis-turns-10/
INFO:__main__:Getting metadata for https://redislabs.com/blog/redis-turns-10/
 90%|████████▉ | 197/219 [10:38<00:20,  1.10it/s]INFO:__main__:Requesting http://www.oss4gov.org/manifesto
INFO:__main__:Getting metadata for http://oss4gov.org/manifesto
 90%|█████████ | 198/219 [10:40<00:23,  1.13s/it]INFO:__main__:Requesting https://18f.gsa.gov/
INFO:__main__:Getting metadata for https://18f.gsa.gov
 91%|█████████ | 199/219 [10:40<00:18,  1.08it/s]INFO:__main__:Requesting https://18f.gsa.gov/open-source-policy/
INFO:__main__:Getting metadata for https://18f.gsa.gov/open-source-policy/
 91%|█████████▏| 200/219 [10:40<00:14,  1.36it/s]INFO:__main__:Requesting https://github.com/18F
INFO:__main__:Getting metadata for https://github.com/18F
 92%|█████████▏| 201/219 [10:42<00:16,  1.09it/s]INFO:__main__:Requesting https://news.ycombinator.com/front?day=2009-02-25
INFO:__main__:Getting metadata for https://news.ycombinator.com/front?day=2009-02-25
ERROR:__main__:Could not get metadata for https://news.ycombinator.com/front?day=2009-02-25
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 92%|█████████▏| 202/219 [10:43<00:19,  1.13s/it]INFO:__main__:Requesting https://news.ycombinator.com/front?day=2019-02-25
INFO:__main__:Getting metadata for https://news.ycombinator.com/front?day=2019-02-25
ERROR:__main__:Could not get metadata for https://news.ycombinator.com/front?day=2019-02-25
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 93%|█████████▎| 203/219 [10:45<00:20,  1.28s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Relational_algebra
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Relational_algebra
 93%|█████████▎| 204/219 [10:47<00:23,  1.59s/it]INFO:__main__:Requesting http://antirez.com/news/122
INFO:__main__:Getting metadata for http://antirez.com/news/122
ERROR:__main__:Could not get metadata for http://antirez.com/news/122
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 94%|█████████▎| 205/219 [10:48<00:20,  1.46s/it]INFO:__main__:Requesting https://gist.github.com/antirez/6ca04dd191bdb82aad9fb241013e88a8
INFO:__main__:Getting metadata for https://gist.github.com/antirez/6ca04dd191bdb82aad9fb241013e88a8
 94%|█████████▍| 206/219 [10:49<00:17,  1.32s/it]INFO:__main__:Requesting http://www.kylheku.com/cgit/txr/tree/linenoise
INFO:__main__:Getting metadata for http://www.kylheku.com/cgit/txr/tree/linenoise
ERROR:__main__:Could not get metadata for http://www.kylheku.com/cgit/txr/tree/linenoise
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 95%|█████████▍| 207/219 [10:50<00:14,  1.20s/it]INFO:__main__:Requesting http://nongnu.org/txr/txr-manpage.html#N-025AAA27
INFO:__main__:Getting metadata for http://nongnu.org/txr/txr-manpage.html#N-025AAA27
ERROR:__main__:Could not get metadata for http://nongnu.org/txr/txr-manpage.html#N-025AAA27
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 95%|█████████▍| 208/219 [12:16<04:52, 26.55s/it]INFO:__main__:Requesting https://redis.io/topics/pubsub
INFO:__main__:Getting metadata for https://redis.io/topics/pubsub
 95%|█████████▌| 209/219 [12:18<03:12, 19.23s/it]INFO:__main__:Requesting https://www.pearson.com/us/higher-education/program/Ousterhout-Tcl-and-the-Tk-Toolkit-2nd-Edition/PGM23076.html
INFO:__main__:Getting metadata for https://www.pearson.com/us/higher-education/program/Ousterhout-Tcl-and-the-Tk-Toolkit-2nd-Edition/PGM23076.html
ERROR:__main__:Could not get metadata for https://www.pearson.com/us/higher-education/program/Ousterhout-Tcl-and-the-Tk-Toolkit-2nd-Edition/PGM23076.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 195, in web_preview
    content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 174, in __init__
    super(TwitterCard, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 96%|█████████▌| 210/219 [12:21<02:09, 14.41s/it]INFO:__main__:Requesting https://tcl.apache.org/rivet/
INFO:__main__:Getting metadata for https://tcl.apache.org/rivet/
 96%|█████████▋| 211/219 [12:24<01:27, 10.95s/it]INFO:__main__:Requesting http://antirez.com/articoli/tclmisunderstood.html
INFO:__main__:Getting metadata for http://antirez.com/articoli/tclmisunderstood.html
 97%|█████████▋| 212/219 [12:25<00:55,  7.98s/it]INFO:__main__:Requesting http://jim.tcl.tk/index.html/doc/www/www/index.html
INFO:__main__:Getting metadata for http://jim.tcl.tk/index.html/doc/www/www/index.html
 97%|█████████▋| 213/219 [12:26<00:34,  5.73s/it]INFO:__main__:Requesting https://en.m.wikipedia.org/wiki/D._Richard_Hipp
INFO:__main__:Getting metadata for https://en.m.wikipedia.org/wiki/D._Richard_Hipp
 98%|█████████▊| 214/219 [12:26<00:21,  4.22s/it]INFO:__main__:Requesting https://www.tcl.tk/community/tcl2017/assets/talk93/Paper.html
INFO:__main__:Getting metadata for https://www.tcl.tk/community/tcl2017/assets/talk93/Paper.html
 98%|█████████▊| 215/219 [12:27<00:12,  3.24s/it]INFO:__main__:Requesting https://www.dbms2.com/2008/02/18/mike-stonebraker-calls-for-the-complete-destruction-of-the-old-dbms-order/
INFO:__main__:Getting metadata for https://www.dbms2.com/2008/02/18/mike-stonebraker-calls-for-the-complete-destruction-of-the-old-dbms-order/
 99%|█████████▊| 216/219 [12:32<00:10,  3.67s/it]INFO:__main__:Requesting https://www.bleepingcomputer.com/news/security/around-75-percent-of-open-redis-servers-are-infected-with-malware/
INFO:__main__:Getting metadata for https://www.bleepingcomputer.com/news/security/around-75-percent-of-open-redis-servers-are-infected-with-malware/
 99%|█████████▉| 217/219 [12:34<00:06,  3.21s/it]INFO:__main__:Requesting http://antirez.com/news/96
INFO:__main__:Getting metadata for http://antirez.com/news/96
ERROR:__main__:Could not get metadata for http://antirez.com/news/96
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
100%|█████████▉| 218/219 [12:36<00:02,  2.70s/it]INFO:__main__:Requesting https://goodformcode.com
INFO:__main__:Getting metadata for https://goodformcode.com
100%|██████████| 219/219 [12:36<00:00,  1.97s/it]
