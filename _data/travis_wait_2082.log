INFO:__main__:Get urls from stories
  0%|          | 0/30 [00:00<?, ?it/s]  3%|▎         | 1/30 [00:01<00:39,  1.38s/it]  7%|▋         | 2/30 [00:01<00:28,  1.03s/it] 10%|█         | 3/30 [00:02<00:24,  1.11it/s] 13%|█▎        | 4/30 [00:04<00:33,  1.28s/it] 17%|█▋        | 5/30 [00:05<00:34,  1.38s/it] 20%|██        | 6/30 [00:06<00:28,  1.17s/it] 23%|██▎       | 7/30 [00:07<00:24,  1.07s/it] 30%|███       | 9/30 [00:07<00:16,  1.30it/s] 40%|████      | 12/30 [00:07<00:10,  1.78it/s] 43%|████▎     | 13/30 [00:08<00:11,  1.49it/s] 47%|████▋     | 14/30 [00:09<00:11,  1.43it/s] 50%|█████     | 15/30 [00:11<00:15,  1.02s/it] 57%|█████▋    | 17/30 [00:11<00:09,  1.32it/s] 60%|██████    | 18/30 [00:13<00:11,  1.01it/s] 63%|██████▎   | 19/30 [00:13<00:08,  1.35it/s] 67%|██████▋   | 20/30 [00:13<00:05,  1.79it/s] 70%|███████   | 21/30 [00:16<00:12,  1.41s/it] 73%|███████▎  | 22/30 [00:17<00:08,  1.06s/it] 80%|████████  | 24/30 [00:17<00:04,  1.22it/s] 83%|████████▎ | 25/30 [00:17<00:03,  1.65it/s] 87%|████████▋ | 26/30 [00:18<00:02,  1.94it/s] 90%|█████████ | 27/30 [00:18<00:01,  1.67it/s] 97%|█████████▋| 29/30 [00:19<00:00,  1.70it/s]100%|██████████| 30/30 [00:20<00:00,  1.80it/s]
  0%|          | 0/230 [00:00<?, ?it/s]INFO:__main__:Requesting https://www.universityofcalifornia.edu/press-room/uc-terminates-subscriptions-worlds-largest-scientific-publisher-push-open-access-publicly
INFO:__main__:Getting metadata for https://www.universityofcalifornia.edu/press-room/uc-terminates-subscriptions-worlds-largest-scientific-publisher-push-open-access-publicly
  0%|          | 1/230 [00:00<01:02,  3.68it/s]INFO:__main__:Requesting https://www.theguardian.com/science/2012/apr/24/harvard-university-journal-publishers-prices
INFO:__main__:Getting metadata for https://www.theguardian.com/science/2012/apr/24/harvard-university-journal-publishers-prices
  1%|          | 2/230 [00:00<01:12,  3.14it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=pgUA1tluVmE
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=pgUA1tluVmE
  1%|▏         | 3/230 [00:01<01:54,  1.99it/s]INFO:__main__:Requesting https://twitter.com/dgmacarthur/status/1028489457803161600?s=09
INFO:__main__:Getting metadata for https://twitter.com/dgmacarthur/status/1028489457803161600?s=09
  2%|▏         | 4/230 [00:02<02:33,  1.47it/s]INFO:__main__:Requesting https://www.crui.it/archivio-notizie/i-ricercatori-italiani-potranno-beneficiare-dell%E2%80%99accesso-continuo-al-database-sciencedirect-di-elsevie.html
INFO:__main__:Getting metadata for https://www.crui.it/archivio-notizie/i-ricercatori-italiani-potranno-beneficiare-dell%E2%80%99accesso-continuo-al-database-sciencedirect-di-elsevie.html
  2%|▏         | 5/230 [00:06<06:13,  1.66s/it]INFO:__main__:Requesting https://osc.universityofcalifornia.edu/open-access-at-uc/publisher-negotiations/uc-and-elsevier/
INFO:__main__:Getting metadata for https://osc.universityofcalifornia.edu/open-access-at-uc/publisher-negotiations/uc-and-elsevier/
  3%|▎         | 6/230 [00:06<04:39,  1.25s/it]INFO:__main__:Requesting https://unpaywall.org/products/extension
INFO:__main__:Getting metadata for https://unpaywall.org/products/extension
ERROR:__main__:Could not get metadata for https://unpaywall.org/products/extension
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  3%|▎         | 7/230 [00:07<04:16,  1.15s/it]INFO:__main__:Requesting https://github.com/nfahlgren/scihub_bookmark
INFO:__main__:Getting metadata for https://github.com/nfahlgren/scihub_bookmark
  3%|▎         | 8/230 [00:08<03:51,  1.04s/it]INFO:__main__:Requesting https://getpolarized.io/
INFO:__main__:Getting metadata for https://getpolarized.io
  4%|▍         | 9/230 [00:10<04:12,  1.14s/it]INFO:__main__:Requesting http://www.lib.berkeley.edu/using-the-libraries/interlibrary-loan
INFO:__main__:Getting metadata for http://www.lib.berkeley.edu/using-the-libraries/interlibrary-loan
  4%|▍         | 10/230 [00:10<03:56,  1.07s/it]INFO:__main__:Requesting https://livingotherwise.com/2019/01/22/death-sentence-life-service/
INFO:__main__:Getting metadata for https://livingotherwise.com/2019/01/22/death-sentence-life-service/
  5%|▍         | 11/230 [00:12<03:54,  1.07s/it]INFO:__main__:Requesting https://www.nytimes.com/2018/08/10/world/asia/china-xinjiang-un-uighurs.html
INFO:__main__:Getting metadata for https://www.nytimes.com/2018/08/10/world/asia/china-xinjiang-un-uighurs.html
  5%|▌         | 12/230 [00:12<03:01,  1.20it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Design_Patterns
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Design_Patterns
  6%|▌         | 13/230 [00:13<03:30,  1.03it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Gang_of_Four
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Gang_of_Four
  6%|▌         | 14/230 [00:14<03:40,  1.02s/it]INFO:__main__:Requesting http://wiki.c2.com/?GangOfFour
INFO:__main__:Getting metadata for http://wiki.c2.com/?GangOfFour
ERROR:__main__:Could not get metadata for http://wiki.c2.com/?GangOfFour
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
  7%|▋         | 15/230 [00:14<02:48,  1.28it/s]INFO:__main__:Requesting https://pagedraw.io/
INFO:__main__:Getting metadata for https://pagedraw.io
  7%|▋         | 16/230 [00:16<03:06,  1.15it/s]INFO:__main__:Requesting https://medium.com/@gabriel_20625/technical-lessons-from-building-a-compiler-startup-for-3-years-4473405161cd
INFO:__main__:Getting metadata for https://medium.com/@gabriel_20625/technical-lessons-from-building-a-compiler-startup-for-3-years-4473405161cd
  7%|▋         | 17/230 [00:16<02:46,  1.28it/s]INFO:__main__:Requesting https://ourincrediblejourney.tumblr.com/
INFO:__main__:Getting metadata for https://ourincrediblejourney.tumblr.com
  8%|▊         | 18/230 [00:17<02:50,  1.24it/s]INFO:__main__:Requesting https://github.com/Pagedraw/pagedraw/tree/master/src
INFO:__main__:Getting metadata for https://github.com/Pagedraw/pagedraw/tree/master/src
  8%|▊         | 19/230 [00:18<02:48,  1.25it/s]INFO:__main__:Requesting https://github.com/Pagedraw/pagedraw/blob/master/package.json
INFO:__main__:Getting metadata for https://github.com/Pagedraw/pagedraw/blob/master/package.json
  9%|▊         | 20/230 [00:19<03:06,  1.12it/s]INFO:__main__:Requesting https://github.com/Pagedraw/pagedraw/blob/master/src/editor/edit-page.cjsx
INFO:__main__:Getting metadata for https://github.com/Pagedraw/pagedraw/blob/master/src/editor/edit-page.cjsx
  9%|▉         | 21/230 [00:21<04:17,  1.23s/it]INFO:__main__:Requesting http://www.paulgraham.com/avg.html
INFO:__main__:Getting metadata for http://www.paulgraham.com/avg.html
ERROR:__main__:Could not get metadata for http://www.paulgraham.com/avg.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 10%|▉         | 22/230 [00:22<03:39,  1.06s/it]INFO:__main__:Requesting https://github.com/Pagedraw/pagedraw
INFO:__main__:Getting metadata for https://github.com/Pagedraw/pagedraw
 10%|█         | 23/230 [00:22<03:27,  1.00s/it]INFO:__main__:Requesting https://hacks.mozilla.org/2019/02/rewriting-a-browser-component-in-rust/
INFO:__main__:Getting metadata for https://hacks.mozilla.org/2019/02/rewriting-a-browser-component-in-rust/
 10%|█         | 24/230 [00:23<02:54,  1.18it/s]INFO:__main__:Requesting https://doc.rust-lang.org/nightly/edition-guide/rust-2018/ownership-and-lifetimes/non-lexical-lifetimes.html
INFO:__main__:Getting metadata for https://doc.rust-lang.org/nightly/edition-guide/rust-2018/ownership-and-lifetimes/non-lexical-lifetimes.html
 11%|█         | 25/230 [00:24<02:42,  1.26it/s]INFO:__main__:Requesting https://docs.adacore.com/spark2014-docs/html/ug/en/source/concurrency.html#preventing-data-races
INFO:__main__:Getting metadata for https://docs.adacore.com/spark2014-docs/html/ug/en/source/concurrency.html#preventing-data-races
 11%|█▏        | 26/230 [00:26<04:07,  1.21s/it]INFO:__main__:Requesting https://docs.adacore.com/spark2014-docs/html/ug/en/source/co..
 12%|█▏        | 27/230 [00:26<03:03,  1.11it/s]INFO:__main__:Requesting https://www.adaic.org/resources/add_content/standards/05rat/html/Rat-3-2.html
ERROR:__main__:Could not reach https://www.adaic.org/resources/add_content/standards/05rat/html/Rat-3-2.html
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 344, in connect
    ssl_context=context)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/ssl_.py", line 344, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 407, in wrap_socket
    _context=self, _session=session)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 814, in __init__
    self.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1068, in do_handshake
    self._sslobj.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.adaic.org', port=443): Max retries exceeded with url: /resources/add_content/standards/05rat/html/Rat-3-2.html (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.adaic.org', port=443): Max retries exceeded with url: /resources/add_content/standards/05rat/html/Rat-3-2.html (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))
 12%|█▏        | 28/230 [00:26<02:35,  1.30it/s]INFO:__main__:Requesting https://yoric.github.io/post/rust-typestate/
INFO:__main__:Getting metadata for https://yoric.github.io/post/rust-typestate/
 13%|█▎        | 29/230 [00:27<02:01,  1.65it/s]INFO:__main__:Requesting https://en.cppreference.com/w/cpp/container/vector/operator_at
INFO:__main__:Getting metadata for https://en.cppreference.com/w/cpp/container/vector/operator_at
 13%|█▎        | 30/230 [00:28<03:02,  1.09it/s]INFO:__main__:Requesting https://github.com/dropbox/rust-brotli-decompressor/blob/master/src/memory.rs#L71-L76
INFO:__main__:Getting metadata for https://github.com/dropbox/rust-brotli-decompressor/blob/master/src/memory.rs#L71-L76
 13%|█▎        | 31/230 [00:29<03:11,  1.04it/s]INFO:__main__:Requesting https://github.com/dropbox/rust-brotli-decompressor/blob/master/src/memory.rs#L18-L23
INFO:__main__:Getting metadata for https://github.com/dropbox/rust-brotli-decompressor/blob/master/src/memory.rs#L18-L23
 14%|█▍        | 32/230 [00:30<03:04,  1.07it/s]INFO:__main__:Requesting https://www.reddit.com/r/programming/comments/atyzz4/halley_a_lightweight_game_engine_written_in_c14/eh69lz7/
INFO:__main__:Getting metadata for https://www.reddit.com/r/programming/comments/atyzz4/halley_a_lightweight_game_engine_written_in_c14/eh69lz7/
 14%|█▍        | 33/230 [00:31<02:51,  1.15it/s]INFO:__main__:Requesting https://www.reddit.com/r/programming/comments/atyzz4/halley_a_lightweight_game_engine_written_in_c14/eh5kdqv/
INFO:__main__:Getting metadata for https://www.reddit.com/r/programming/comments/atyzz4/halley_a_lightweight_game_engine_written_in_c14/eh5kdqv/
 15%|█▍        | 34/230 [00:32<02:48,  1.16it/s]INFO:__main__:Requesting https://blogs.dropbox.com/tech/2016/06/lossless-compression-with-brotli/
INFO:__main__:Getting metadata for https://blogs.dropbox.com/tech/2016/06/lossless-compression-with-brotli/
ERROR:__main__:Could not get metadata for https://blogs.dropbox.com/tech/2016/06/lossless-compression-with-brotli/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 15%|█▌        | 35/230 [00:32<02:32,  1.28it/s]INFO:__main__:Requesting https://developer.android.com/reference/android/util/FloatMath.html
INFO:__main__:Getting metadata for https://developer.android.com/reference/android/util/FloatMath.html
ERROR:__main__:Could not get metadata for https://developer.android.com/reference/android/util/FloatMath.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 16%|█▌        | 36/230 [00:36<05:19,  1.65s/it]INFO:__main__:Requesting https://github.com/Microsoft/cppwinrt
INFO:__main__:Getting metadata for https://github.com/Microsoft/cppwinrt
 16%|█▌        | 37/230 [00:37<04:41,  1.46s/it]INFO:__main__:Requesting https://blog.rust-lang.org/2015/05/11/traits.html
INFO:__main__:Getting metadata for https://blog.rust-lang.org/2015/05/11/traits.html
 17%|█▋        | 38/230 [00:37<03:40,  1.15s/it]INFO:__main__:Requesting https://www.bbc.co.uk/news/technology-47408969
INFO:__main__:Getting metadata for https://www.bbc.co.uk/news/technology-47408969
 17%|█▋        | 39/230 [00:39<04:14,  1.33s/it]INFO:__main__:Requesting https://twitter.com/chrisulmer/status/1099366622329036801
INFO:__main__:Getting metadata for https://twitter.com/chrisulmer/status/1099366622329036801
 17%|█▋        | 40/230 [00:40<03:50,  1.21s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/I_know_it_when_I_see_it
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/I_know_it_when_I_see_it
 18%|█▊        | 41/230 [00:41<03:24,  1.08s/it]INFO:__main__:Requesting https://youtube-creators.googleblog.com/2019/02/more-updates-on-our-actions-related-to.html
INFO:__main__:Getting metadata for https://youtube-creators.googleblog.com/2019/02/more-updates-on-our-actions-related-to.html
 18%|█▊        | 42/230 [00:41<02:33,  1.23it/s]INFO:__main__:Requesting https://chrome.google.com/webstore/detail/herp-derp-for-youtube/ioomnmgjblnnolpdgdhebainmfbipjoh?hl=en-US
INFO:__main__:Getting metadata for https://chrome.google.com/webstore/detail/herp-derp-for-youtube/ioomnmgjblnnolpdgdhebainmfbipjoh?hl=en-US
 19%|█▊        | 43/230 [00:41<01:55,  1.62it/s]INFO:__main__:Requesting https://definitions.uslegal.com/c/child-enticement/
INFO:__main__:Getting metadata for https://definitions.uslegal.com/c/child-enticement/
 19%|█▉        | 44/230 [00:45<04:21,  1.41s/it]INFO:__main__:Requesting https://www.theatlantic.com/national/archive/2013/08/government-knocking-doors-because-google-searches/312599/
INFO:__main__:Getting metadata for https://www.theatlantic.com/national/archive/2013/08/government-knocking-doors-because-google-searches/312599/
 20%|█▉        | 45/230 [00:45<03:28,  1.13s/it]INFO:__main__:Requesting https://blog.mozilla.org/blog/2019/02/28/sharing-our-common-voices-mozilla-releases-the-largest-to-date-public-domain-transcribed-voice-dataset/
INFO:__main__:Getting metadata for https://blog.mozilla.org/blog/2019/02/28/sharing-our-common-voices-mozilla-releases-the-largest-to-date-public-domain-transcribed-voice-dataset/
 20%|██        | 46/230 [00:46<02:54,  1.06it/s]INFO:__main__:Requesting http://www.openslr.org/12/
INFO:__main__:Getting metadata for http://www.openslr.org/12/
 20%|██        | 47/230 [00:47<03:18,  1.08s/it]INFO:__main__:Requesting https://hacks.mozilla.org/2017/11/a-journey-to-10-word-error-rate/
INFO:__main__:Getting metadata for https://hacks.mozilla.org/2017/11/a-journey-to-10-word-error-rate/
 21%|██        | 48/230 [00:47<02:43,  1.12it/s]INFO:__main__:Requesting https://m.youtube.com/watch?v=NMS2VnDveP8
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=NMS2VnDveP8&app=desktop
 21%|██▏       | 49/230 [00:48<02:53,  1.04it/s]INFO:__main__:Requesting http://trumped.com
INFO:__main__:Getting metadata for http://trumped.com
 22%|██▏       | 50/230 [00:49<02:36,  1.15it/s]INFO:__main__:Requesting https://www.mathieustern.com/blog/2018/10/22/l437fjpq58g619vlkm6t1iwhk8s6dr
INFO:__main__:Getting metadata for https://www.mathieustern.com/blog/2018/10/22/l437fjpq58g619vlkm6t1iwhk8s6dr
 22%|██▏       | 51/230 [00:50<02:22,  1.26it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Fresnel_lens
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Fresnel_lens
 23%|██▎       | 52/230 [00:51<02:42,  1.10it/s]INFO:__main__:Requesting https://www.medicalnewstoday.com/articles/302550.php
INFO:__main__:Getting metadata for https://www.medicalnewstoday.com/articles/302550.php
 23%|██▎       | 53/230 [00:52<02:48,  1.05it/s]INFO:__main__:Requesting https://www.ted.com/talks/josh_silver_demos_adjustable_liquid_filled_eyeglasses?language=en
INFO:__main__:Getting metadata for https://www.ted.com/talks/josh_silver_demos_adjustable_liquid_filled_eyeglasses?language=en
 23%|██▎       | 54/230 [00:53<02:42,  1.08it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Liquid_mirror_telescope
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Liquid_mirror_telescope
 24%|██▍       | 55/230 [00:54<02:53,  1.01it/s]INFO:__main__:Requesting http://www.laurawaller.com/opticsfun/sugarGRINlens.htm
 24%|██▍       | 56/230 [00:54<02:11,  1.33it/s]INFO:__main__:Requesting https://kottke.org/19/02/a-camera-lens-made-from-an-iceberg
INFO:__main__:Getting metadata for https://kottke.org/19/02/a-camera-lens-made-from-an-iceberg
 25%|██▍       | 57/230 [00:55<01:49,  1.58it/s]INFO:__main__:Requesting https://phys.org/news/2019-02-million-year-old-worm-superhighway-canada.html
INFO:__main__:Getting metadata for https://phys.org/news/2019-02-million-year-old-worm-superhighway-canada.html
 25%|██▌       | 58/230 [00:55<01:47,  1.60it/s]INFO:__main__:Requesting https://www.sendthemtomir.com/blog/cli-2-factor-authentication
INFO:__main__:Getting metadata for https://www.sendthemtomir.com/blog/cli-2-factor-authentication
 26%|██▌       | 59/230 [00:56<02:21,  1.21it/s]INFO:__main__:Requesting https://support.yubico.com/support/solutions/articles/15000012643-yubikey-manager-cli-ykman-user-manual#ykman_oathwicpwc
INFO:__main__:Getting metadata for https://support.yubico.com/support/solutions/articles/15000012643-yubikey-manager-cli-ykman-user-manual#ykman_oathwicpwc
 26%|██▌       | 60/230 [01:00<04:29,  1.58s/it]INFO:__main__:Requesting https://github.com/tadfisher/pass-otp
INFO:__main__:Getting metadata for https://github.com/tadfisher/pass-otp
 27%|██▋       | 61/230 [01:01<04:00,  1.42s/it]INFO:__main__:Requesting https://github.com/browserpass/browserpass
INFO:__main__:Getting metadata for https://github.com/browserpass/browserpass
 27%|██▋       | 62/230 [01:02<03:40,  1.31s/it]INFO:__main__:Requesting https://github.com/zeapo/Android-Password-Store
INFO:__main__:Getting metadata for https://github.com/zeapo/Android-Password-Store
 27%|██▋       | 63/230 [01:03<03:23,  1.22s/it]INFO:__main__:Requesting https://github.com/rigetti/quilc
INFO:__main__:Getting metadata for https://github.com/rigetti/quilc
 28%|██▊       | 64/230 [01:04<03:03,  1.11s/it]INFO:__main__:Requesting https://ai.googleblog.com/2019/02/long-range-robotic-navigation-via.html
INFO:__main__:Getting metadata for https://ai.googleblog.com/2019/02/long-range-robotic-navigation-via.html
 28%|██▊       | 65/230 [01:04<02:26,  1.12it/s]INFO:__main__:Requesting https://www.reuters.com/article/us-china-apple-icloud-insight-idUSKCN1G8060
INFO:__main__:Getting metadata for https://www.reuters.com/article/us-china-apple-icloud-insight-idUSKCN1G8060
 29%|██▊       | 66/230 [01:05<02:07,  1.29it/s]INFO:__main__:Requesting https://www.vox.com/2018/10/24/18018282/china-reeducation-camps-uighur-muslims
INFO:__main__:Getting metadata for https://www.vox.com/2018/10/24/18018282/china-reeducation-camps-uighur-muslims
 29%|██▉       | 67/230 [01:05<01:42,  1.58it/s]INFO:__main__:Requesting https://github.com/cosmos72/gomacro#gomacro---interactive-go-interpreter-and-debugger-with-generics-and-macros
INFO:__main__:Getting metadata for https://github.com/cosmos72/gomacro#gomacro---interactive-go-interpreter-and-debugger-with-generics-and-macros
 30%|██▉       | 68/230 [01:06<02:04,  1.30it/s]INFO:__main__:Requesting https://golang.org/doc/faq#implements_interface
INFO:__main__:Getting metadata for https://golang.org/doc/faq#implements_interface
 30%|███       | 69/230 [01:07<02:00,  1.33it/s]INFO:__main__:Requesting https://github.com/golang/go/issues/15292#issuecomment-210085246
INFO:__main__:Getting metadata for https://github.com/golang/go/issues/15292#issuecomment-210085246
 30%|███       | 70/230 [01:15<07:37,  2.86s/it]INFO:__main__:Requesting https://dlang.org/spec/template.html
INFO:__main__:Getting metadata for https://dlang.org/spec/template.html
 31%|███       | 71/230 [01:16<06:36,  2.49s/it]INFO:__main__:Requesting https://tour.dlang.org/tour/en/basics/templates
INFO:__main__:Getting metadata for https://tour.dlang.org/tour/en/basics/templates
 31%|███▏      | 72/230 [01:17<05:32,  2.11s/it]INFO:__main__:Requesting https://dlang.org/articles/templates-revisited.html
INFO:__main__:Getting metadata for https://dlang.org/articles/templates-revisited.html
 32%|███▏      | 73/230 [01:19<04:49,  1.84s/it]INFO:__main__:Requesting https://www.jetbrains.com/help/go/debugging-code.html#924cf9d3
INFO:__main__:Getting metadata for https://www.jetbrains.com/help/go/debugging-code.html#924cf9d3
 32%|███▏      | 74/230 [01:20<04:24,  1.70s/it]INFO:__main__:Requesting https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query
INFO:__main__:Getting metadata for https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query
 33%|███▎      | 75/230 [01:21<03:52,  1.50s/it]INFO:__main__:Requesting https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=plaintext
INFO:__main__:Getting metadata for https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=plaintext
 33%|███▎      | 76/230 [01:22<03:24,  1.33s/it]INFO:__main__:Requesting https://golang.org/doc/devel/release.html
INFO:__main__:Getting metadata for https://golang.org/doc/devel/release.html
 33%|███▎      | 77/230 [01:22<02:35,  1.02s/it]INFO:__main__:Requesting https://github.com/golang/go/commit/d72c550f1c7e13c323f4507b57d741ed00f0b0cd
INFO:__main__:Getting metadata for https://github.com/golang/go/commit/d72c550f1c7e13c323f4507b57d741ed00f0b0cd
 34%|███▍      | 78/230 [01:23<02:34,  1.02s/it]INFO:__main__:Requesting https://xref.com/
INFO:__main__:Getting metadata for https://xref.com
 34%|███▍      | 79/230 [01:26<03:44,  1.49s/it]INFO:__main__:Requesting https://workgrades.com
INFO:__main__:Getting metadata for https://workgrades.com
ERROR:__main__:Could not get metadata for https://workgrades.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 35%|███▍      | 80/230 [01:27<03:20,  1.34s/it]INFO:__main__:Requesting https://www.searchlight.ai
INFO:__main__:Getting metadata for https://www.searchlight.ai
ERROR:__main__:Could not get metadata for https://www.searchlight.ai
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 35%|███▌      | 81/230 [01:28<03:04,  1.24s/it]INFO:__main__:Requesting https://dothemath.ucsd.edu/2012/06/heat-pumps-work-miracles/
INFO:__main__:Getting metadata for https://dothemath.ucsd.edu/2012/06/heat-pumps-work-miracles/
 36%|███▌      | 82/230 [01:30<03:46,  1.53s/it]INFO:__main__:Requesting https://flair.co/pages/mini-splits-and-window-units
INFO:__main__:Getting metadata for https://flair.co/pages/mini-splits-and-window-units
 36%|███▌      | 83/230 [01:30<02:56,  1.20s/it]INFO:__main__:Requesting https://www.drawdown.org/solutions/materials/refrigerant-management
INFO:__main__:Getting metadata for https://www.drawdown.org/solutions/materials/refrigerant-management
 37%|███▋      | 84/230 [01:31<02:41,  1.11s/it]INFO:__main__:Requesting https://www.energystar.gov/newhomes
INFO:__main__:Getting metadata for https://www.energystar.gov/newhomes
 37%|███▋      | 85/230 [01:34<03:48,  1.58s/it]INFO:__main__:Requesting https://www.energielabel.nl
INFO:__main__:Getting metadata for https://www.energielabel.nl
 37%|███▋      | 86/230 [01:37<05:00,  2.08s/it]INFO:__main__:Requesting https://freshome.com/2014/10/09/what-is-a-leed-certified-home/
INFO:__main__:Getting metadata for https://freshome.com/2014/10/09/what-is-a-leed-certified-home/
 38%|███▊      | 87/230 [01:38<03:37,  1.52s/it]INFO:__main__:Requesting https://www.statista.com/statistics/702735/household-natural-gas-prices-in-selected-countries/
INFO:__main__:Getting metadata for https://www.statista.com/statistics/702735/household-natural-gas-prices-in-selected-countries/
 38%|███▊      | 88/230 [01:38<03:00,  1.27s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Cogeneration
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Cogeneration
 39%|███▊      | 89/230 [01:40<03:09,  1.35s/it]INFO:__main__:Requesting https://www.buildingscience.com/documents/insights/bsi-001-the-perfect-wall
INFO:__main__:Getting metadata for https://www.buildingscience.com/documents/insights/bsi-001-the-perfect-wall
ERROR:__main__:Could not get metadata for https://www.buildingscience.com/documents/insights/bsi-001-the-perfect-wall
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 39%|███▉      | 90/230 [01:47<07:02,  3.02s/it]INFO:__main__:Requesting https://www.architectsjournal.co.uk/buildings/airtightness-blamed-for-health-risks-in-homes/10014252.article
INFO:__main__:Getting metadata for https://www.architectsjournal.co.uk/buildings/airtightness-blamed-for-health-risks-in-homes/10014252.article
 40%|███▉      | 91/230 [01:49<06:44,  2.91s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=CIcrXut_EFA
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=CIcrXut_EFA
 40%|████      | 92/230 [01:50<05:20,  2.32s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Heat_recovery_ventilation
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Heat_recovery_ventilation
 40%|████      | 93/230 [01:51<04:32,  1.99s/it]INFO:__main__:Requesting https://en.m.wikipedia.org/wiki/Blower_door
INFO:__main__:Getting metadata for https://en.m.wikipedia.org/wiki/Blower_door
 41%|████      | 94/230 [01:53<04:03,  1.79s/it]INFO:__main__:Requesting https://www.google.com/amp/s/amp.theguardian.com/cities/2017/nov/16/japan-reusable-housing-revolution
INFO:__main__:Getting metadata for https://www.theguardian.com/cities/2017/nov/16/japan-reusable-housing-revolution
 41%|████▏     | 95/230 [01:54<03:24,  1.51s/it]INFO:__main__:Requesting https://www.bbc.com/news/uk-england-london-10645700
INFO:__main__:Getting metadata for https://www.bbc.com/news/uk-england-london-10645700
 42%|████▏     | 96/230 [01:56<03:52,  1.74s/it]INFO:__main__:Requesting https://www.bgs.ac.uk/discoveringgeology/hazards/earthquakes/uk.html
INFO:__main__:Getting metadata for https://www.bgs.ac.uk/discoveringgeology/hazards/earthquakes/uk.html
 42%|████▏     | 97/230 [01:59<04:59,  2.25s/it]INFO:__main__:Requesting https://www.theguardian.com/travel/2013/jul/27/history-of-englands-forests
INFO:__main__:Getting metadata for https://www.theguardian.com/travel/2013/jul/27/history-of-englands-forests
 43%|████▎     | 98/230 [02:00<03:46,  1.72s/it]INFO:__main__:Requesting https://www.demilec.com/
INFO:__main__:Getting metadata for https://www.demilec.com
 43%|████▎     | 99/230 [02:02<04:14,  1.94s/it]INFO:__main__:Requesting http://renewability.com/#learn-more
INFO:__main__:Getting metadata for http://renewability.com/#learn-more
 43%|████▎     | 100/230 [02:03<03:09,  1.46s/it]INFO:__main__:Requesting https://www.energy.gov/energysaver/water-heating/drain-water-heat-recovery
 44%|████▍     | 101/230 [02:03<02:28,  1.15s/it]INFO:__main__:Requesting https://www.energystar.gov/about/federal_tax_credits/air_source_heat_pumps
INFO:__main__:Getting metadata for https://www.energystar.gov/about/federal_tax_credits/air_source_heat_pumps
 44%|████▍     | 102/230 [02:03<01:59,  1.07it/s]INFO:__main__:Requesting https://www.thisoldhouse.com/watch/jamestown-net-zero-house
INFO:__main__:Getting metadata for https://www.thisoldhouse.com/watch/jamestown-net-zero-house
ERROR:__main__:Could not get metadata for https://www.thisoldhouse.com/watch/jamestown-net-zero-house
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 45%|████▍     | 103/230 [02:04<01:54,  1.11it/s]INFO:__main__:Requesting https://www.youtube.com/user/MattRisinger
INFO:__main__:Getting metadata for https://www.youtube.com/user/MattRisinger
 45%|████▌     | 104/230 [02:07<02:51,  1.36s/it]INFO:__main__:Requesting https://www.rheem.com/innovations/innovation_residential/integrated_systems/
INFO:__main__:Getting metadata for https://www.rheem.com/innovations/innovation_residential/integrated_systems/
 46%|████▌     | 105/230 [02:11<04:36,  2.21s/it]INFO:__main__:Requesting https://techcrunch.com/2011/06/12/air-conditioning-water-heater/
ERROR:__main__:Could not reach https://techcrunch.com/2011/06/12/air-conditioning-water-heater/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 46%|████▌     | 106/230 [02:11<03:17,  1.59s/it]INFO:__main__:Requesting https://en.m.wikipedia.org/wiki/Absorption_refrigerator
INFO:__main__:Getting metadata for https://en.m.wikipedia.org/wiki/Absorption_refrigerator
 47%|████▋     | 107/230 [02:12<02:38,  1.29s/it]INFO:__main__:Requesting https://blog.rust-lang.org/2019/02/28/Rust-1.33.0.html
INFO:__main__:Getting metadata for https://blog.rust-lang.org/2019/02/28/Rust-1.33.0.html
 47%|████▋     | 108/230 [02:12<01:55,  1.05it/s]INFO:__main__:Requesting https://github.com/rust-lang/rust/pull/56568
INFO:__main__:Getting metadata for https://github.com/rust-lang/rust/pull/56568
 47%|████▋     | 109/230 [02:15<03:32,  1.76s/it]INFO:__main__:Requesting https://github.com/rust-lang/rust/issues/49150
INFO:__main__:Getting metadata for https://github.com/rust-lang/rust/issues/49150
 48%|████▊     | 110/230 [02:19<04:38,  2.32s/it]INFO:__main__:Requesting https://github.com/rust-lang-nursery/reference/blob/master/src/items/functions.md#const-functions
INFO:__main__:Getting metadata for https://github.com/rust-lang-nursery/reference/blob/master/src/items/functions.md#const-functions
 48%|████▊     | 111/230 [02:20<03:38,  1.83s/it]INFO:__main__:Requesting https://newrustacean.com/show_notes/news/rust_1_31/part_2/index.html
INFO:__main__:Getting metadata for https://newrustacean.com/show_notes/news/rust_1_31/part_2/index.html
 49%|████▊     | 112/230 [02:22<03:37,  1.85s/it]INFO:__main__:Requesting http://b.atch.se/posts/non-constant-constant-expressions/
INFO:__main__:Getting metadata for http://b.atch.se/posts/non-constant-constant-expressions/
 49%|████▉     | 113/230 [02:23<03:31,  1.80s/it]INFO:__main__:Requesting https://areweasyncyet.rs/
INFO:__main__:Getting metadata for https://areweasyncyet.rs
 50%|████▉     | 114/230 [02:24<02:52,  1.49s/it]INFO:__main__:Requesting https://areweasyncyet.rs
INFO:__main__:Getting metadata for https://areweasyncyet.rs
 50%|█████     | 115/230 [02:25<02:19,  1.22s/it]INFO:__main__:Requesting https://cyclingtips.com/2019/02/did-strava-copy-its-mobile-route-builder-from-another-app/
INFO:__main__:Getting metadata for https://cyclingtips.com/2019/02/did-strava-copy-its-mobile-route-builder-from-another-app/
 50%|█████     | 116/230 [02:27<03:00,  1.58s/it]INFO:__main__:Requesting http://footpathapp.com
INFO:__main__:Getting metadata for https://footpathapp.com
 51%|█████     | 117/230 [02:27<02:12,  1.17s/it]INFO:__main__:Requesting https://techcrunch.com/2016/08/02/silicon-copy/
ERROR:__main__:Could not reach https://techcrunch.com/2016/08/02/silicon-copy/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 51%|█████▏    | 118/230 [02:27<01:36,  1.16it/s]INFO:__main__:Requesting https://twitter.com/iamnunocaldeira/status/1101105269793308673
INFO:__main__:Getting metadata for https://twitter.com/iamnunocaldeira/status/1101105269793308673
 52%|█████▏    | 119/230 [02:28<01:31,  1.21it/s]INFO:__main__:Requesting https://www.wnycstudios.org/story/the_buried_bodies_case
INFO:__main__:Getting metadata for https://www.wnycstudios.org/story/the_buried_bodies_case
 52%|█████▏    | 120/230 [02:29<01:19,  1.39it/s]INFO:__main__:Requesting https://footpathapp.com/privacy
INFO:__main__:Getting metadata for https://footpathapp.com/privacy/
 53%|█████▎    | 121/230 [02:29<01:03,  1.73it/s]INFO:__main__:Requesting https://www.ip2location.com/demo/12.131.20.242
INFO:__main__:Getting metadata for https://www.ip2location.com/demo/12.131.20.242
 53%|█████▎    | 122/230 [02:29<00:54,  1.97it/s]INFO:__main__:Requesting https://www.maxmind.com/en/geoip-demo
INFO:__main__:Getting metadata for https://www.maxmind.com/en/geoip-demo
 53%|█████▎    | 123/230 [02:30<01:15,  1.42it/s]INFO:__main__:Requesting http://disq.us/p/202igai
INFO:__main__:Getting metadata for https://cyclingtips.com/2019/02/did-strava-copy-its-mobile-route-builder-from-another-app/#comment-4357784826
 54%|█████▍    | 124/230 [02:33<02:14,  1.27s/it]INFO:__main__:Requesting https://www.gmap-pedometer.com/
INFO:__main__:Getting metadata for https://www.gmap-pedometer.com
 54%|█████▍    | 125/230 [02:34<01:55,  1.10s/it]INFO:__main__:Requesting https://www.maps.ie/map-my-route/
 55%|█████▍    | 126/230 [02:34<01:29,  1.17it/s]INFO:__main__:Requesting https://support.google.com/mymaps/answer/3433053
INFO:__main__:Getting metadata for https://support.google.com/mymaps/answer/3433053
 55%|█████▌    | 127/230 [02:35<01:26,  1.19it/s]INFO:__main__:Requesting https://slatestarcodex.com/2017/05/11/silicon-valley-a-reality-check/
INFO:__main__:Getting metadata for https://slatestarcodex.com/2017/05/11/silicon-valley-a-reality-check/
 56%|█████▌    | 128/230 [02:36<01:35,  1.07it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=hGY3uBHVVr4
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=hGY3uBHVVr4
 56%|█████▌    | 129/230 [02:37<01:33,  1.08it/s]INFO:__main__:Requesting https://github.com/kanaka/mal/blob/master/process/guide.md
INFO:__main__:Getting metadata for https://github.com/kanaka/mal/blob/master/process/guide.md
 57%|█████▋    | 130/230 [02:38<01:49,  1.10s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/ELIZA
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/ELIZA
 57%|█████▋    | 131/230 [02:39<01:42,  1.04s/it]INFO:__main__:Requesting https://github.com/norvig/paip-lisp/blob/master/README.md
INFO:__main__:Getting metadata for https://github.com/norvig/paip-lisp/blob/master/README.md
 57%|█████▋    | 132/230 [02:40<01:30,  1.08it/s]INFO:__main__:Requesting http://web.sonoma.edu/users/l/luvisi/
INFO:__main__:Getting metadata for http://web.sonoma.edu/users/l/luvisi/
ERROR:__main__:Could not get metadata for http://web.sonoma.edu/users/l/luvisi/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 58%|█████▊    | 133/230 [02:41<01:21,  1.19it/s]INFO:__main__:Requesting https://github.com/krig/LISP
INFO:__main__:Getting metadata for https://github.com/krig/LISP
 58%|█████▊    | 134/230 [02:42<01:23,  1.14it/s]INFO:__main__:Requesting https://github.com/rigetti/qvm
INFO:__main__:Getting metadata for https://github.com/rigetti/qvm
 59%|█████▊    | 135/230 [02:42<01:21,  1.16it/s]INFO:__main__:Requesting https://www.bloombergquint.com/businessweek/america-s-cities-are-running-on-software-from-the-80s
INFO:__main__:Getting metadata for https://www.bloombergquint.com/businessweek/america-s-cities-are-running-on-software-from-the-80s
 59%|█████▉    | 136/230 [02:43<01:04,  1.45it/s]INFO:__main__:Requesting https://mentalhealthdaily.com/2015/02/18/at-what-age-is-the-brain-fully-developed/
INFO:__main__:Getting metadata for https://mentalhealthdaily.com/2015/02/18/at-what-age-is-the-brain-fully-developed/
 60%|█████▉    | 137/230 [02:44<01:26,  1.07it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Typeahead
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Typeahead
 60%|██████    | 138/230 [02:45<01:14,  1.24it/s]INFO:__main__:Requesting https://images.hdsydsvenskan.se/980x588/KoHYjzCi_hdzfPAF4xY_j0PR9ls.jpg
INFO:__main__:Getting metadata for https://images.hdsydsvenskan.se/980x588/KoHYjzCi_hdzfPAF4xY_j0PR9ls.jpg
ERROR:__main__:Could not get metadata for https://images.hdsydsvenskan.se/980x588/KoHYjzCi_hdzfPAF4xY_j0PR9ls.jpg
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 60%|██████    | 139/230 [02:46<01:31,  1.00s/it]INFO:__main__:Requesting https://www.twincities.com/2019/02/14/mn-dmv-mnlars-report-department-driver-vehicle-services/
INFO:__main__:Getting metadata for https://www.twincities.com/2019/02/14/mn-dmv-mnlars-report-department-driver-vehicle-services/
 61%|██████    | 140/230 [02:47<01:24,  1.07it/s]INFO:__main__:Requesting https://en.m.wikipedia.org/wiki/Phoenix_pay_system
INFO:__main__:Getting metadata for https://en.m.wikipedia.org/wiki/Phoenix_pay_system
 61%|██████▏   | 141/230 [02:49<01:40,  1.13s/it]INFO:__main__:Requesting https://www.comeetie.fr/galerie/BatiParis/#12/48.8589/2.3491
INFO:__main__:Getting metadata for https://www.comeetie.fr/galerie/BatiParis/#12/48.8589/2.3491
 62%|██████▏   | 142/230 [02:51<02:15,  1.54s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Clock_of_the_Long_Now
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Clock_of_the_Long_Now
 62%|██████▏   | 143/230 [02:52<01:53,  1.31s/it]INFO:__main__:Requesting https://www.cbsnews.com/news/mta-why-has-the-nyc-subway-gone-off-the-rails-60-minutes/
INFO:__main__:Getting metadata for https://www.cbsnews.com/news/mta-why-has-the-nyc-subway-gone-off-the-rails-60-minutes/
 63%|██████▎   | 144/230 [02:52<01:32,  1.07s/it]INFO:__main__:Requesting https://twitter.com/dongho_chang/status/960645535311937538
INFO:__main__:Getting metadata for https://twitter.com/dongho_chang/status/960645535311937538
 63%|██████▎   | 145/230 [02:53<01:27,  1.03s/it]INFO:__main__:Requesting https://beta.nyc/
INFO:__main__:Getting metadata for https://beta.nyc
ERROR:__main__:Could not get metadata for https://beta.nyc
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 63%|██████▎   | 146/230 [02:54<01:16,  1.10it/s]INFO:__main__:Requesting https://simple.m.wikipedia.org/wiki/Sustainability
INFO:__main__:Getting metadata for https://simple.m.wikipedia.org/wiki/Sustainability
 64%|██████▍   | 147/230 [02:55<01:11,  1.15it/s]INFO:__main__:Requesting https://discovery.princeton.edu/2018/12/02/beyond-einstein-physicists-find-surprising-connections-in-the-cosmos/
INFO:__main__:Getting metadata for https://discovery.princeton.edu/2018/12/02/beyond-einstein-physicists-find-surprising-connections-in-the-cosmos/
 64%|██████▍   | 148/230 [02:56<01:33,  1.14s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=3HYw6vPR9qU
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=3HYw6vPR9qU
 65%|██████▍   | 149/230 [02:58<01:30,  1.12s/it]INFO:__main__:Requesting https://arxiv.org/abs/1801.08160
INFO:__main__:Getting metadata for https://arxiv.org/abs/1801.08160
 65%|██████▌   | 150/230 [02:59<01:26,  1.08s/it]INFO:__main__:Requesting https://coocoor.com/advisory/cve/CVE-2018-8778
INFO:__main__:Getting metadata for https://coocoor.com/advisory/cve/CVE-2018-8778
ERROR:__main__:Could not get metadata for https://coocoor.com/advisory/cve/CVE-2018-8778
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 66%|██████▌   | 151/230 [02:59<01:10,  1.13it/s]INFO:__main__:Requesting https://www.tandfonline.com/doi/full/10.1080/02791072.2019.1580804
INFO:__main__:Getting metadata for https://www.tandfonline.com/doi/full/10.1080/02791072.2019.1580804
 66%|██████▌   | 152/230 [03:01<01:26,  1.10s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Active_placebo
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Active_placebo
 67%|██████▋   | 153/230 [03:01<01:15,  1.02it/s]INFO:__main__:Requesting https://slideslive.com/38913519/topological-approaches-for-unsupervised-learning
INFO:__main__:Getting metadata for https://slideslive.com/38913519/topological-approaches-for-unsupervised-learning
 67%|██████▋   | 154/230 [03:02<01:12,  1.05it/s]INFO:__main__:Requesting https://arxiv.org/abs/1802.03426
INFO:__main__:Getting metadata for https://arxiv.org/abs/1802.03426
 67%|██████▋   | 155/230 [03:03<01:12,  1.04it/s]INFO:__main__:Requesting https://github.com/lmcinnes/umap
INFO:__main__:Getting metadata for https://github.com/lmcinnes/umap
 68%|██████▊   | 156/230 [03:04<01:12,  1.02it/s]INFO:__main__:Requesting https://branchfree.org/2019/02/28/paper-hyperscan-a-fast-multi-pattern-regex-matcher-for-modern-cpus/
ERROR:__main__:Could not reach https://branchfree.org/2019/02/28/paper-hyperscan-a-fast-multi-pattern-regex-matcher-for-modern-cpus/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 68%|██████▊   | 157/230 [03:04<00:53,  1.36it/s]INFO:__main__:Requesting http://matt.might.net/articles/parsing-with-derivatives/
INFO:__main__:Getting metadata for http://matt.might.net/articles/parsing-with-derivatives/
 69%|██████▊   | 158/230 [03:05<00:48,  1.50it/s]INFO:__main__:Requesting https://github.com/shenfe/python-hyperscan
INFO:__main__:Getting metadata for https://github.com/shenfe/python-hyperscan
 69%|██████▉   | 159/230 [03:06<00:56,  1.25it/s]INFO:__main__:Requesting https://github.com/nemequ/simde
INFO:__main__:Getting metadata for https://github.com/nemequ/simde
 70%|██████▉   | 160/230 [03:07<00:58,  1.20it/s]INFO:__main__:Requesting https://github.com/BurntSushi/ripgrep
INFO:__main__:Getting metadata for https://github.com/BurntSushi/ripgrep
 70%|███████   | 161/230 [03:08<01:00,  1.14it/s]INFO:__main__:Requesting https://github.com/rust-lang/regex/commit/203c509df9e1dcba61eaa60ba9c09be9ca0c4b25
INFO:__main__:Getting metadata for https://github.com/rust-lang/regex/commit/203c509df9e1dcba61eaa60ba9c09be9ca0c4b25
 70%|███████   | 162/230 [03:09<01:09,  1.02s/it]INFO:__main__:Requesting https://github.blog/2018-10-17-behind-the-scenes-of-github-token-scanning/
INFO:__main__:Getting metadata for https://github.blog/2018-10-17-behind-the-scenes-of-github-token-scanning/
 71%|███████   | 163/230 [03:10<01:02,  1.07it/s]INFO:__main__:Requesting https://github.com/zricethezav/gitleaks
INFO:__main__:Getting metadata for https://github.com/zricethezav/gitleaks
 71%|███████▏  | 164/230 [03:11<01:05,  1.01it/s]INFO:__main__:Requesting https://liberapay.com/
INFO:__main__:Getting metadata for https://liberapay.com
 72%|███████▏  | 165/230 [03:12<01:10,  1.08s/it]INFO:__main__:Requesting https://fr.wikipedia.org/wiki/Association_loi_de_1901
INFO:__main__:Getting metadata for https://fr.wikipedia.org/wiki/Association_loi_de_1901
 72%|███████▏  | 166/230 [03:14<01:20,  1.26s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Registered_association_(Germany)
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Registered_association_(Germany)
 73%|███████▎  | 167/230 [03:15<01:09,  1.11s/it]INFO:__main__:Requesting https://snowdrift.coop
INFO:__main__:Getting metadata for https://snowdrift.coop
 73%|███████▎  | 168/230 [03:16<01:03,  1.03s/it]INFO:__main__:Requesting https://en.liberapay.com/about/faq
INFO:__main__:Getting metadata for https://en.liberapay.com/about/faq
ERROR:__main__:Could not get metadata for https://en.liberapay.com/about/faq
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 73%|███████▎  | 169/230 [03:19<01:38,  1.62s/it]INFO:__main__:Requesting https://medium.com/liberapay-blog/liberapay-status-update-a76403f4e0
INFO:__main__:Getting metadata for https://medium.com/liberapay-blog/liberapay-status-update-a76403f4e0
 74%|███████▍  | 170/230 [03:19<01:17,  1.29s/it]INFO:__main__:Requesting https://maecen.com/
INFO:__main__:Getting metadata for https://maecen.com
 74%|███████▍  | 171/230 [03:23<02:00,  2.05s/it]INFO:__main__:Requesting https://www.tipeee.com/
INFO:__main__:Getting metadata for https://en.tipeee.com
 75%|███████▍  | 172/230 [03:35<04:48,  4.97s/it]INFO:__main__:Requesting https://patreon.com/
INFO:__main__:Getting metadata for https://www.patreon.com
 75%|███████▌  | 173/230 [03:36<03:38,  3.83s/it]INFO:__main__:Requesting https://www.buymeacoffee.com/
ERROR:__main__:Could not reach https://www.buymeacoffee.com/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.buymeacoffee.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.buymeacoffee.com', port=443): Read timed out. (read timeout=6)
 76%|███████▌  | 174/230 [03:42<04:13,  4.52s/it]INFO:__main__:Requesting https://flattr.com/
INFO:__main__:Getting metadata for https://flattr.com
ERROR:__main__:Could not get metadata for https://flattr.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 76%|███████▌  | 175/230 [03:43<03:15,  3.56s/it]INFO:__main__:Requesting https://d.rip/
INFO:__main__:Getting metadata for https://d.rip
 77%|███████▋  | 176/230 [03:44<02:25,  2.69s/it]INFO:__main__:Requesting https://wiki.snowdrift.coop/market-research/other-crowdfunding
INFO:__main__:Getting metadata for https://wiki.snowdrift.coop/market-research/other-crowdfunding
 77%|███████▋  | 177/230 [03:47<02:32,  2.88s/it]INFO:__main__:Requesting https://www.patreon.com/godotengine
INFO:__main__:Getting metadata for https://www.patreon.com/godotengine
 77%|███████▋  | 178/230 [03:48<01:56,  2.24s/it]INFO:__main__:Requesting https://www.patreon.com/mastodon
INFO:__main__:Getting metadata for https://www.patreon.com/mastodon
 78%|███████▊  | 179/230 [03:49<01:31,  1.79s/it]INFO:__main__:Requesting https://liberapay.com/Mastodon/
INFO:__main__:Getting metadata for https://liberapay.com/Mastodon/
 78%|███████▊  | 180/230 [03:50<01:22,  1.65s/it]INFO:__main__:Requesting https://liberapay.com/archiveis/
INFO:__main__:Getting metadata for https://liberapay.com/archiveis/
 79%|███████▊  | 181/230 [03:51<01:11,  1.47s/it]INFO:__main__:Requesting https://liberapay.com/davidrevoy/
INFO:__main__:Getting metadata for https://liberapay.com/davidrevoy/
 79%|███████▉  | 182/230 [03:52<01:07,  1.40s/it]INFO:__main__:Requesting https://liberapay.com/GIMP/
INFO:__main__:Getting metadata for https://liberapay.com/GIMP/
 80%|███████▉  | 183/230 [03:54<01:03,  1.34s/it]INFO:__main__:Requesting https://liberapay.com/UBports/
INFO:__main__:Getting metadata for https://liberapay.com/UBports/
 80%|████████  | 184/230 [03:55<01:00,  1.32s/it]INFO:__main__:Requesting https://liberapay.com/F-Droid-Data/
INFO:__main__:Getting metadata for https://liberapay.com/F-Droid-Data/
 80%|████████  | 185/230 [03:56<00:59,  1.32s/it]INFO:__main__:Requesting https://liberapay.com/pixelfed/
INFO:__main__:Getting metadata for https://liberapay.com/pixelfed/
 81%|████████  | 186/230 [03:58<01:00,  1.38s/it]INFO:__main__:Requesting https://liberapay.com/SFTtech/
INFO:__main__:Getting metadata for https://liberapay.com/SFTtech/
 81%|████████▏ | 187/230 [03:59<00:57,  1.34s/it]INFO:__main__:Requesting https://liberapay.com/Telegram-FOSS/
INFO:__main__:Getting metadata for https://liberapay.com/Telegram-FOSS/
 82%|████████▏ | 188/230 [04:00<00:51,  1.23s/it]INFO:__main__:Requesting https://liberapay.com/phpMyAdmin/
INFO:__main__:Getting metadata for https://liberapay.com/phpMyAdmin/
ERROR:__main__:Could not get metadata for https://liberapay.com/phpMyAdmin/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 82%|████████▏ | 189/230 [04:01<00:51,  1.26s/it]INFO:__main__:Requesting https://liberapay.com/Framasoft/
INFO:__main__:Getting metadata for https://liberapay.com/Framasoft/
 83%|████████▎ | 190/230 [04:03<00:50,  1.27s/it]INFO:__main__:Requesting https://liberapay.com/matrixdotorg/
INFO:__main__:Getting metadata for https://liberapay.com/matrixdotorg/
 83%|████████▎ | 191/230 [04:04<00:49,  1.28s/it]INFO:__main__:Requesting https://liberapay.com/Krita/
INFO:__main__:Getting metadata for https://liberapay.com/Krita/
 83%|████████▎ | 192/230 [04:05<00:49,  1.31s/it]INFO:__main__:Requesting https://liberapay.com/Nextcloud/
INFO:__main__:Getting metadata for https://liberapay.com/Nextcloud/
 84%|████████▍ | 193/230 [04:07<00:48,  1.31s/it]INFO:__main__:Requesting https://liberapay.com/ReactOS/
INFO:__main__:Getting metadata for https://liberapay.com/ReactOS/
ERROR:__main__:Could not get metadata for https://liberapay.com/ReactOS/
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 84%|████████▍ | 194/230 [04:08<00:47,  1.31s/it]INFO:__main__:Requesting https://gratipay.com/
INFO:__main__:Getting metadata for https://gratipay.com
 85%|████████▍ | 195/230 [04:08<00:37,  1.08s/it]INFO:__main__:Requesting https://en.liberapay.com/matrixdotorg/
INFO:__main__:Getting metadata for https://en.liberapay.com/matrixdotorg/
 85%|████████▌ | 196/230 [04:09<00:34,  1.02s/it]INFO:__main__:Requesting https://opencollective.com/
INFO:__main__:Getting metadata for https://opencollective.com
ERROR:__main__:Could not get metadata for https://opencollective.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 132, in __init__
    self._set_properties()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 152, in _set_properties
    if property_meta and property_meta['content'] != "":
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/bs4/element.py", line 1016, in __getitem__
    return self.attrs[key]
KeyError: 'content'
 86%|████████▌ | 197/230 [04:10<00:26,  1.24it/s]INFO:__main__:Requesting https://gratipay.news/gratipocalypse-42fd0ec0d9e8
INFO:__main__:Getting metadata for https://gratipay.news/gratipocalypse-42fd0ec0d9e8?gi=a2a6f7c94cf1
 86%|████████▌ | 198/230 [04:11<00:32,  1.00s/it]INFO:__main__:Requesting https://flattr.com/>
 87%|████████▋ | 199/230 [04:12<00:26,  1.18it/s]INFO:__main__:Requesting http://imgs.xkcd.com/comics/standards.png
INFO:__main__:Getting metadata for http://imgs.xkcd.com/comics/standards.png
ERROR:__main__:Could not get metadata for http://imgs.xkcd.com/comics/standards.png
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 87%|████████▋ | 200/230 [04:13<00:26,  1.14it/s]INFO:__main__:Requesting https://flattr.com
INFO:__main__:Getting metadata for https://flattr.com
ERROR:__main__:Could not get metadata for https://flattr.com
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 87%|████████▋ | 201/230 [04:14<00:27,  1.06it/s]INFO:__main__:Requesting https://liberapay.com/explore/individuals
INFO:__main__:Getting metadata for https://liberapay.com/explore/individuals
 88%|████████▊ | 202/230 [04:17<00:48,  1.75s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Jean-Marie_Le_Pen#Issues_and_policy_positions
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Jean-Marie_Le_Pen#Issues_and_policy_positions
 88%|████████▊ | 203/230 [04:19<00:44,  1.66s/it]INFO:__main__:Requesting https://github.com/liberapay/liberapay.com/issues/1383
INFO:__main__:Getting metadata for https://github.com/liberapay/liberapay.com/issues/1383
 89%|████████▊ | 204/230 [04:20<00:41,  1.60s/it]INFO:__main__:Requesting https://medium.com/liberapay-blog/liberapay-is-in-trouble-b58b40714d82
INFO:__main__:Getting metadata for https://medium.com/liberapay-blog/liberapay-is-in-trouble-b58b40714d82
 89%|████████▉ | 205/230 [04:21<00:32,  1.28s/it]INFO:__main__:Requesting https://stripe.com/us/restricted-businesses
INFO:__main__:Getting metadata for https://stripe.com/us/restricted-businesses
 90%|████████▉ | 206/230 [04:21<00:26,  1.12s/it]INFO:__main__:Requesting https://www.vera.org/in-our-backyards-stories/farm-aid-for-the-big-house
INFO:__main__:Getting metadata for https://www.vera.org/in-our-backyards-stories/farm-aid-for-the-big-house
 90%|█████████ | 207/230 [04:24<00:33,  1.44s/it]INFO:__main__:Requesting https://thelri.org/blog-and-news/why-drugs-that-work-in-mice-dont-work-in-humans/
INFO:__main__:Getting metadata for https://thelri.org/blog-and-news/why-drugs-that-work-in-mice-dont-work-in-humans/
 90%|█████████ | 208/230 [04:24<00:25,  1.16s/it]INFO:__main__:Requesting https://www.nature.com/articles/nrd3078
INFO:__main__:Getting metadata for https://www.nature.com/articles/nrd3078
 91%|█████████ | 209/230 [04:27<00:34,  1.62s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Animal_Welfare_Act_of_1966
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Animal_Welfare_Act_of_1966
 91%|█████████▏| 210/230 [04:28<00:28,  1.41s/it]INFO:__main__:Requesting https://www.quora.com/Do-you-agree-with-the-controversial-views-of-Dr-B-M-Hegde-when-it-comes-to-medicine-and-doctors
INFO:__main__:Getting metadata for https://www.quora.com/Do-you-agree-with-the-controversial-views-of-Dr-B-M-Hegde-when-it-comes-to-medicine-and-doctors
 92%|█████████▏| 211/230 [04:31<00:36,  1.90s/it]INFO:__main__:Requesting https://www.getrevue.co/profile/nathanbenaich/issues/6-impactful-applications-of-ai-to-the-life-sciences-new-essay-150757
INFO:__main__:Getting metadata for https://www.getrevue.co/profile/nathanbenaich/issues/6-impactful-applications-of-ai-to-the-life-sciences-new-essay-150757
 92%|█████████▏| 212/230 [04:32<00:28,  1.56s/it]INFO:__main__:Requesting https://europepmc.org/abstract/pmc/pmc1142312
INFO:__main__:Getting metadata for https://europepmc.org/abstract/pmc/pmc1142312
ERROR:__main__:Could not get metadata for https://europepmc.org/abstract/pmc/pmc1142312
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 93%|█████████▎| 213/230 [04:36<00:43,  2.55s/it]INFO:__main__:Requesting http://dogagingproject.com
 93%|█████████▎| 214/230 [04:37<00:29,  1.84s/it]INFO:__main__:Requesting https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/28374166/
ERROR:__main__:Could not reach https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/28374166/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 247, in resolve_redirects
    **adapter_kwargs
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 93%|█████████▎| 215/230 [04:37<00:21,  1.45s/it]INFO:__main__:Requesting https://www.leafscience.org/dr-matt-kaeberlein-the-dog-aging-project/
INFO:__main__:Getting metadata for https://www.leafscience.org/dr-matt-kaeberlein-the-dog-aging-project/
 94%|█████████▍| 216/230 [04:38<00:16,  1.18s/it]INFO:__main__:Requesting https://www.abcam.com/cyclooxygenase-cox-activity-assay-kit-luminometric-ab139432.html
INFO:__main__:Getting metadata for https://www.abcam.com/cyclooxygenase-cox-activity-assay-kit-luminometric-ab139432.html
 94%|█████████▍| 217/230 [04:39<00:15,  1.17s/it]INFO:__main__:Requesting https://www.le.ac.uk/bl/phh4/roottip.htm
INFO:__main__:Getting metadata for https://www.le.ac.uk/bl/phh4/roottip.htm
 95%|█████████▍| 218/230 [04:41<00:18,  1.57s/it]INFO:__main__:Requesting https://www.tdi.ox.ac.uk/small-compound-libraries
INFO:__main__:Getting metadata for https://www.tdi.ox.ac.uk/small-compound-libraries
 95%|█████████▌| 219/230 [04:45<00:24,  2.22s/it]INFO:__main__:Requesting https://wiki.nci.nih.gov/display/NCIDTPdata/Compound+Sets
INFO:__main__:Getting metadata for https://wiki.nci.nih.gov/display/NCIDTPdata/Compound+Sets
 96%|█████████▌| 220/230 [04:48<00:22,  2.30s/it]INFO:__main__:Requesting https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5870873/
INFO:__main__:Getting metadata for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5870873/
 96%|█████████▌| 221/230 [04:50<00:20,  2.23s/it]INFO:__main__:Requesting https://news.ycombinator.com/newsguidelines.html
INFO:__main__:Getting metadata for https://news.ycombinator.com/newsguidelines.html
ERROR:__main__:Could not get metadata for https://news.ycombinator.com/newsguidelines.html
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 97%|█████████▋| 222/230 [04:51<00:15,  1.90s/it]INFO:__main__:Requesting https://grapesjs.com/
INFO:__main__:Getting metadata for https://grapesjs.com
 97%|█████████▋| 223/230 [04:51<00:09,  1.39s/it]INFO:__main__:Requesting https://github.com/unlayer/react-email-editor
INFO:__main__:Getting metadata for https://github.com/unlayer/react-email-editor
 97%|█████████▋| 224/230 [04:52<00:07,  1.21s/it]INFO:__main__:Requesting https://github.com/artf/grapesjs/tree/dev/test/specs
INFO:__main__:Getting metadata for https://github.com/artf/grapesjs/tree/dev/test/specs
 98%|█████████▊| 225/230 [04:53<00:05,  1.12s/it]INFO:__main__:Requesting https://avatars2.githubusercontent.com/u/11614725?s=400&v=4
INFO:__main__:Getting metadata for https://avatars2.githubusercontent.com/u/11614725?s=400&v=4
ERROR:__main__:Could not get metadata for https://avatars2.githubusercontent.com/u/11614725?s=400&v=4
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
 98%|█████████▊| 226/230 [04:54<00:04,  1.15s/it]INFO:__main__:Requesting https://codepen.io/yulian/full/rRNxJx
INFO:__main__:Getting metadata for https://codepen.io/yulian/full/rRNxJx
 99%|█████████▊| 227/230 [04:54<00:02,  1.03it/s]INFO:__main__:Requesting https://github.com/ioulian
INFO:__main__:Getting metadata for https://github.com/ioulian
 99%|█████████▉| 228/230 [04:56<00:02,  1.06s/it]INFO:__main__:Requesting https://github.com/vigetlabs/colonel-kurtz
INFO:__main__:Getting metadata for https://github.com/vigetlabs/colonel-kurtz
100%|█████████▉| 229/230 [04:56<00:00,  1.03it/s]INFO:__main__:Requesting https://github.com/artf/grapesjs/commit/69cfec68bd5202a1fbc349976938704bf1dbb80c
INFO:__main__:Getting metadata for https://github.com/artf/grapesjs/commit/69cfec68bd5202a1fbc349976938704bf1dbb80c
ERROR:__main__:Could not get metadata for https://github.com/artf/grapesjs/commit/69cfec68bd5202a1fbc349976938704bf1dbb80c
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 94, in _get_site_title_and_description
    description = description[:450] + '...' if len(description) > 450 else description
TypeError: object of type 'NoneType' has no len()
100%|██████████| 230/230 [04:58<00:00,  1.15s/it]
