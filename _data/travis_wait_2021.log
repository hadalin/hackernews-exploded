INFO:__main__:Get urls from stories
  0%|          | 0/30 [00:00<?, ?it/s]  3%|▎         | 1/30 [00:00<00:24,  1.21it/s]  7%|▋         | 2/30 [00:01<00:18,  1.52it/s] 10%|█         | 3/30 [00:01<00:15,  1.77it/s] 13%|█▎        | 4/30 [00:01<00:11,  2.22it/s] 23%|██▎       | 7/30 [00:01<00:07,  2.89it/s] 27%|██▋       | 8/30 [00:02<00:09,  2.32it/s] 30%|███       | 9/30 [00:03<00:14,  1.50it/s] 33%|███▎      | 10/30 [00:04<00:11,  1.77it/s] 37%|███▋      | 11/30 [00:04<00:09,  2.06it/s] 40%|████      | 12/30 [00:05<00:10,  1.74it/s] 43%|████▎     | 13/30 [00:05<00:09,  1.72it/s] 47%|████▋     | 14/30 [00:06<00:07,  2.08it/s] 57%|█████▋    | 17/30 [00:08<00:07,  1.83it/s] 60%|██████    | 18/30 [00:11<00:16,  1.41s/it] 63%|██████▎   | 19/30 [00:12<00:13,  1.20s/it] 70%|███████   | 21/30 [00:13<00:09,  1.01s/it] 73%|███████▎  | 22/30 [00:13<00:06,  1.20it/s] 80%|████████  | 24/30 [00:13<00:03,  1.66it/s] 87%|████████▋ | 26/30 [00:15<00:02,  1.71it/s] 90%|█████████ | 27/30 [00:15<00:01,  2.05it/s] 93%|█████████▎| 28/30 [00:15<00:00,  2.48it/s] 97%|█████████▋| 29/30 [00:17<00:00,  1.13it/s]100%|██████████| 30/30 [00:17<00:00,  1.53it/s]
  0%|          | 0/248 [00:00<?, ?it/s]INFO:__main__:Requesting https://privacyinternational.org/blog/2758/guess-what-facebook-still-tracks-you-android-apps-even-if-you-dont-have-facebook-account
INFO:__main__:Getting metadata for https://privacyinternational.org/blog/2758/guess-what-facebook-still-tracks-you-android-apps-even-if-you-dont-have-facebook-account
  0%|          | 1/248 [00:01<05:32,  1.35s/it]INFO:__main__:Requesting https://github.com/jmdugan/blocklists/blob/master/corporations/facebook/all
INFO:__main__:Getting metadata for https://github.com/jmdugan/blocklists/blob/master/corporations/facebook/all
  1%|          | 2/248 [00:02<05:25,  1.32s/it]INFO:__main__:Requesting https://matomo.org/
INFO:__main__:Getting metadata for https://matomo.org
  1%|          | 3/248 [00:03<05:24,  1.32s/it]INFO:__main__:Requesting https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/
INFO:__main__:Getting metadata for https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/
  2%|▏         | 4/248 [00:04<04:06,  1.01s/it]INFO:__main__:Requesting https://twitter.com/jeremyburge/status/1101402001907372032
INFO:__main__:Getting metadata for https://twitter.com/jeremyburge/status/1101402001907372032
  2%|▏         | 5/248 [00:05<04:27,  1.10s/it]INFO:__main__:Requesting https://media.ccc.de/v/35c3-9941-how_facebook_tracks_you_on_android/
INFO:__main__:Getting metadata for https://media.ccc.de/v/35c3-9941-how_facebook_tracks_you_on_android/
  2%|▏         | 6/248 [00:06<04:51,  1.20s/it]INFO:__main__:Requesting https://www.gnu.org/philosophy/ubuntu-spyware.en.html
INFO:__main__:Getting metadata for https://www.gnu.org/philosophy/ubuntu-spyware.en.html
  3%|▎         | 7/248 [00:08<04:49,  1.20s/it]INFO:__main__:Requesting https://mspoweruser.com/microsoft-makes-telemetry-updates-for-windows-7-and-8-1-critical-updates/
INFO:__main__:Getting metadata for https://mspoweruser.com/microsoft-makes-telemetry-updates-for-windows-7-and-8-1-critical-updates/
  3%|▎         | 8/248 [00:08<03:45,  1.06it/s]INFO:__main__:Requesting https://www.howtogeek.com/269331/how-to-disable-all-of-windows-10s-built-in-advertising/
INFO:__main__:Getting metadata for https://www.howtogeek.com/269331/how-to-disable-all-of-windows-10s-built-in-advertising/
  4%|▎         | 9/248 [00:09<03:44,  1.06it/s]INFO:__main__:Requesting https://en.m.wikipedia.org/wiki/BonziBuddy
INFO:__main__:Getting metadata for https://en.m.wikipedia.org/wiki/BonziBuddy
  4%|▍         | 10/248 [00:10<03:20,  1.19it/s]INFO:__main__:Requesting https://news.ycombinator.com/newsguidelines.html
INFO:__main__:Getting metadata for https://news.ycombinator.com/newsguidelines.html
  4%|▍         | 11/248 [00:11<03:38,  1.08it/s]INFO:__main__:Requesting https://web-in-security.blogspot.com/2019/02/how-to-spoof-pdf-signatures.html
INFO:__main__:Getting metadata for https://web-in-security.blogspot.com/2019/02/how-to-spoof-pdf-signatures.html
  5%|▍         | 12/248 [00:11<02:57,  1.33it/s]INFO:__main__:Requesting https://ec.europa.eu/digital-single-market/en/eu-trusted-lists-trust-service-providers
INFO:__main__:Getting metadata for https://ec.europa.eu/digital-single-market/en/eu-trusted-lists-trust-service-providers
  5%|▌         | 13/248 [00:12<03:32,  1.11it/s]INFO:__main__:Requesting https://helpx.adobe.com/acrobat/using/certificate-based-signatures.html#certifying_and_signing_documents
INFO:__main__:Getting metadata for https://helpx.adobe.com/acrobat/using/certificate-based-signatures.html#certifying_and_signing_documents
  6%|▌         | 14/248 [00:14<04:10,  1.07s/it]INFO:__main__:Requesting https://www.pdf-insecurity.org/signature/viewer.html
INFO:__main__:Getting metadata for https://www.pdf-insecurity.org/signature/viewer.html
  6%|▌         | 15/248 [00:17<06:53,  1.78s/it]INFO:__main__:Requesting https://github.com/corkami/collisions
INFO:__main__:Getting metadata for https://github.com/corkami/collisions
  6%|▋         | 16/248 [00:18<06:18,  1.63s/it]INFO:__main__:Requesting https://artsexperiments.withgoogle.com/nasasvisualuniverse
INFO:__main__:Getting metadata for https://artsexperiments.withgoogle.com/nasasvisualuniverse
INFO:__main__:Requesting http://www.paulgraham.com/hp.html
INFO:__main__:Getting metadata for http://www.paulgraham.com/hp.html
  7%|▋         | 18/248 [00:19<04:52,  1.27s/it]INFO:__main__:Requesting https://experiments.withgoogle.com/collection/arts-culture
INFO:__main__:Getting metadata for https://experiments.withgoogle.com/collection/arts-culture
  8%|▊         | 19/248 [00:20<04:19,  1.13s/it]INFO:__main__:Requesting https://www.amazon.com/gp/product/0596006624
INFO:__main__:Getting metadata for https://www.amazon.com/gp/product/0596006624
  8%|▊         | 20/248 [00:22<05:42,  1.50s/it]INFO:__main__:Requesting https://
ERROR:__main__:Could not reach https://
Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 519, in request
    prep = self.prepare_request(req)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 462, in prepare_request
    hooks=merge_hooks(request.hooks, self.hooks),
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 313, in prepare
    self.prepare_url(url, params)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 390, in prepare_url
    raise InvalidURL("Invalid URL %r: No host supplied" % url)
requests.exceptions.InvalidURL: Invalid URL 'https://': No host supplied
INFO:__main__:Requesting https://techcrunch.com/2019/03/06/facebook-refuses-to-disclose-chuck-chequers-brexit-advertiser-to-uk-parliament/
ERROR:__main__:Could not reach https://techcrunch.com/2019/03/06/facebook-refuses-to-disclose-chuck-chequers-brexit-advertiser-to-uk-parliament/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
  9%|▉         | 22/248 [00:23<04:01,  1.07s/it]INFO:__main__:Requesting https://outline.com/ZEdxXN
INFO:__main__:Getting metadata for https://outline.com/ZEdxXN
  9%|▉         | 23/248 [00:23<03:42,  1.01it/s]INFO:__main__:Requesting https://victorzhou.com/blog/intro-to-neural-networks/
INFO:__main__:Getting metadata for https://victorzhou.com/blog/intro-to-neural-networks/
 10%|▉         | 24/248 [00:24<03:22,  1.11it/s]INFO:__main__:Requesting https://cppcrypt.tumblr.com/post/168134225802
INFO:__main__:Getting metadata for https://cppcrypt.tumblr.com/post/168134225802
 10%|█         | 25/248 [00:25<02:52,  1.29it/s]INFO:__main__:Requesting https://cppcrypt.tumblr.com/archive
INFO:__main__:Getting metadata for https://cppcrypt.tumblr.com/archive
 10%|█         | 26/248 [00:26<03:40,  1.01it/s]INFO:__main__:Requesting https://eli.thegreenplace.net/2016/the-expression-problem-and-its-solutions/
INFO:__main__:Getting metadata for https://eli.thegreenplace.net/2016/the-expression-problem-and-its-solutions/
 11%|█         | 27/248 [00:27<04:03,  1.10s/it]INFO:__main__:Requesting https://github.com/dpugson/examples/blob/master/chpt1_the_visitor_pattern/example.cpp
INFO:__main__:Getting metadata for https://github.com/dpugson/examples/blob/master/chpt1_the_visitor_pattern/example.cpp
 11%|█▏        | 28/248 [00:28<03:50,  1.05s/it]INFO:__main__:Requesting https://cppcrypt.tumblr.com/post/168134402897
INFO:__main__:Getting metadata for https://cppcrypt.tumblr.com/post/168134402897
 12%|█▏        | 29/248 [00:29<03:13,  1.13it/s]INFO:__main__:Requesting https://cppcrypt.tumblr.com/post/169439207562
INFO:__main__:Getting metadata for https://cppcrypt.tumblr.com/post/169439207562
 12%|█▏        | 30/248 [00:29<02:46,  1.31it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=CELWr9roNno
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=CELWr9roNno
 12%|█▎        | 31/248 [00:30<02:49,  1.28it/s]INFO:__main__:Requesting https://coliru.stacked-crooked.com/a/dfed39bc7fcdfb01
ERROR:__main__:Could not reach https://coliru.stacked-crooked.com/a/dfed39bc7fcdfb01
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 344, in connect
    ssl_context=context)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/ssl_.py", line 344, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 407, in wrap_socket
    _context=self, _session=session)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 814, in __init__
    self.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1068, in do_handshake
    self._sslobj.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='coliru.stacked-crooked.com', port=443): Max retries exceeded with url: /a/dfed39bc7fcdfb01 (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='coliru.stacked-crooked.com', port=443): Max retries exceeded with url: /a/dfed39bc7fcdfb01 (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))
 13%|█▎        | 32/248 [00:30<02:05,  1.72it/s]INFO:__main__:Requesting https://coliru.stacked-crooked.com/a/be5c44281eea8bc4
ERROR:__main__:Could not reach https://coliru.stacked-crooked.com/a/be5c44281eea8bc4
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 344, in connect
    ssl_context=context)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/ssl_.py", line 344, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 407, in wrap_socket
    _context=self, _session=session)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 814, in __init__
    self.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1068, in do_handshake
    self._sslobj.do_handshake()
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='coliru.stacked-crooked.com', port=443): Max retries exceeded with url: /a/be5c44281eea8bc4 (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='coliru.stacked-crooked.com', port=443): Max retries exceeded with url: /a/be5c44281eea8bc4 (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))
INFO:__main__:Requesting https://en.cppreference.com/w/cpp/utility/variant/visit
INFO:__main__:Getting metadata for https://en.cppreference.com/w/cpp/utility/variant/visit
 14%|█▎        | 34/248 [00:32<02:24,  1.48it/s]INFO:__main__:Requesting https://gist.github.com/km216/aad5c0fa11f32aa562af2370a32208cb
INFO:__main__:Getting metadata for https://gist.github.com/km216/aad5c0fa11f32aa562af2370a32208cb
 14%|█▍        | 35/248 [00:33<02:34,  1.38it/s]INFO:__main__:Requesting https://www.bloomberg.com/news/articles/2019-02-26/buffett-joins-crowd-struggling-to-assess-opaque-oracle
INFO:__main__:Getting metadata for https://www.bloomberg.com/tosv2.html?vid=&uuid=8c9a04f0-4031-11e9-b02b-5d32a8ab642c&url=L25ld3MvYXJ0aWNsZXMvMjAxOS0wMi0yNi9idWZmZXR0LWpvaW5zLWNyb3dkLXN0cnVnZ2xpbmctdG8tYXNzZXNzLW9wYXF1ZS1vcmFjbGU=
 15%|█▍        | 36/248 [00:34<02:36,  1.35it/s]INFO:__main__:Requesting http://www.multpl.com/
INFO:__main__:Getting metadata for http://www.multpl.com
 15%|█▍        | 37/248 [00:34<02:12,  1.59it/s]INFO:__main__:Requesting https://youtu.be/-zRN7XLCRhc?t=1983
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=-zRN7XLCRhc&feature=youtu.be&t=1983
 15%|█▌        | 38/248 [00:35<02:29,  1.40it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=-zRN7XLCRhc#t=38m25s
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=-zRN7XLCRhc#t=38m25s
 16%|█▌        | 39/248 [00:36<02:35,  1.34it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=-zRN7XLCRhc
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=-zRN7XLCRhc
 16%|█▌        | 40/248 [00:37<02:45,  1.26it/s]INFO:__main__:Requesting https://www.bbc.co.uk/news/business-46895770
INFO:__main__:Getting metadata for https://www.bbc.co.uk/news/business-46895770
 17%|█▋        | 41/248 [00:39<03:55,  1.14s/it]INFO:__main__:Requesting https://eliresidential.com/blog/2018/6/12/what-is-the-average-length-of-home-ownership
INFO:__main__:Getting metadata for https://eliresidential.com/blog/2018/6/12/what-is-the-average-length-of-home-ownership
 17%|█▋        | 42/248 [00:39<03:27,  1.01s/it]INFO:__main__:Requesting http://nahbclassic.org/generic.aspx?genericContentID=194717
INFO:__main__:Getting metadata for http://nahbclassic.org/generic.aspx?genericContentID=194717
 17%|█▋        | 43/248 [00:40<03:25,  1.00s/it]INFO:__main__:Requesting https://www.chicagoreader.com/chicago/contract-selling-redlining-housing-discrimination/Content?oid=25705647
INFO:__main__:Getting metadata for https://www.chicagoreader.com/chicago/contract-selling-redlining-housing-discrimination/Content?oid=25705647
 18%|█▊        | 44/248 [00:47<08:59,  2.64s/it]INFO:__main__:Requesting https://fred.stlouisfed.org/series/DRSFRMACBS
INFO:__main__:Getting metadata for https://fred.stlouisfed.org/series/DRSFRMACBS
 18%|█▊        | 45/248 [00:47<06:38,  1.96s/it]INFO:__main__:Requesting https://free.vice.com/en_ca/article/59xp9z/how-six-friends-pooled-their-money-to-buy-a-dollar13-million-house-in-toronto?utm_source=vicecanadafbca&utm_campaign=global
INFO:__main__:Getting metadata for https://free.vice.com/en_ca/article/59xp9z/how-six-friends-pooled-their-money-to-buy-a-dollar13-million-house-in-toronto?utm_source=vicecanadafbca&utm_campaign=global
 19%|█▊        | 46/248 [00:47<04:51,  1.44s/it]INFO:__main__:Requesting https://www.theguardian.com/cities/gallery/2017/jun/07/boxed-life-inside-hong-kong-coffin-cubicles-cage-homes-in-pictures
INFO:__main__:Getting metadata for https://www.theguardian.com/cities/gallery/2017/jun/07/boxed-life-inside-hong-kong-coffin-cubicles-cage-homes-in-pictures
 19%|█▉        | 47/248 [00:48<03:46,  1.13s/it]INFO:__main__:Requesting https://www.cnbc.com/id/101018722
INFO:__main__:Getting metadata for https://www.cnbc.com/id/101018722
 19%|█▉        | 48/248 [00:49<03:27,  1.04s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Urbanization_in_the_United_States#Historical_statistics
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Urbanization_in_the_United_States#Historical_statistics
 20%|█▉        | 49/248 [00:50<03:59,  1.20s/it]INFO:__main__:Requesting https://www.gov.uk/government/publications/income-tax-rent-a-room-relief/income-tax-rent-a-room-relief
INFO:__main__:Getting metadata for https://www.gov.uk/government/publications/income-tax-rent-a-room-relief/income-tax-rent-a-room-relief
 20%|██        | 50/248 [00:51<03:23,  1.03s/it]INFO:__main__:Requesting http://neatsplit.com/
INFO:__main__:Getting metadata for http://neatsplit.com
 21%|██        | 51/248 [00:52<03:35,  1.09s/it]INFO:__main__:Requesting https://beta.companieshouse.gov.uk/company/09581451
INFO:__main__:Getting metadata for https://beta.companieshouse.gov.uk/company/09581451
ERROR:__main__:Could not get metadata for https://beta.companieshouse.gov.uk/company/09581451
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 80, in create_connection
    raise err
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/connection.py", line 70, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 343, in _make_request
    self._validate_conn(conn)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 839, in _validate_conn
    conn.connect()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 301, in connect
    conn = self._new_conn()
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7fd6d47be278>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='beta.companieshouse.gov.uk', port=443): Max retries exceeded with url: /company/09581451 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fd6d47be278>: Failed to establish a new connection: [Errno 110] Connection timed out',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 34, in __init__
    res = requests.get(url, timeout=timeout, headers=headers)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='beta.companieshouse.gov.uk', port=443): Max retries exceeded with url: /company/09581451 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fd6d47be278>: Failed to establish a new connection: [Errno 110] Connection timed out',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 199, in web_preview
    s = Schema(url, ['name', 'description', 'image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 183, in __init__
    super(Schema, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 131, in __init__
    super(SocialPreviewBase, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 36, in __init__
    raise URLUnreachable("The URL does not exist.")
webpreview.excepts.URLUnreachable: The URL does not exist.
 21%|██        | 52/248 [09:35<8:35:15, 157.73s/it]INFO:__main__:Requesting https://www.syndikat.org/en/
INFO:__main__:Getting metadata for https://www.syndikat.org/en/
 21%|██▏       | 53/248 [09:39<6:02:12, 111.45s/it]INFO:__main__:Requesting https://www.theverge.com/transportation/2019/3/5/18250996/sikorsky-autonomous-helicopter-flying-taxi-lockheed
INFO:__main__:Getting metadata for https://www.theverge.com/transportation/2019/3/5/18250996/sikorsky-autonomous-helicopter-flying-taxi-lockheed
 22%|██▏       | 54/248 [09:39<4:12:27, 78.08s/it] INFO:__main__:Requesting https://upload.wikimedia.org/wikipedia/commons/2/27/Igor_Sikorsky_300.jpg
INFO:__main__:Getting metadata for https://upload.wikimedia.org/wikipedia/commons/2/27/Igor_Sikorsky_300.jpg
 22%|██▏       | 55/248 [09:44<3:00:10, 56.01s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Konstantin_Chelpan
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Konstantin_Chelpan
 23%|██▎       | 56/248 [09:44<2:06:09, 39.42s/it]INFO:__main__:Requesting https://arxiv.org/abs/1903.00446
INFO:__main__:Getting metadata for https://arxiv.org/abs/1903.00446
 23%|██▎       | 57/248 [09:45<1:28:49, 27.90s/it]INFO:__main__:Requesting https://people.xiph.org/~xiphmont/demo/neil-young.html
INFO:__main__:Getting metadata for https://people.xiph.org/~xiphmont/demo/neil-young.html
 23%|██▎       | 58/248 [09:47<1:03:15, 19.98s/it]INFO:__main__:Requesting https://forums.stevehoffman.tv/threads/the-common-audiophiles-terror-of-compression-limiting.335257/
INFO:__main__:Getting metadata for https://forums.stevehoffman.tv/threads/the-common-audiophiles-terror-of-compression-limiting.335257/
 24%|██▍       | 59/248 [09:48<44:51, 14.24s/it]  INFO:__main__:Requesting https://en.wikipedia.org/wiki/Dual-tone_multi-frequency_signaling
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Dual-tone_multi-frequency_signaling
 24%|██▍       | 60/248 [09:48<32:02, 10.23s/it]INFO:__main__:Requesting https://en.m.wikipedia.org/wiki/Presbycusis
INFO:__main__:Getting metadata for https://en.m.wikipedia.org/wiki/Presbycusis
 25%|██▍       | 61/248 [09:49<22:59,  7.38s/it]INFO:__main__:Requesting https://www.tate.org.uk/art/artworks/klein-ikb-79-t01513
INFO:__main__:Getting metadata for https://www.tate.org.uk/art/artworks/klein-ikb-79-t01513
 25%|██▌       | 62/248 [09:51<17:23,  5.61s/it]INFO:__main__:Requesting https://contemporaryartetc.wordpress.com/2007/09/13/fact-of-the-day-61/
ERROR:__main__:Could not reach https://contemporaryartetc.wordpress.com/2007/09/13/fact-of-the-day-61/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 25%|██▌       | 63/248 [09:51<12:13,  3.97s/it]INFO:__main__:Requesting https://xiph.org/video/vid1.shtml
INFO:__main__:Getting metadata for https://xiph.org/video/vid1.shtml
 26%|██▌       | 64/248 [09:52<09:32,  3.11s/it]INFO:__main__:Requesting https://xiph.org/video/vid2.shtml
INFO:__main__:Getting metadata for https://xiph.org/video/vid2.shtml
 26%|██▌       | 65/248 [09:53<07:37,  2.50s/it]INFO:__main__:Requesting https://xiph.org/vorbis/
INFO:__main__:Getting metadata for https://xiph.org/vorbis/
 27%|██▋       | 66/248 [09:54<06:15,  2.07s/it]INFO:__main__:Requesting http://www.opus-codec.org/comparison/
INFO:__main__:Getting metadata for http://www.opus-codec.org/comparison/
 27%|██▋       | 67/248 [09:55<04:53,  1.62s/it]INFO:__main__:Requesting https://wiki.xiph.org/OpusFAQ#Does_Opus_make_all_those_other_lossy_codecs_obsolete.3F
INFO:__main__:Getting metadata for https://wiki.xiph.org/OpusFAQ#Does_Opus_make_all_those_other_lossy_codecs_obsolete.3F
 27%|██▋       | 68/248 [09:57<05:20,  1.78s/it]INFO:__main__:Requesting http://www.noise11.com/news/r-i-p-pono-neil-young-kills-off-his-digital-player-20170423
INFO:__main__:Getting metadata for http://www.noise11.com/news/r-i-p-pono-neil-young-kills-off-his-digital-player-20170423
 28%|██▊       | 69/248 [09:57<04:07,  1.38s/it]INFO:__main__:Requesting https://pitchfork.com/reviews/albums/earl-sweatshirt-some-rap-songs/
INFO:__main__:Getting metadata for https://pitchfork.com/reviews/albums/earl-sweatshirt-some-rap-songs/
 28%|██▊       | 70/248 [09:58<03:26,  1.16s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=RlCG2fK-abo
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=RlCG2fK-abo
 29%|██▊       | 71/248 [09:59<03:16,  1.11s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Pono_(digital_music_service)
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Pono_(digital_music_service)
 29%|██▉       | 72/248 [10:00<03:10,  1.08s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Blind_wine_tasting#Biases
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Blind_wine_tasting#Biases
 29%|██▉       | 73/248 [10:01<03:02,  1.04s/it]INFO:__main__:Requesting https://www.nationalgeographic.com/culture/2019/03/maya-ritual-balamku-cave-stuns-archaeologists/
INFO:__main__:Getting metadata for https://www.nationalgeographic.com/culture/2019/03/maya-ritual-balamku-cave-stuns-archaeologists/
 30%|██▉       | 74/248 [10:01<02:19,  1.25it/s]INFO:__main__:Requesting https://imgur.com/EHrwHs3.jpg
INFO:__main__:Getting metadata for https://i.imgur.com/EHrwHs3.jpg
 30%|███       | 75/248 [10:26<23:29,  8.15s/it]INFO:__main__:Requesting https://gfycat.com/responsibleboweddalmatian-exploration-caving-nope
INFO:__main__:Getting metadata for https://gfycat.com/responsibleboweddalmatian-exploration-caving-nope
 31%|███       | 76/248 [10:27<16:45,  5.85s/it]INFO:__main__:Requesting https://www.amazon.com/dp/0812979494
INFO:__main__:Getting metadata for https://www.amazon.com/dp/0812979494
 31%|███       | 77/248 [10:29<13:37,  4.78s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=FAY-t32vyds
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=FAY-t32vyds
 31%|███▏      | 78/248 [10:30<10:15,  3.62s/it]INFO:__main__:Requesting https://i.imgur.com/BkmpH9v.jpg
INFO:__main__:Getting metadata for https://i.imgur.com/BkmpH9v.jpg
 32%|███▏      | 79/248 [10:36<12:14,  4.34s/it]INFO:__main__:Requesting https://www.deseretnews.com/article/705347362/Man-trapped-in-Utah-Countys-Nutty-Putty-cave-dies.html
INFO:__main__:Getting metadata for https://www.deseretnews.com/article/705347362/Man-trapped-in-Utah-Countys-Nutty-Putty-cave-dies.html
 32%|███▏      | 80/248 [10:37<09:03,  3.24s/it]INFO:__main__:Requesting https://translate.google.com/translate?hl=&sl=es&tl=en&u=http%3A%2F%2Fprohispen.com%2Fvictor-segovia-pinto%2F
INFO:__main__:Getting metadata for https://translate.google.com/translate?hl=&sl=es&tl=en&u=http%3A%2F%2Fprohispen.com%2Fvictor-segovia-pinto%2F
 33%|███▎      | 81/248 [10:37<06:35,  2.37s/it]INFO:__main__:Requesting https://revistas-filologicas.unam.mx/estudios-cultura-maya/index.php/ecm/article/view/466
INFO:__main__:Getting metadata for https://revistas-filologicas.unam.mx/estudios-cultura-maya/index.php/ecm/article/view/466
 33%|███▎      | 82/248 [10:44<10:35,  3.83s/it]INFO:__main__:Requesting https://books.google.nl/books?id=bHcgCwAAQBAJ&lpg=PA198&ots=_izQqeMrKE&dq=victor%20segovia%20pinto&pg=PA198#v=onepage&q=victor%20segovia%20pinto&f=false
INFO:__main__:Getting metadata for https://books.google.nl/books?id=bHcgCwAAQBAJ&lpg=PA198&ots=_izQqeMrKE&dq=victor%20segovia%20pinto&pg=PA198#v=onepage&q=victor%20segovia%20pinto&f=false
 33%|███▎      | 83/248 [10:45<08:00,  2.91s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Chaac
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Chaac
 34%|███▍      | 84/248 [10:46<06:12,  2.27s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Tl%C4%81loc
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Tl%C4%81loc
 34%|███▍      | 85/248 [10:47<05:10,  1.90s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Maya_codices
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Maya_codices
 35%|███▍      | 86/248 [10:48<04:28,  1.66s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/1491:_New_Revelations_of_the_Americas_Before_Columbus
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/1491:_New_Revelations_of_the_Americas_Before_Columbus
 35%|███▌      | 87/248 [10:49<03:51,  1.44s/it]INFO:__main__:Requesting https://blog.acolyer.org/2019/03/06/keeping-calm-when-distributed-consistency-is-easy/
ERROR:__main__:Could not reach https://blog.acolyer.org/2019/03/06/keeping-calm-when-distributed-consistency-is-easy/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 35%|███▌      | 88/248 [10:49<02:49,  1.06s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=HnOix9TFy1A
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=HnOix9TFy1A
 36%|███▌      | 89/248 [10:50<02:34,  1.03it/s]INFO:__main__:Requesting https://www.hillelwayne.com/talks/distributed-systems-tlaplus/
INFO:__main__:Getting metadata for https://www.hillelwayne.com/talks/distributed-systems-tlaplus/
 36%|███▋      | 90/248 [10:50<02:07,  1.24it/s]INFO:__main__:Requesting https://lamport.azurewebsites.net/video/videos.html
INFO:__main__:Getting metadata for https://lamport.azurewebsites.net/video/videos.html
 37%|███▋      | 91/248 [10:51<02:18,  1.14it/s]INFO:__main__:Requesting https://lamport.azurewebsites.net/tla/hyperbook.html
INFO:__main__:Getting metadata for https://lamport.azurewebsites.net/tla/hyperbook.html
 37%|███▋      | 92/248 [10:52<02:24,  1.08it/s]INFO:__main__:Requesting https://lamport.azurewebsites.net/tla/book.html
INFO:__main__:Getting metadata for https://lamport.azurewebsites.net/tla/book.html
 38%|███▊      | 93/248 [10:53<02:28,  1.04it/s]INFO:__main__:Requesting https://vadosware.io/post/paxosmon-gotta-concensus-them-all
INFO:__main__:Getting metadata for https://vadosware.io/post/paxosmon-gotta-concensus-them-all/
 38%|███▊      | 94/248 [10:55<03:04,  1.20s/it]INFO:__main__:Requesting https://www.researchgate.net/publication/320371248_Pure_Operation-Based_Replicated_Data_Types
 38%|███▊      | 95/248 [10:55<02:22,  1.07it/s]INFO:__main__:Requesting https://github.com/xgdsmileboy/SimFix
INFO:__main__:Getting metadata for https://github.com/xgdsmileboy/SimFix
 39%|███▊      | 96/248 [10:57<02:36,  1.03s/it]INFO:__main__:Requesting http://program-repair.org/
INFO:__main__:Getting metadata for http://program-repair.org
 39%|███▉      | 97/248 [10:57<02:06,  1.20it/s]INFO:__main__:Requesting https://squareslab.github.io/genprog-code/
INFO:__main__:Getting metadata for https://squareslab.github.io/genprog-code/
 40%|███▉      | 98/248 [10:57<01:35,  1.57it/s]INFO:__main__:Requesting https://github.com/quantifiedcode/quantifiedcode
INFO:__main__:Getting metadata for https://github.com/quantifiedcode/quantifiedcode
 40%|███▉      | 99/248 [10:58<01:39,  1.50it/s]INFO:__main__:Requesting https://www.quantamagazine.org/the-universes-ultimate-complexity-revealed-by-simple-quantum-games-20190305/
INFO:__main__:Getting metadata for https://www.quantamagazine.org/the-universes-ultimate-complexity-revealed-by-simple-quantum-games-20190305/
 40%|████      | 100/248 [10:59<01:58,  1.25it/s]INFO:__main__:Requesting https://www.washingtonpost.com/health/2019/02/28/weekend-catch-up-sleep-is-lie/
ERROR:__main__:Could not reach https://www.washingtonpost.com/health/2019/02/28/weekend-catch-up-sleep-is-lie/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)
 41%|████      | 101/248 [11:05<05:50,  2.38s/it]INFO:__main__:Requesting https://www.huffingtonpost.com/entry/7-scary-ways-sleep-deprivation-affects-teen-physical-and-mental-health_us_55a7bd07e4b04740a3df0fb3
INFO:__main__:Getting metadata for https://www.huffingtonpost.com/entry/7-scary-ways-sleep-deprivation-affects-teen-physical-and-mental-health_us_55a7bd07e4b04740a3df0fb3
 41%|████      | 102/248 [11:05<04:14,  1.74s/it]INFO:__main__:Requesting https://www.huffpost.com/entry/teen-sleep-crimes-adults_n_58b70880e4b019d36d0fec64
INFO:__main__:Getting metadata for https://www.huffpost.com/entry/teen-sleep-crimes-adults_n_58b70880e4b019d36d0fec64
ERROR:__main__:Could not get metadata for https://www.huffpost.com/entry/teen-sleep-crimes-adults_n_58b70880e4b019d36d0fec64
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 324, in _decode
    data = self._decoder.decompress(data)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 77, in decompress
    ret += self._obj.decompress(data)
zlib.error: Error -3 while decompressing data: incorrect header check

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 750, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 494, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 466, in read
    data = self._decode(data, decode_content, flush_decoder)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 329, in _decode
    "failed to decode it." % content_encoding, e)
urllib3.exceptions.DecodeError: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 93, in _get_site_title_and_description
    title, description, _ = web_preview(url, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 190, in web_preview
    og = OpenGraph(url, ['og:title', 'og:description', 'og:image'], timeout=timeout, headers=headers, content=content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 165, in __init__
    super(OpenGraph, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 131, in __init__
    super(SocialPreviewBase, self).__init__(*args, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/webpreview/previews.py", line 34, in __init__
    res = requests.get(url, timeout=timeout, headers=headers)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 686, in send
    r.content
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 828, in content
    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 755, in generate
    raise ContentDecodingError(e)
requests.exceptions.ContentDecodingError: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check',))
 42%|████▏     | 103/248 [11:06<03:12,  1.33s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Circadian_rhythm
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Circadian_rhythm
 42%|████▏     | 104/248 [11:08<03:37,  1.51s/it]INFO:__main__:Requesting https://www.ncbi.nlm.nih.gov/pubmed/10849238
INFO:__main__:Getting metadata for https://www.ncbi.nlm.nih.gov/pubmed/10849238
 42%|████▏     | 105/248 [11:11<04:38,  1.95s/it]INFO:__main__:Requesting https://www.washingtonpost.com/news/speaking-of-science/wp/2018/05/23/people-who-sleep-in-on-weekends-avoid-dying-young-study-suggests/?utm_term=.283730348877
ERROR:__main__:Could not reach https://www.washingtonpost.com/news/speaking-of-science/wp/2018/05/23/people-who-sleep-in-on-weekends-avoid-dying-young-study-suggests/?utm_term=.283730348877
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=6)
 43%|████▎     | 106/248 [11:17<07:31,  3.18s/it]INFO:__main__:Requesting https://scholar.google.com/citations?user=wL1F22UAAAAJ&hl=en
INFO:__main__:Getting metadata for https://scholar.google.com/citations?user=wL1F22UAAAAJ&hl=en
 43%|████▎     | 107/248 [11:18<06:21,  2.71s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Replication_crisis
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Replication_crisis
 44%|████▎     | 108/248 [11:20<05:31,  2.37s/it]INFO:__main__:Requesting https://www.sciencealert.com/replication-results-reproducibility-crisis-science-nature-journals
INFO:__main__:Getting metadata for https://www.sciencealert.com/replication-results-reproducibility-crisis-science-nature-journals
 44%|████▍     | 109/248 [11:21<04:19,  1.87s/it]INFO:__main__:Requesting https://onlinelibrary.wiley.com/doi/full/10.1111/jsr.12712
INFO:__main__:Getting metadata for https://onlinelibrary.wiley.com/doi/full/10.1111/jsr.12712
 44%|████▍     | 110/248 [11:27<07:20,  3.19s/it]INFO:__main__:Requesting https://www.goodreads.com/book/show/34466963
INFO:__main__:Getting metadata for https://www.goodreads.com/book/show/34466963-why-we-sleep
 45%|████▍     | 111/248 [11:28<05:45,  2.52s/it]INFO:__main__:Requesting https://onlinelibrary.wiley.com/doi/pdf/10.1111/jsr.12712
INFO:__main__:Getting metadata for https://onlinelibrary.wiley.com/doi/pdf/10.1111/jsr.12712
 45%|████▌     | 112/248 [11:38<10:39,  4.70s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=pwaWilO_Pig
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=pwaWilO_Pig
 46%|████▌     | 113/248 [11:39<08:01,  3.57s/it]INFO:__main__:Requesting https://www.goodreads.com/book/show/34466963-why-we-sleep
INFO:__main__:Getting metadata for https://www.goodreads.com/book/show/34466963-why-we-sleep
 46%|████▌     | 114/248 [11:40<06:18,  2.83s/it]INFO:__main__:Requesting https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5639921/#!po=7.85124
INFO:__main__:Getting metadata for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5639921/#!po=7.85124
 46%|████▋     | 115/248 [11:41<05:14,  2.37s/it]INFO:__main__:Requesting https://www.aumilight.com/
INFO:__main__:Getting metadata for https://www.aumilight.com
 47%|████▋     | 116/248 [11:41<03:53,  1.77s/it]INFO:__main__:Requesting https://shop.hatchbaby.com/pages/rest
INFO:__main__:Getting metadata for https://shop.hatchbaby.com/pages/rest
 47%|████▋     | 117/248 [11:42<02:56,  1.35s/it]INFO:__main__:Requesting https://www.keenglow.com/
INFO:__main__:Getting metadata for https://www.keenglow.com
 48%|████▊     | 118/248 [11:42<02:15,  1.04s/it]INFO:__main__:Requesting https://archive.fo/0ruX4
ERROR:__main__:Could not reach https://archive.fo/0ruX4
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 360, in _error_catcher
    yield
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 442, in read
    data = self._fp.read(amt)
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 449, in read
    n = self.readinto(b)
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 493, in readinto
    n = self.fp.readinto(b)
  File "/opt/python/3.6.3/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 1009, in recv_into
    return self.read(nbytes, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 871, in read
    return self._sslobj.read(len, buffer)
  File "/opt/python/3.6.3/lib/python3.6/ssl.py", line 631, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 750, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 494, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 459, in read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/opt/python/3.6.3/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/response.py", line 365, in _error_catcher
    raise ReadTimeoutError(self._pool, None, 'Read timed out.')
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='archive.fo', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 686, in send
    r.content
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 828, in content
    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/models.py", line 757, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='archive.fo', port=443): Read timed out.
 48%|████▊     | 119/248 [11:49<06:16,  2.92s/it]INFO:__main__:Requesting https://www.cell.com/current-biology/fulltext/S0960-9822(19)30098-3
INFO:__main__:Getting metadata for https://www.cell.com/current-biology/fulltext/S0960-9822(19)30098-3
 48%|████▊     | 120/248 [11:55<07:50,  3.68s/it]INFO:__main__:Requesting https://www.nsa.gov/ghidra
INFO:__main__:Getting metadata for https://www.nsa.gov/resources/everyone/ghidra/
 49%|████▉     | 121/248 [11:56<05:56,  2.81s/it]INFO:__main__:Requesting https://www.radare.org
INFO:__main__:Getting metadata for https://www.radare.org
 49%|████▉     | 122/248 [11:57<04:43,  2.25s/it]INFO:__main__:Requesting https://github.com/NationalSecurityAgency/ghidra
INFO:__main__:Getting metadata for https://github.com/NationalSecurityAgency/ghidra
 50%|████▉     | 123/248 [11:57<03:47,  1.82s/it]INFO:__main__:Requesting https://docs.binary.ninja/about/license/index.html
INFO:__main__:Getting metadata for https://docs.binary.ninja/about/license/index.html
 50%|█████     | 124/248 [11:58<03:07,  1.51s/it]INFO:__main__:Requesting https://www.hex-rays.com/cgi-bin/quote.cgi
INFO:__main__:Getting metadata for https://www.hex-rays.com/cgi-bin/quote.cgi
 50%|█████     | 125/248 [12:03<05:06,  2.49s/it]INFO:__main__:Requesting https://github.com/BinaryAnalysisPlatform/bap
INFO:__main__:Getting metadata for https://github.com/BinaryAnalysisPlatform/bap
 51%|█████     | 126/248 [12:04<04:23,  2.16s/it]INFO:__main__:Requesting https://github.com/BinaryAnalysisPlatform/bap/issues/929
INFO:__main__:Getting metadata for https://github.com/BinaryAnalysisPlatform/bap/issues/929
 51%|█████     | 127/248 [12:05<03:42,  1.84s/it]INFO:__main__:Requesting https://github.com/IDArlingTeam/IDArling/
INFO:__main__:Getting metadata for https://github.com/IDArlingTeam/IDArling/
 52%|█████▏    | 128/248 [12:06<03:13,  1.61s/it]INFO:__main__:Requesting https://www.pnfsoftware.com
INFO:__main__:Getting metadata for https://www.pnfsoftware.com
 52%|█████▏    | 129/248 [12:08<03:08,  1.59s/it]INFO:__main__:Requesting https://github.com/radare/radare2
INFO:__main__:Getting metadata for https://github.com/radare/radare2
 52%|█████▏    | 130/248 [12:09<02:47,  1.42s/it]INFO:__main__:Requesting https://github.com/radareorg/cutter
INFO:__main__:Getting metadata for https://github.com/radareorg/cutter
 53%|█████▎    | 131/248 [12:10<02:35,  1.33s/it]INFO:__main__:Requesting https://github.com/radareorg/radeco
INFO:__main__:Getting metadata for https://github.com/radareorg/radeco
 53%|█████▎    | 132/248 [12:11<02:19,  1.20s/it]INFO:__main__:Requesting https://github.com/NationalSecurityAgency/ghidra/issues/6
INFO:__main__:Getting metadata for https://github.com/NationalSecurityAgency/ghidra/issues/6
 54%|█████▎    | 133/248 [12:13<02:54,  1.52s/it]INFO:__main__:Requesting https://www.battelle.org/
INFO:__main__:Getting metadata for https://www.battelle.org
 54%|█████▍    | 134/248 [12:14<02:26,  1.29s/it]INFO:__main__:Requesting https://ghidra-sre.org/
INFO:__main__:Getting metadata for https://ghidra-sre.org
 54%|█████▍    | 135/248 [12:14<01:56,  1.03s/it]INFO:__main__:Requesting https://github.com/NationalSecurityAgency/ghidra/
INFO:__main__:Getting metadata for https://github.com/NationalSecurityAgency/ghidra/
 55%|█████▍    | 136/248 [12:15<01:47,  1.04it/s]INFO:__main__:Requesting https://github.com/redhawksdr
INFO:__main__:Getting metadata for https://github.com/redhawksdr
 55%|█████▌    | 137/248 [12:16<01:50,  1.01it/s]INFO:__main__:Requesting https://www.hex-rays.com/products/ida/support/download_freeware.shtml
INFO:__main__:Getting metadata for https://www.hex-rays.com/products/ida/support/download_freeware.shtml
 56%|█████▌    | 138/248 [12:17<01:40,  1.10it/s]INFO:__main__:Requesting https://github.com/NationalSecurityAgency/ghidra/blob/master/NOTICE
INFO:__main__:Getting metadata for https://github.com/NationalSecurityAgency/ghidra/blob/master/NOTICE
 56%|█████▌    | 139/248 [12:18<01:40,  1.09it/s]INFO:__main__:Requesting https://github.com/NationalSecurityAgency/ghidra/blob/master/INTENT.md
INFO:__main__:Getting metadata for https://github.com/NationalSecurityAgency/ghidra/blob/master/INTENT.md
 56%|█████▋    | 140/248 [12:19<01:34,  1.14it/s]INFO:__main__:Requesting https://ghidra-sre.org/GhidraGettingStartedVideo/GhidraGettingStartedVideo_player.html?embedIFrameId=embeddedSmartPlayerInstance&theme=dusk
INFO:__main__:Getting metadata for https://ghidra-sre.org/GhidraGettingStartedVideo/GhidraGettingStartedVideo_player.html?embedIFrameId=embeddedSmartPlayerInstance&theme=dusk
 57%|█████▋    | 141/248 [12:19<01:16,  1.40it/s]INFO:__main__:Requesting https://twitter.com/hackerfantastic/status/1103087869063704576
INFO:__main__:Getting metadata for https://twitter.com/hackerfantastic/status/1103087869063704576
 57%|█████▋    | 142/248 [12:20<01:27,  1.21it/s]INFO:__main__:Requesting https://github.com/avast-tl/retdec
INFO:__main__:Getting metadata for https://github.com/avast-tl/retdec
 58%|█████▊    | 143/248 [12:21<01:41,  1.03it/s]INFO:__main__:Requesting https://binary.ninja/purchase/
INFO:__main__:Getting metadata for https://binary.ninja/purchase/
 58%|█████▊    | 144/248 [12:22<01:27,  1.19it/s]INFO:__main__:Requesting https://github.com/SELinuxProject
INFO:__main__:Getting metadata for https://github.com/SELinuxProject
 58%|█████▊    | 145/248 [12:23<01:21,  1.26it/s]INFO:__main__:Requesting https://github.com/nationalsecurityagency
INFO:__main__:Getting metadata for https://github.com/nationalsecurityagency
 59%|█████▉    | 146/248 [12:24<01:26,  1.17it/s]INFO:__main__:Requesting https://www.cyberscoop.com/ghidra-nsa-tool-public/
INFO:__main__:Getting metadata for https://www.cyberscoop.com/ghidra-nsa-tool-public/
 59%|█████▉    | 147/248 [12:24<01:20,  1.25it/s]INFO:__main__:Requesting https://wikileaks.org/ciav7p1/cms/page_51183656.html
INFO:__main__:Getting metadata for https://wikileaks.org/ciav7p1/cms/page_51183656.html
 60%|█████▉    | 148/248 [12:28<02:54,  1.75s/it]INFO:__main__:Requesting https://coincircle.com/l/50VVxbObg3
INFO:__main__:Getting metadata for https://coincircle.com/earn?r_id=836cf082-a068-4579-8242-b454ba3bb8ab&source=earn&channel=POST_TO_POST_TO_HACKER_NEWS&beta=coincircle123
 60%|██████    | 149/248 [12:29<02:17,  1.39s/it]INFO:__main__:Requesting https://twitter.com/hackerfantastic/status/1103087869063704576?s=21
INFO:__main__:Getting metadata for https://twitter.com/hackerfantastic/status/1103087869063704576?s=21
 60%|██████    | 150/248 [12:30<02:08,  1.31s/it]INFO:__main__:Requesting https://ghidrace.github.io/
INFO:__main__:Requesting https://github.com/withzombies?tab=following
INFO:__main__:Getting metadata for https://github.com/withzombies?tab=following
 61%|██████▏   | 152/248 [12:31<01:41,  1.06s/it]INFO:__main__:Requesting https://letoverlambda.com/
INFO:__main__:Getting metadata for https://letoverlambda.com
 62%|██████▏   | 153/248 [12:32<01:34,  1.01it/s]INFO:__main__:Requesting https://github.com/nornagon/jonesforth/blob/master/jonesforth.S
INFO:__main__:Getting metadata for https://github.com/nornagon/jonesforth/blob/master/jonesforth.S
 62%|██████▏   | 154/248 [12:34<01:54,  1.22s/it]INFO:__main__:Requesting https://old.reddit.com/r/lisp/comments/axu858/here_is_what_we_are_doing_with_common_lisp/
INFO:__main__:Getting metadata for https://old.reddit.com/r/lisp/comments/axu858/here_is_what_we_are_doing_with_common_lisp/
 62%|██████▎   | 155/248 [12:34<01:32,  1.00it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=hZRuGt4TcD8&list=PLbl4KVdl9U3I3MhFWgauT0cz-x7SymZmn&index=4&t=0s
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=hZRuGt4TcD8&list=PLbl4KVdl9U3I3MhFWgauT0cz-x7SymZmn&index=4&t=0s
 63%|██████▎   | 156/248 [12:35<01:33,  1.02s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=8X69_42Mj-g&t=177s&index=3&list=PLbl4KVdl9U3I3MhFWgauT0cz-x7SymZmn
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=8X69_42Mj-g&t=177s&index=3&list=PLbl4KVdl9U3I3MhFWgauT0cz-x7SymZmn
 63%|██████▎   | 157/248 [12:36<01:28,  1.03it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=gYYH2zF41fc&list=PLbl4KVdl9U3I3MhFWgauT0cz-x7SymZmn&index=2&t=201s
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=gYYH2zF41fc&list=PLbl4KVdl9U3I3MhFWgauT0cz-x7SymZmn&index=2&t=201s
 64%|██████▎   | 158/248 [12:37<01:24,  1.07it/s]INFO:__main__:Requesting https://www.cliki.net/Quicklisp%20tutorial
INFO:__main__:Getting metadata for https://www.cliki.net/Quicklisp%20tutorial
 64%|██████▍   | 159/248 [12:39<02:06,  1.42s/it]INFO:__main__:Requesting https://pgloader.io/
INFO:__main__:Getting metadata for https://pgloader.io
 65%|██████▍   | 160/248 [12:40<01:36,  1.10s/it]INFO:__main__:Requesting https://tapoueh.org/blog/2014/05/why-is-pgloader-so-much-faster/
INFO:__main__:Getting metadata for https://tapoueh.org/blog/2014/05/why-is-pgloader-so-much-faster/
 65%|██████▍   | 161/248 [12:40<01:18,  1.11it/s]INFO:__main__:Requesting https://medium.com/@MartinCracauer/a-gentle-introduction-to-compile-time-computing-part-1-d4d96099cea0
INFO:__main__:Getting metadata for https://medium.com/@MartinCracauer/a-gentle-introduction-to-compile-time-computing-part-1-d4d96099cea0
 65%|██████▌   | 162/248 [12:41<01:09,  1.23it/s]INFO:__main__:Requesting https://opusmodus.com
INFO:__main__:Getting metadata for https://opusmodus.com
 66%|██████▌   | 163/248 [12:44<02:02,  1.45s/it]INFO:__main__:Requesting http://www.greghendershott.com/fear-of-macros/fear-of-macros.jpg
INFO:__main__:Getting metadata for http://www.greghendershott.com/fear-of-macros/fear-of-macros.jpg
 66%|██████▌   | 164/248 [12:44<01:44,  1.24s/it]INFO:__main__:Requesting https://letoverlambda.com/index.cl/guest/chap6.html
INFO:__main__:Getting metadata for https://letoverlambda.com/index.cl/guest/chap6.html
 67%|██████▋   | 165/248 [12:46<01:44,  1.26s/it]INFO:__main__:Requesting https://hcsw.org/contact.php
INFO:__main__:Getting metadata for https://hcsw.org/contact.php
 67%|██████▋   | 166/248 [12:47<01:32,  1.13s/it]INFO:__main__:Requesting https://hoytech.com/about
INFO:__main__:Getting metadata for https://hoytech.com/about
 67%|██████▋   | 167/248 [12:47<01:22,  1.01s/it]INFO:__main__:Requesting https://github.com/thephoeron/let-over-lambda
INFO:__main__:Getting metadata for https://github.com/thephoeron/let-over-lambda
 68%|██████▊   | 168/248 [12:48<01:20,  1.00s/it]INFO:__main__:Requesting http://www.paulgraham.com/onlisptext.html
INFO:__main__:Getting metadata for http://www.paulgraham.com/onlisptext.html
 68%|██████▊   | 169/248 [12:49<01:08,  1.16it/s]INFO:__main__:Requesting http://stevelosh.com/blog/2018/08/a-road-to-common-lisp/
INFO:__main__:Getting metadata for http://stevelosh.com/blog/2018/08/a-road-to-common-lisp/
 69%|██████▊   | 170/248 [12:50<01:05,  1.19it/s]INFO:__main__:Requesting https://www.forbes.com/sites/kalevleetaru/2019/02/17/the-big-data-revolution-will-be-sampled-how-big-data-has-come-to-mean-small-sampled-data/
INFO:__main__:Getting metadata for https://www.forbes.com/sites/kalevleetaru/2019/02/17/the-big-data-revolution-will-be-sampled-how-big-data-has-come-to-mean-small-sampled-data/
 69%|██████▉   | 171/248 [12:50<00:51,  1.49it/s]INFO:__main__:Requesting https://www.citylab.com/life/2019/03/rue-cremieux-paris-instagram-tourists-where-to-take-pictures/584164/
INFO:__main__:Getting metadata for https://www.citylab.com/life/2019/03/rue-cremieux-paris-instagram-tourists-where-to-take-pictures/584164/
 69%|██████▉   | 172/248 [12:50<00:40,  1.86it/s]INFO:__main__:Requesting https://www.sciencedirect.com/science/article/pii/S2211368117301687
INFO:__main__:Getting metadata for https://www.sciencedirect.com/science/article/pii/S2211368117301687
 70%|██████▉   | 173/248 [12:51<00:47,  1.57it/s]INFO:__main__:Requesting https://www.slice.ca/travel/photos/most-popular-travel-spots-by-decade/#!The_Catskills_Popular-Destinatons-by-Decade_
INFO:__main__:Getting metadata for https://www.slice.ca/travel/photos/most-popular-travel-spots-by-decade/#!The_Catskills_Popular-Destinatons-by-Decade_
 70%|███████   | 174/248 [12:53<01:09,  1.06it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Grand_Tour
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Grand_Tour
 71%|███████   | 175/248 [12:54<01:14,  1.02s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Pilgrimage
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Pilgrimage
 71%|███████   | 176/248 [12:55<01:18,  1.08s/it]INFO:__main__:Requesting http://ieg-ego.eu/en/threads/europe-on-the-road/the-history-of-tourism#EarlyFormsofTravelandTypesofJourney
INFO:__main__:Getting metadata for http://ieg-ego.eu/en/threads/europe-on-the-road/the-history-of-tourism#EarlyFormsofTravelandTypesofJourney
 71%|███████▏  | 177/248 [12:58<01:56,  1.65s/it]INFO:__main__:Requesting https://www.theguardian.com/cities/2018/jun/25/tourists-go-home-refugees-welcome-why-barcelona-chose-migrants-over-visitors
INFO:__main__:Getting metadata for https://www.theguardian.com/cities/2018/jun/25/tourists-go-home-refugees-welcome-why-barcelona-chose-migrants-over-visitors
 72%|███████▏  | 178/248 [12:59<01:30,  1.30s/it]INFO:__main__:Requesting https://www.instagram.com/__serio__/
INFO:__main__:Getting metadata for https://www.instagram.com/__serio__/
 72%|███████▏  | 179/248 [13:00<01:27,  1.26s/it]INFO:__main__:Requesting https://www.instagram.com/p/Bs2aWsbHxT0/
INFO:__main__:Getting metadata for https://www.instagram.com/p/Bs2aWsbHxT0/
 73%|███████▎  | 180/248 [13:00<01:12,  1.07s/it]INFO:__main__:Requesting https://www.instagram.com/p/Buo4NcFDxU7/
INFO:__main__:Getting metadata for https://www.instagram.com/p/Buo4NcFDxU7/
 73%|███████▎  | 181/248 [13:01<00:58,  1.15it/s]INFO:__main__:Requesting https://www.wonderslist.com/wp-content/uploads/2013/07/Bondi-Beach-New-South-Wales.jpg
INFO:__main__:Getting metadata for https://www.wonderslist.com/wp-content/uploads/2013/07/Bondi-Beach-New-South-Wales.jpg
 73%|███████▎  | 182/248 [13:04<01:49,  1.65s/it]INFO:__main__:Requesting https://www.theglobeandmail.com/canada/article-how-the-quest-for-the-perfect-selfie-forced-an-ontario-sunflower-farm/
INFO:__main__:Getting metadata for https://www.theglobeandmail.com/canada/article-how-the-quest-for-the-perfect-selfie-forced-an-ontario-sunflower-farm/
 74%|███████▍  | 183/248 [13:05<01:21,  1.26s/it]INFO:__main__:Requesting http://www.stilldrinking.com/this-is-not-about-tinder
 74%|███████▍  | 184/248 [13:05<01:00,  1.06it/s]INFO:__main__:Requesting https://www.bbc.co.uk/news/resources/idt-sh/the_beach_nobody_can_touch
INFO:__main__:Getting metadata for https://www.bbc.co.uk/news/resources/idt-sh/the_beach_nobody_can_touch
 75%|███████▍  | 185/248 [13:06<01:14,  1.18s/it]INFO:__main__:Requesting https://www.telegraph.co.uk/news/2019/02/12/tate-modern-neighbours-lose-privacy-battle-judge-says-put-net/
INFO:__main__:Getting metadata for https://www.telegraph.co.uk/news/2019/02/12/tate-modern-neighbours-lose-privacy-battle-judge-says-put-net/
 75%|███████▌  | 186/248 [13:08<01:24,  1.36s/it]INFO:__main__:Requesting https://www.standard.co.uk/news/london/please-stop-influencing-on-our-doorsteps-notting-hill-residents-tell-unapologetic-social-media-a4078806.html
INFO:__main__:Getting metadata for https://www.standard.co.uk/news/london/please-stop-influencing-on-our-doorsteps-notting-hill-residents-tell-unapologetic-social-media-a4078806.html
 75%|███████▌  | 187/248 [13:09<01:06,  1.09s/it]INFO:__main__:Requesting https://www.earthcam.com/world/england/london/abbeyroad/?cam=abbeyroad_uk
INFO:__main__:Getting metadata for https://www.earthcam.com/world/england/london/abbeyroad/?cam=abbeyroad_uk
 76%|███████▌  | 188/248 [13:09<00:57,  1.05it/s]INFO:__main__:Requesting https://youtu.be/Itjc14Fm-gs
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=Itjc14Fm-gs&feature=youtu.be
 76%|███████▌  | 189/248 [13:10<00:55,  1.07it/s]INFO:__main__:Requesting https://www.boredpanda.com/social-media-instagram-identical-photos/
INFO:__main__:Getting metadata for https://www.boredpanda.com/social-media-instagram-identical-photos/
 77%|███████▋  | 190/248 [13:11<00:57,  1.01it/s]INFO:__main__:Requesting https://numenta.com/blog/2019/01/16/the-thousand-brains-theory-of-intelligence/
INFO:__main__:Getting metadata for https://numenta.com/blog/2019/01/16/the-thousand-brains-theory-of-intelligence/
 77%|███████▋  | 191/248 [13:12<00:44,  1.27it/s]INFO:__main__:Requesting https://discourse.numenta.org/
INFO:__main__:Getting metadata for https://discourse.numenta.org
 77%|███████▋  | 192/248 [13:12<00:41,  1.36it/s]INFO:__main__:Requesting https://www.techrepublic.com/article/google-deepmind-founder-demis-hassabis-three-truths-about-ai/
INFO:__main__:Getting metadata for https://www.techrepublic.com/article/google-deepmind-founder-demis-hassabis-three-truths-about-ai/
 78%|███████▊  | 193/248 [13:14<00:50,  1.09it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/BrownBoost
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/BrownBoost
 78%|███████▊  | 194/248 [13:15<00:52,  1.04it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Random_forest
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Random_forest
 79%|███████▊  | 195/248 [13:17<01:09,  1.31s/it]INFO:__main__:Requesting https://www.theverge.com/2019/3/4/18246182/usb-4-thunderbolt-3-specs-features-release-date
INFO:__main__:Getting metadata for https://www.theverge.com/2019/3/4/18246182/usb-4-thunderbolt-3-specs-features-release-date
 79%|███████▉  | 196/248 [13:17<00:51,  1.01it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=uOlQbP63lDQ
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=uOlQbP63lDQ
 79%|███████▉  | 197/248 [13:18<00:49,  1.03it/s]INFO:__main__:Requesting https://www.youtube.com/watch?v=GDyL2tPyXFA
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=GDyL2tPyXFA
 80%|███████▉  | 198/248 [13:19<00:46,  1.06it/s]INFO:__main__:Requesting https://twitter.com/antoniogm/status/1103190266930913281
INFO:__main__:Getting metadata for https://twitter.com/antoniogm/status/1103190266930913281
 80%|████████  | 199/248 [13:20<00:46,  1.05it/s]INFO:__main__:Requesting https://www.python.org/dev/peps/pep-0584/
INFO:__main__:Getting metadata for https://www.python.org/dev/peps/pep-0584/
 81%|████████  | 200/248 [13:20<00:36,  1.32it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Liskov_substitution_principle
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Liskov_substitution_principle
 81%|████████  | 201/248 [13:21<00:37,  1.25it/s]INFO:__main__:Requesting https://doc.rust-lang.org/stable/src/std/collections/hash/set.rs.html#111-113
INFO:__main__:Getting metadata for https://doc.rust-lang.org/stable/src/std/collections/hash/set.rs.html#111-113
 81%|████████▏ | 202/248 [13:24<01:06,  1.44s/it]INFO:__main__:Requesting https://docs.scala-lang.org/overviews/collections/maps.html
INFO:__main__:Getting metadata for https://docs.scala-lang.org/overviews/collections/maps.html
 82%|████████▏ | 203/248 [13:27<01:28,  1.97s/it]INFO:__main__:Requesting https://bugs.python.org/issue36144#msg336848
INFO:__main__:Getting metadata for https://bugs.python.org/issue36144#msg336848
 82%|████████▏ | 204/248 [13:31<01:48,  2.46s/it]INFO:__main__:Requesting https://shipilev.net/jvm/anatomy-quarks/23-compressed-references/
INFO:__main__:Getting metadata for https://shipilev.net/jvm/anatomy-quarks/23-compressed-references/
 83%|████████▎ | 205/248 [13:34<01:52,  2.61s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Succinct_data_structure
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Succinct_data_structure
 83%|████████▎ | 206/248 [13:35<01:32,  2.21s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Compressed_data_structure
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Compressed_data_structure
 83%|████████▎ | 207/248 [13:36<01:12,  1.77s/it]INFO:__main__:Requesting https://github.com/rust-lang/rust/pull/45225
INFO:__main__:Getting metadata for https://github.com/rust-lang/rust/pull/45225
 84%|████████▍ | 208/248 [13:41<01:55,  2.88s/it]INFO:__main__:Requesting https://github.com/eclipse/openj9
INFO:__main__:Getting metadata for https://github.com/eclipse/openj9
 84%|████████▍ | 209/248 [13:43<01:33,  2.40s/it]INFO:__main__:Requesting https://blog.openj9.org/category/jit/aot/
ERROR:__main__:Could not reach https://blog.openj9.org/category/jit/aot/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 85%|████████▍ | 210/248 [13:43<01:06,  1.75s/it]INFO:__main__:Requesting http://openjdk.java.net/projects/panama/
INFO:__main__:Getting metadata for http://openjdk.java.net/projects/panama/
 85%|████████▌ | 211/248 [13:43<00:53,  1.44s/it]INFO:__main__:Requesting https://www.azul.com/presentation/objectlayout/
INFO:__main__:Getting metadata for https://www.azul.com/presentation/objectlayout/
 85%|████████▌ | 212/248 [13:44<00:39,  1.09s/it]INFO:__main__:Requesting https://medium.com/waymo/bringing-3d-perimeter-lidar-to-partners-6beaa7d3dcc2
INFO:__main__:Getting metadata for https://medium.com/waymo/bringing-3d-perimeter-lidar-to-partners-6beaa7d3dcc2
 86%|████████▌ | 213/248 [13:44<00:31,  1.12it/s]INFO:__main__:Requesting https://techcrunch.com/2019/03/06/waymo-to-start-selling-standalone-lidar-sensors/
ERROR:__main__:Could not reach https://techcrunch.com/2019/03/06/waymo-to-start-selling-standalone-lidar-sensors/
Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/util/retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/urllib3/connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/opt/python/3.6.3/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../_scripts/crawler/crawler.py", line 210, in metafy_url
    response = requests.get(url, timeout=6, headers={'User-Agent': 'Mozilla/5.0'})
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/home/travis/virtualenv/python3.6.3/lib/python3.6/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))
 86%|████████▋ | 214/248 [13:44<00:22,  1.51it/s]INFO:__main__:Requesting https://www.theverge.com/2019/3/6/18252561/waymo-sell-lidar-laser-sensor-av-customer-robot-taxi-competition
INFO:__main__:Getting metadata for https://www.theverge.com/2019/3/6/18252561/waymo-sell-lidar-laser-sensor-av-customer-robot-taxi-competition
 87%|████████▋ | 215/248 [13:45<00:17,  1.91it/s]INFO:__main__:Requesting https://www.dw.com/en/european-parliament-set-to-end-eu-wide-daylight-savings/a-47775317
INFO:__main__:Getting metadata for https://www.dw.com/en/european-parliament-set-to-end-eu-wide-daylight-saving/a-47775317
 87%|████████▋ | 216/248 [13:46<00:27,  1.15it/s]INFO:__main__:Requesting https://www.rspb.org.uk/birds-and-wildlife/advice/how-you-can-help-birds/where-have-all-the-birds-gone/is-the-number-of-birds-in-decline/
INFO:__main__:Getting metadata for https://www.rspb.org.uk/birds-and-wildlife/advice/how-you-can-help-birds/where-have-all-the-birds-gone/is-the-number-of-birds-in-decline/
 88%|████████▊ | 217/248 [13:48<00:37,  1.21s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Soviet_calendar
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Soviet_calendar
 88%|████████▊ | 218/248 [13:49<00:37,  1.23s/it]INFO:__main__:Requesting https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time
INFO:__main__:Getting metadata for https://infiniteundo.com/post/25509354022/more-falsehoods-programmers-believe-about-time
 88%|████████▊ | 219/248 [13:50<00:30,  1.06s/it]INFO:__main__:Requesting http://creativedeletion.com/2015/01/28/falsehoods-programmers-date-time-zones.html
INFO:__main__:Getting metadata for http://www.creativedeletion.com/2015/01/28/falsehoods-programmers-date-time-zones.html
 89%|████████▊ | 220/248 [13:51<00:24,  1.16it/s]INFO:__main__:Requesting http://www.legislation.gov.uk/uksi/2002/262/article/2/made
INFO:__main__:Getting metadata for http://www.legislation.gov.uk/uksi/2002/262/article/2/made
 89%|████████▉ | 221/248 [13:51<00:23,  1.16it/s]INFO:__main__:Requesting http://www.webexhibits.org/daylightsaving/usc.html
INFO:__main__:Getting metadata for http://www.webexhibits.org/daylightsaving/usc.html
 90%|████████▉ | 222/248 [13:52<00:21,  1.20it/s]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Daylight_saving_time_in_the_United_States#1966%E2%80%931972:_Federal_standard_established
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Daylight_saving_time_in_the_United_States#1966%E2%80%931972:_Federal_standard_established
 90%|████████▉ | 223/248 [13:53<00:23,  1.07it/s]INFO:__main__:Requesting https://www.livescience.com/56725-does-daylight-saving-time-save-energy.html
INFO:__main__:Getting metadata for https://www.livescience.com/56725-does-daylight-saving-time-save-energy.html
 90%|█████████ | 224/248 [13:55<00:27,  1.13s/it]INFO:__main__:Requesting https://www.dw.com/en/eu-citizens-feel-times-up-for-changing-clocks/a-45263664
INFO:__main__:Getting metadata for https://www.dw.com/en/eu-citizens-feel-times-up-for-changing-clocks/a-45263664
 91%|█████████ | 225/248 [13:56<00:26,  1.17s/it]INFO:__main__:Requesting https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52018SC0406
INFO:__main__:Getting metadata for https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52018SC0406
 91%|█████████ | 226/248 [14:01<00:47,  2.15s/it]INFO:__main__:Requesting https://qz.com/1375622/eu-citizens-voted-to-abolish-daylight-saving-time-in-a-landslide/
INFO:__main__:Getting metadata for https://qz.com/1375622/eu-citizens-voted-to-abolish-daylight-saving-time-in-a-landslide/
 92%|█████████▏| 227/248 [14:01<00:32,  1.56s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Apportionment_in_the_European_Parliament
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Apportionment_in_the_European_Parliament
 92%|█████████▏| 228/248 [14:03<00:34,  1.73s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Degressive_proportionality
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Degressive_proportionality
 92%|█████████▏| 229/248 [14:04<00:27,  1.45s/it]INFO:__main__:Requesting https://youtu.be/84aWtseb2-4?t=230
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=84aWtseb2-4&feature=youtu.be&t=230
 93%|█████████▎| 230/248 [14:05<00:23,  1.31s/it]INFO:__main__:Requesting https://www.nrc.nl/nieuws/2018/12/19/meeste-nederlanders-willen-hele-jaar-wintertijd-a3126390
INFO:__main__:Getting metadata for https://www.nrc.nl/nieuws/2018/12/19/meeste-nederlanders-willen-hele-jaar-wintertijd-a3126390
 93%|█████████▎| 231/248 [14:06<00:22,  1.32s/it]INFO:__main__:Requesting https://qntm.org/abolish
INFO:__main__:Getting metadata for https://qntm.org/abolish
 94%|█████████▎| 232/248 [14:08<00:24,  1.52s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Daylight_saving_time#History
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Daylight_saving_time#History
 94%|█████████▍| 233/248 [14:10<00:25,  1.72s/it]INFO:__main__:Requesting https://www.timeanddate.com/sun/usa/san-francisco
INFO:__main__:Getting metadata for https://www.timeanddate.com/sun/usa/san-francisco
 94%|█████████▍| 234/248 [14:52<03:10, 13.63s/it]INFO:__main__:Requesting https://www.timeanddate.com/sun/sweden/stockholm
INFO:__main__:Getting metadata for https://www.timeanddate.com/sun/sweden/stockholm
 95%|█████████▍| 235/248 [15:13<03:26, 15.92s/it]INFO:__main__:Requesting https://www.timeanddate.com/sun/usa/honolulu
INFO:__main__:Getting metadata for https://www.timeanddate.com/sun/usa/honolulu
 95%|█████████▌| 236/248 [15:34<03:29, 17.49s/it]INFO:__main__:Requesting https://www.timeanddate.com/sun/norway/narvik
INFO:__main__:Getting metadata for https://www.timeanddate.com/sun/norway/narvik
 96%|█████████▌| 237/248 [15:55<03:24, 18.60s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Swatch_Internet_Time
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Swatch_Internet_Time
 96%|█████████▌| 238/248 [15:56<02:12, 13.28s/it]INFO:__main__:Requesting https://en.wikipedia.org/wiki/Northern_Cyprus
INFO:__main__:Getting metadata for https://en.wikipedia.org/wiki/Northern_Cyprus
 96%|█████████▋| 239/248 [15:59<01:31, 10.15s/it]INFO:__main__:Requesting https://briefingsforbrexit.com/
INFO:__main__:Getting metadata for https://briefingsforbrexit.com
 97%|█████████▋| 240/248 [16:02<01:04,  8.02s/it]INFO:__main__:Requesting https://www.ibtimes.co.uk/tony-benn-dead-five-questions-power-other-memorable-quotes-1440277
INFO:__main__:Getting metadata for https://www.ibtimes.co.uk/tony-benn-dead-five-questions-power-other-memorable-quotes-1440277
 97%|█████████▋| 241/248 [16:02<00:40,  5.73s/it]INFO:__main__:Requesting https://europa.eu/european-union/about-eu/institutions-bodies/european-parliament_en
INFO:__main__:Getting metadata for https://europa.eu/european-union/about-eu/institutions-bodies/european-parliament_en
 98%|█████████▊| 242/248 [16:04<00:27,  4.52s/it]INFO:__main__:Requesting https://www.telegraph.co.uk/culture/art/10561090/Akhenaten-mad-bad-or-brilliant.html
INFO:__main__:Getting metadata for https://www.telegraph.co.uk/culture/art/10561090/Akhenaten-mad-bad-or-brilliant.html
 98%|█████████▊| 243/248 [16:04<00:16,  3.26s/it]INFO:__main__:Requesting https://www.amazon.com/1177-B-C-Civilization-Collapsed-Turning/dp/0691168385
INFO:__main__:Getting metadata for https://www.amazon.com/1177-B-C-Civilization-Collapsed-Turning/dp/0691168385
 98%|█████████▊| 244/248 [16:07<00:12,  3.06s/it]INFO:__main__:Requesting https://operawire.com/a-philip-glass-opera-confirmed-for-metropolitan-opera-premiere-in-2019/
 99%|█████████▉| 245/248 [16:07<00:06,  2.20s/it]INFO:__main__:Requesting https://www.eno.org/whats-on/akhnaten/
INFO:__main__:Getting metadata for https://www.eno.org/whats-on/akhnaten/
 99%|█████████▉| 246/248 [16:09<00:03,  1.93s/it]INFO:__main__:Requesting https://www.youtube.com/watch?v=jEYPaZeLhLg
INFO:__main__:Getting metadata for https://www.youtube.com/watch?v=jEYPaZeLhLg
100%|█████████▉| 247/248 [16:09<00:01,  1.63s/it]INFO:__main__:Requesting https://philosophynow.org/issues/128/Does_Western_Philosophy_Have_Egyptian_Roots
INFO:__main__:Getting metadata for https://philosophynow.org/issues/128/Does_Western_Philosophy_Have_Egyptian_Roots
100%|██████████| 248/248 [16:15<00:00,  2.71s/it]
